\part{Case-Studies in Biomedical Data Integration}

\section{Integrating Clinical Outcomes with Radiological Data}
\p{Diagnostic imaging and radiological data sets are 
an important aspect of Covid-19 data because radiological 
analyses of the chest, particularly Computed Tomography 
scans, can prove the suspicion that a patient is suffering 
from Covid-19.  The Radiological Society of 
North America (\RSNA{}) has announced an initiative to 
create an \q{\AI{} Imaging Data Repository,} which will 
\q{support research on using medical imaging to screen for, 
diagnose and treat COVID-19} 
(see \bhref{https://www.rsna.org/covid-19}).  In 
accordance with previously curated \RSNA{} data sets, 
this repository will include image series paired with 
annotations encoding analytic results indicating 
image features that suggest a Covid-19 diagnosis.}

\p{To demonstrate the need for radiology-oriented 
ontologies designed with an emphasis on 
application integration --- that is, for an Application 
Ontology dedicated to the diagnostic-imaging domain 
--- one should note that curating radiological data sets 
presents challenges different than those addressed by 
conventional diagnostic-imaging software.  In the 
conventional workflow, radiographic images are requested by 
some medical institution for diagnostic purposes.  
Relevant information is therefore shared between 
two end-points: the institution which prescribes 
a diagostic evaluation and the radiologist or 
laboratory which analyzes the resulting images.  
Building radiographic data repositories complicates 
this workflow because a third entity becomes 
involved --- the organization responsible 
for aggregating images and analyses is generally 
distinct from both the prescribing institution and 
the radiologists themselves.  Large-scale 
repositories (such as the \RSNA{}'s 
\AI{} Imaging Data Repository) 
are designed to pool patient data from multiple 
hospitals and multiple radiographic laboratories.  
As a result, both radiologists and prescribing 
institutions, upon participation in the formation 
of the target repository, must identify when a given patient 
is a proper candidate for the repository. 
For example, images become relevant for the 
Covid-19 \AI{} Imaging Data Repository when 
such images consist of \CT{} scans that are 
prescribed for the purpose of confirming 
a diagnosis of SARS-CoV-2 infection.}

\p{In the diagnostic context, radiographic data may, 
in general, include the following: 
(1) the findings reported by radiologists; 
(2) image-annotations made by radiologists which point 
to image features providing evidence for their 
findings; and (3) data generated by algorithmic 
image-analysis tools.  As \AI{} tools and 
Computer Vision have become more powerful, 
data generated by quantitative image-analysis 
has become an important element of radiographic 
data.  Moreover, the software used to perform image analysis 
may be distinct from the \PACS{} systems employed by 
radiologists themselves in the laboratory setting.  
For example, the \CaPTk{} (Cancer Imaging Phenomics 
Toolkit) software, developed by \CBICA{} 
(the Center for Biomedical Image Computing and Analytics at 
the University of Pennsylvania), is designed 
as a central workstation from which --- after 
loading an image --- researchers can initiate a number 
of analytic operations, yielding a modified image and/or 
a quantitative data aggregate (e.g., a feature vector) 
encoding information about the image (see 
\bhref{https://www.med.upenn.edu/cbica/captk/}).}

\p{The \CaPTk{} architecture, although developed in 
the context of cancer research, is compatible with image-processing 
for any radiological area of study.  This 
architecture is extensible: developers may add new 
image-analysis software which is registered with 
the central \CaPTk{} application, allowing users 
to launch these software extensions while running 
the main application.  Collectively, then, 
a \CaPTk{} instance enhanced with such software 
add-ons form a multi-application 
network similar to those outlined above in the White Paper. 
For this system to work properly, \CaPTk{} and 
its peer applications implement a specific 
data-sharing protocol, which in turn is based 
on the Common Workflow Language (\CWL{}) and on technical \Qt{} 
coding patterns related to reactive programming.}

\p{In the context of radiological data curation --- that is, 
where image-analysis data is not only used  
for a single diagnosis, but is also registered with a 
central repository which tracks radiographic 
data specific to a given disease, imaging modality, 
or course of treatment --- the native data-sharing 
protocol between \CaPTk{} and its peer applications 
can then be extended.  In this manner, image-analysis data 
can be exported outside the overall \CaPTk{} system, 
allowing this data to be shared with external 
repositories.  Furthermore, a similar workflow can be 
implemented in the context of conventional 
radiological software --- that is, software 
oriented to manual diagnosis and annotation rather 
than \AI{} tools.  For example, \CaPTk{} pairs 
conveniently with \medInria{} (a general-purpose radiology 
platform) and with \ThreeDimViewer{} (a tool which generates 
\ThreeD{} tissue models from \TwoD{} image series).  
All three of these applications share a common 
programming foundation (based on \Cpp{}, \Qt{}, 
and the Insight Toolkit and Visualization Toolkit 
for image segmentation and \TwoD{}/\ThreeD{} image 
analysis).  It is therefore possible 
to implement a data-sharing protocol which integrates 
each of these applications; a researcher 
could use \medInria{} for manual examination of an 
image series and then switch to \CaPTk{} to perform 
\AI{}-driven analyses.  This data integration applies not 
only to radiologists conducting a prescribed diagnosis, 
but also --- perhaps more significantly --- 
to researchers conducting analyses on images 
published within a radiographic repository.  
In this case, researchers are trying to retroactively 
analyze collections of images, drawn from different 
patients, so as to find correlations between 
observable features in a diagnostic image and 
post-diagnostic treatment outcomes.}

\p{Integrating \CaPTk{} (along with its software 
extensions, which are themselves semi-autonomous 
native applications) with additional radiological 
software, such as \medInria{} and \ThreeDimViewer{}, 
yields a multi-faceted Application Network 
capable of integrating different forms of 
radiographic data.  Such a framework, however, 
requires a data-sharing protocol which operates 
effectively at the application level --- in effect, 
an Application Ontology.  Although the 
Common Workflow Language (\CWL{}) provides a basic 
layer of inter-application communication, a fully-developed 
radiological application ontology has not yet been 
formalized.  In curating the \CRtwo{} and \AIMConc{} 
repositories, we will address 
these lacunae by defining a diagnostic-imaging Hypergraph 
Ontology and implementing support for the 
corresponding schema as extensions to \CaPTk{}, 
\medInria{}, \ThreeDimViewer{}, and other image-processing and 
research tools.  We will also expand the scope of 
this ontology to incoporate clinical and outcomes data.}

\p{As illustrated by \CaPTk{}, multi-application workflows 
are characterized both by the data which is 
transferred between applications and by the 
operations which connect the two applications 
--- that is, the procedures enacted by 
each application when they become operationally 
linked.  As a preliminary model, we can identify 
two stages of operational connection between 
an already-running application (which may be 
called the \textit{primary} component) 
and a second application launched by the primary 
(which may be called the \textit{peer} component).  
The first stage occurs when the primary component 
launches the peer component, and is characterized 
by two operational sequences: procedures enacted 
by the primary prior to this launch, and procedures 
enacted by the peer subsequent to the launch.  
A second stage occurs when the peer component 
has completed its actions, and sends data back 
to the primary component, which again involves two 
operational sequences: procedures enacted by the 
peer prior to the transfer, and procedures enacted by the 
primary subsequent to the transfer.  Fully describing 
the procedural workflow therefore entails specifying 
four operational sequences: primary, then peer, 
during the launch stage; and peer, then primary, 
during the transfer stage.  A schema describing 
the operations performed during these four sequences 
can be called a \textit{procedural ontology}.}

\p{Consequently, rigorous models of multi-application networks 
should \textit{synthesize} information about data structures 
(the type of information shared between application-points) 
with information about procedural workflows 
(describing operational sequences prior to 
the launch and transfer stages of a multi-application linkage).  
The synthesis of this structural and procedural information 
can be called a \textit{procedural application ontology}.  
In the case of \CaPTk{}, such a procedural model is 
implicitly recognized in the protocol for integrating 
new applications with the \CaPTk{} software, but 
this implicit protocol has not been explicitly 
defined in ontological terms.  As such, we propose to 
standardize a Procedural Application Ontology model which 
can clarify the inner workings of multi-application 
protocols such as those of \CaPTk{}.} 

\p{Aside from enhancing \CaPTk{} itself, this form of ontology 
can serve the more general purpose of prototyping 
the kinds of inter-application networking which is 
prerequisite for generalizing medical-imaging software 
in the direction of data-repository curation and 
Comparative Effectiveness research.  That is, 
projects which seek to aggregate radiographic 
data into third-party archives --- such as the 
\RSNA{} \AI{} repository for Covid-19 --- 
and/or projects which perform analyses cross-referencing 
radiographic data with clinical outcomes, need 
to pull data from radiological software systems so 
that this information can be absorbed into a larger 
clinical-evaluative ecosystem.  In effect, 
radiological application networks need to be 
expanded to accommodate patient-centered, epidemiological, 
treatment plan, and outcomes data.  We propose to 
formalize this extension phenomenon by 
treating it as a generalization of 
multi-application protocols already evidenced by 
tools such as \CaPTk{} and analyzable in 
terms of Procedural Application 
Ontologies.\footnote{It should be noted that other 
software platforms --- such as Paraview, in the context of 
data visualization, and CERN ROOT, in the context 
of nuclear physics, have related extension 
mechanisms that can also be analyzed as further 
details for a general-purpose model of multi-native-application 
networking.}}

\p{Radiological data repositories may be 
developed in part to improve image-analysis 
in general --- certain image sets can provide a 
\q{standard corpus} with which to compare 
different analytic methods --- but a key 
goal of these repositories is also to 
cross-reference image analysis with 
clinical data and medical outcomes.  
For example, researchers may wish to 
devise algorithms for analyzing diagnostic 
images with which to guide subsequent 
clinical interventions: the ultimate goal is 
to automatically extract image data, given an 
image series (together with clinical information 
pertinent to the clinicians' decision to 
request radiological evaluation), which 
suggests that one or another treatment 
plan is more likely to produce positive 
outcomes for the patient.}
%}
%\p{Radiological data is intrinsically multi-modal, 
%because radiological findings typically 
%include image graphics as well as image 
%annotations, diagnostic codes, and a certain 
%amount of basic clinical data.  Recent 
%\q{comparative effectiveness} initiatives have 
%attempted to expand the scope of radiological 
%data by incorporating more, and more detailed, 
%clinical information.  These initiatives imply 
%that radiological data will become increasingly 
%multi-modal in nature in the future, which 
%in turn will shape software that manages 
%radiological data such as the \RSNA{} Covid-19 
%repository.}
%\p{Any radiological analysis is connected to 
%a clinical context insofar as diagnostic 
%imaging has to be prescribed by a specific 
%doctor (or medical team), which means that 
%the patient examined is already situated 
%in a medical/institutional environment.  
%The diagnostic tests, and subsequent findings, 
%therefore can get absorbed into the larger 
%space of data which accrues to a patient 
%over the trajectory of their clinical history.  

\p{The manner in which both radiological and 
clinical software are structured, however, 
often makes it difficult to cross-reference 
radiological data with corresponding details describing 
patients' treatment protocols and medical 
outcomes once a radiological diagnosis has 
been performed.  For a concrete example (see 
\bhref{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5119276/pdf/nihms-822829.pdf}), 
\q{to retrieve the radiation treatment plan} 
associated with a \CT{} scan, one \q{has to search for the 
RTSTRUCT object based on the specific CT scan, and from there 
search for the RTPLAN object based on the RTSTRUCT object [which] is an inefficient operation because all RTSTRUCT [and] RTPLAN files for the patient need to be processed to find the correct treatment plan.}}

\p{Even within the context of analyzing radiological 
data sets for radiology-specific data, established 
\PACS{} software is not designed for large-scale query 
evaluation linked to clinical data.  As pointed out 
by the Semantic \DICOM{} documentation (see 
\bhref{https://semantic-dicom.com/starting-page/}), 
queries like \q{display all patients with a
bronchial carcinoma bigger than 50 cm$^3$} cannot 
be processed by \PACS{} systems: \q{although there are various powerful clinical applications to process image data and image data series to create significant clinical analyses, none of these analytic results can be merged with the clinical data of a single patient.  However, retrieving this data is an essential prerequisite to perform such search queries.}  
These inefficiencies limit researchers' ability to 
perform data mining which incorporates diagnostic 
images, and also to prepare well-integrated data 
sets for advancing diagnostic and Comparative Effectiveness 
research.}

\p{In a well-integrated research framework, treatment plans 
should be linked both to the diagnostic data which 
form the basis of the plan (including radiological images) and 
to reports of treatment outcomes.  As a concrete 
example, consider the choice to use \IORT{} 
(Intraoperative Radiation Therapy) as an alternative to 
conventional cancer treatments (see 
\bhref{https://www.cuimc.columbia.edu/news/new-cancer-treatment-personalized-radiation-therapy-during-cancer-surgery}).  
Researchers can ask two different questions related to the 
effectiveness of \IORT{}: (1) which diagnostic 
cues indicate that a given patient may benefit from 
\IORT{} in lieu of longer-term therapies; and 
(2) which treatment is more effective at 
promoting better survival rates.  These two lines 
of inquiry both require an integrated data-querying 
mechanism that recognizes data from image analysis, 
clinical outcomes, and descriptions of 
medical treatment; each of these kinds of 
data can be potentially 
included as a source of parameters with which to define 
patient cohorts or to search for statistical correlations.  
The relatively new \IORT{} treatment is an example of 
why integrated research is important --- oncologists 
still have limited understanding of which diagnostic 
clues are statistically associated with positive 
outcomes from \IORT{} as compared with conventional therapy.}

\p{In the context of Covid-19, which is an even newer research 
priority, initiatives such as the \RSNA{} repository are just 
beginning to aggregate radiological data in a manner which 
permits broad-scale analysis to be performed.  
Although radiological ontologies are primarily designed 
for use in laboratory software itself --- i.e., the 
programs radiologists use directly to derive and 
present their findings --- radiological research 
in general introduces further application domains, 
including software for image analysis, for 
integrating radiological and clinical data, and 
for examining radiological data sets.
This new data presents opportunities for the use of semantic 
annotation technology, including ontologies such 
as \SeDI{} or \ViSion{} (see \bhref{https://epos.myesr.org/esr/viewing/index.php?module=viewing_poster&task=&pi=155548}).}


\p{Insofar as \PACS{} and \DICOM{} systems need 
to be paired with applications in the other 
categories (such as image and data-set analysis), it is 
important to develop radiological Application Ontologies, 
alongside the canonical Reference Ontologies 
associated with diagnostic imaging.  As such, starting with 
the Covid-19 context, but designed for more 
general applications as well, one component of \CRtwo{} 
is a novel radiology-focused \textit{application} 
ontology, specifically what LTS calls the \q{Hypergraph Ontology 
for Diagnostic Imaging, Clinical 
Outcomes, and Data Mining} (\HDICOM{}).  The goal 
of \HDICOM{} is to connect \RDF{}-based 
radiological ontologies with software applications 
designed to manipulate radiological (and corresponding 
treatment and outcomes) data.  
%Using the more 
%expressive Hypergraph Ontology framework, developers 
%via \HDICOM{} can model how software objects 
%are connected to classes and properties standardized 
%within vocabularies such as \RadLex{}.  
In addition, \HDICOM{} will formalize 
the data-sharing protocols implicitly adopted 
by software aggregates such as \CaPTk{}.}

%\p{In the context of data mining, there are different 
%operations which belong to a data-mining pipeline, 
%distinctions which are appropriate to make within an 
%Application Ontology.  For example, we can distinguish 
%between \textit{integrative} data mining (merging 
%heterogeneous data into a common representation so as 
%to enlarge the available search space), 
%\textit{selective} data mining (filtering a large data 
%space to select a smaller aggregate that can be 
%directly managed by a specific application; e.g., a 
%patient cohort),  
%\textit{holistic} data mining (large-scale analysis 
%to uncover statistical patterns or correlations), 
%and \textit{investigative} data mining (executing 
%multi-parameter queries against a large, heterogeneous, 
%and/or multi-modal data space).
%}

\p{Within data mining and image analysis, hypergraph 
models are used in different ways for different 
algorithms.  In the context of Covid-19 radiology, 
\bhref{https://arxiv.org/pdf/2005.04043.pdf} 
describes an algorithm for assessing the probability 
of SARS-CoV-2 infection from chest \CT{} scans, 
where hypernodes represent high-dimensional 
vectors (191 dimensions overall) and hyperedges 
represent k-nearest-neighbors; here each hypernode 
represents an entire image, mapped to a 191-dimensional 
feature-vector.  In contrast, other image-analysis 
methods use hypernodes to designate smaller segments 
\textit{within} the image, where hyperedges 
designate geometric adjacency and/or feature-space 
similarities.  Whatever the algorithm, hypergraph 
analyses would employ a hypergraph library 
to store preliminary data for analysis and/or for 
serialization within a data set.  One benefit of a 
Hypergraph Application Ontology is therefore that 
these data structures used internally to implement 
analytic methods can be directly expressed within 
the ontology, whereas \RDF{} ontologies can only 
model hypergraphs indirectly.}

%\p{}

