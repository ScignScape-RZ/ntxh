\documentclass[10pt,letterpaper]{article}

\usepackage{eso-pic}

\AddToShipoutPictureBG{%

\ifnum\value{page}>0{
\AtTextUpperLeft{
\makebox[18.5cm][r]{
\raisebox{-2.3cm}{%
{\transparent{0.3}{\includegraphics[width=0.29\textwidth]{e-logo.png}}	}} } }
}\fi
}

\AddToShipoutPicture{%
{
 {\color{blGreen!70!red}\transparent{0.9}{\put(0,0){\rule{.55cm}{\paperheight}}}}%
 {\color{darkRed!70!purple}\transparent{1}\put(6,0){{\rule{.3cm}{\paperheight}}}}
% {\color{logoPeach!80!cyan}\transparent{0.5}{\put(0,700){\rule{1cm}{.6cm}}}}%
% {\color{darkRed!60!cyan}\transparent{0.7}\put(0,706){{\rule{1cm}{.6cm}}}}
% \put(18,726){\thepage}
% \transparent{0.8}
}
}



\AddToShipoutPicture{%

\ifnum\value{page}>0


{\color{blGreen!70!red}\transparent{0.9}{\put(300,8){\rule{0.5\paperwidth}{.3cm}}}}%
{\color{inOne}\transparent{0.8}{\put(300,10){\rule{0.5\paperwidth}{.3cm}}}}%
{\color{inTwo}\transparent{0.3}\put(300,13){{\rule{0.5\paperwidth}{.3cm}}}}

\put(301,16){%
\transparent{0.7}{
\includegraphics[width=0.2\textwidth]{logo.png}} }

{\color{blGreen!70!red}\transparent{0.9}{\put(5.6,5){\rule{0.5\paperwidth}{.4cm}}}}%
{\color{inOne}\transparent{1}{\put(5.6,10){\rule{0.5\paperwidth}{.4cm}}}}%
{\color{inTwo}\transparent{0.3}\put(5.6,15){{\rule{0.5\paperwidth}{.4cm}}}}

\fi
}

%\pagestyle{empty} % no page number
%\parskip 7.2pt    % space between paragraphs
%\parindent 12pt   % indent for new paragraph
%\textwidth 4.5in  % width of text
%\columnsep 0.8in  % separation between columns

\setlength{\footskip}{23pt}

\usepackage[paperheight=14.75in,paperwidth=9.5in]{geometry}
\geometry{left=.9in,top=.8in,right=.7in,bottom=1.5in} %margins

\newcommand{\sectsp}{\vspace{12pt}}

\usepackage{graphicx}
\usepackage{color,framed}

\usepackage{float}

\usepackage{mdframed}


\usepackage{setspace}
\newcommand{\rpdfNotice}[1]{\begin{onehalfspacing}{

\Large #1

}\end{onehalfspacing}}

\usepackage{xcolor}

\usepackage[hyphenbreaks]{breakurl}
\usepackage[hyphens]{url}

\usepackage{hyperref}
\newcommand{\rpdfLink}[1]{\href{#1}{\small{#1}}}
\newcommand{\dblHref}[1]{\href{#1}{\small{\burl{#1}}}}
\newcommand{\browseHref}[2]{\href{#1}{\Large #2}}

\hypersetup{
    colorlinks=true,
    linkcolor=cyan,
    filecolor=magenta,
    urlcolor=blue,
}

\urlstyle{same}

\definecolor{blGreen}{rgb}{.2,.7,.3}
\definecolor{darkRed}{rgb}{.2,.0,.1}

\definecolor{darkBlGreen}{rgb}{.1,.3,.2}

\definecolor{oldBlColor}{rgb}{.2,.7,.3}

\definecolor{blColor}{rgb}{.1,.3,.2}

\definecolor{elColor}{rgb}{.2,.1,0}
\definecolor{flColor}{rgb}{0.7,0.3,0.3}

\definecolor{logoOrange}{RGB}{108, 18, 30}
\definecolor{logoGreen}{RGB}{85, 153, 89}
\definecolor{logoPurple}{RGB}{200, 208, 30}

\definecolor{logoBlue}{RGB}{4, 2, 25}
\definecolor{logoPeach}{RGB}{255, 159, 102}
\definecolor{logoCyan}{RGB}{66, 206, 244}
\definecolor{logoRed}{rgb}{.3,0,0}

\definecolor{inOne}{rgb}{0.122, 0.435, 0.698}% Rule colour
\definecolor{inTwo}{rgb}{0.122, 0.698, 0.435}% Rule colour

\definecolor{outOne}{rgb}{0.435, 0.698, 0.122}% Rule colour
\definecolor{outTwo}{rgb}{0.698, 0.435, 0.122}% Rule colour

\usepackage[many]{tcolorbox}% http://ctan.org/pkg/tcolorbox

\usepackage{transparent}

\newenvironment{cframed}{\begin{mdframed}[linecolor=logoPeach,linewidth=0.4mm]}{\end{mdframed}}

\newenvironment{ccframed}{\begin{mdframed}[backgroundcolor=logoGreen!5,linecolor=logoCyan!50!black,linewidth=0.4mm]}{\end{mdframed}}

\usepackage{aurical}
\usepackage[T1]{fontenc}

\usepackage{relsize}

\newcommand{\pseudoIndent}{

\vspace{1pt}\hspace{8pt}}

\newcommand{\YPDFI}{{\fontfamily{fvs}\selectfont YPDF-Interactive}}

%
\newcommand{\deconum}[1]{{\protect\raisebox{-1pt}{{\LARGE #1}}}}



\newcommand{\VersatileUX}{{\color{red!85!black}{\Fontauri Versatile}}%
{{\fontfamily{qhv}\selectfont\smaller UX}}}

\newcommand{\NDPCloud}{{\color{red!15!black}%
{\fontfamily{qhv}\selectfont {\smaller NDP C{\smaller LOUD}}}}}

\newcommand{\lfNDPCloud}{{\color{red!15!black}%
{\fontfamily{qhv}\selectfont N{\smaller DP C{\smaller LOUD}}}}}

\newcommand{\textds}[1]{{\fontfamily{lmdh}\selectfont{%
\raisebox{-1pt}{#1}}}}

\newcommand{\dsC}{{\textds{ds}{\fontfamily{qhv}\selectfont \raisebox{-1pt}
{\color{red!15!black}{C}}}}}

\newcommand{\HTXN}{\resizebox{!}{8pt}{\AcronymText{HTXN}}}
\newcommand{\lHTXN}{\resizebox{!}{8.5pt}{\AcronymText{HTXN}}}

\newcommand{\DTD}{\resizebox{!}{8pt}{\AcronymText{DTD}}}

\newcommand{\QGIS}{\resizebox{!}{8.5pt}{\AcronymText{QGIS}}}

\newcommand{\CSML}{\resizebox{!}{8.5pt}{\AcronymText{CSML}}}

\newcommand{\lMOSAIC}{\resizebox{!}{8.5pt}{\AcronymText{MOSAIC}}}

\newcommand{\XML}{\resizebox{!}{8pt}{\AcronymText{XML}}}
\newcommand{\RDF}{\resizebox{!}{8pt}{\AcronymText{RDF}}}

\newcommand{\JSON}{\resizebox{!}{8pt}{\AcronymText{JSON}}}

\newcommand{\lsIT}{\resizebox{!}{9.5pt}{\AcronymText{IT}}}

\newcommand{\CLang}{\resizebox{!}{8pt}{\AcronymText{C}}}

\newcommand{\HNaN}{\resizebox{!}{8pt}{\AcronymText{HN%
\textsc{a}N}}}


\newcommand{\MeshLab}{\resizebox{!}{8pt}{\AcronymText{MeshLab}}}
\newcommand{\IQmol}{\resizebox{!}{8pt}{\AcronymText{IQmol}}}

\newcommand{\GUI}{\resizebox{!}{8pt}{\AcronymText{GUI}}}

\newcommand{\OS}{\resizebox{!}{8.5pt}{\AcronymText{OS}}}

\newcommand{\lHGDM}{\resizebox{!}{8.5pt}{\AcronymText{HGDM}}}
\newcommand{\lsHGDM}{\resizebox{!}{9.5pt}{\AcronymText{HGDM}}}

\newcommand{\lsHTXN}{\resizebox{!}{9.5pt}{\AcronymText{HTXN}}}

\newcommand{\lsXML}{\resizebox{!}{9.5pt}{\AcronymText{HTXN}}}

\newcommand{\API}{\resizebox{!}{8pt}{\AcronymText{API}}}

\newcommand{\NGML}{\resizebox{!}{8pt}{\AcronymText{NGML}}}
%\newcommand{\RDF}{\resizebox{!}{8pt}{\AcronymText{RDF}}}

\newcommand{\IDE}{\resizebox{!}{8pt}{\AcronymText{IDE}}}

\newcommand{\ThreeD}{\resizebox{!}{8pt}{\AcronymText{3D}}}

\newcommand{\FAIR}{\resizebox{!}{8pt}{\AcronymText{FAIR}}}

\newcommand{\UI}{\resizebox{!}{8pt}{\AcronymText{UI}}}
%\newcommand{\NDPCloud}{\resizebox{!}{8pt}{%
%\AcronymText{NDP-Cloud}}}

%\newcommand{\lNDPCloud}{\resizebox{!}{8.5pt}{%
%\AcronymText{NDP-Cloud}}}

\newcommand{\lNDPCloud}{\lfNDPCloud}


\newcommand{\QNetworkManager}{\resizebox{!}{8pt}{\AcronymText{QNetworkManager}}}
\newcommand{\QTextDocument}{\resizebox{!}{8pt}{\AcronymText{QTextDocument}}}
\newcommand{\QWebEngineView}{\resizebox{!}{8pt}{\AcronymText{QWebEngineView}}}
\newcommand{\HTTP}{\resizebox{!}{8pt}{\AcronymText{HTTP}}}


\newcommand{\lAcronymTextNC}[2]{{\fontfamily{fvs}\selectfont {\Large{#1}}{\large{#2}}}}

\newcommand{\AcronymTextNC}[1]{{\fontfamily{fvs}\selectfont {\large #1}}}

\newcommand{\lunvs}{\vspace{2.25em}}
\newcommand{\lunvsa}{\vspace{.5em}}

\colorlet{orr}{orange!60!red}

\newcommand{\textscc}[1]{{\color{orr!35!black}{{%
						\fontfamily{Cabin-TLF}\fontseries{b}\selectfont{\textsc{\scriptsize{#1}}}}}}}


\newcommand{\textsccserif}[1]{{\color{orr!35!black}{{%
				\scriptsize{\textbf{#1}}}}}}


\newcommand{\AcronymText}[1]{{\textscc{#1}}}

\newcommand{\AcronymTextser}[1]{{\textsccserif{#1}}}


\newcommand{\mAcronymText}[1]{{\textscc{\normalsize{#1}}}}

\newcommand{\NAThree}{\resizebox{!}{8pt}{\AcronymText{NA3}}}
\newcommand{\NCN}{\resizebox{!}{8pt}{\AcronymText{NCN}}}
\newcommand{\AThreeR}{\resizebox{!}{8pt}{\AcronymText{A3R}}}

\newcommand{\KDE}{\resizebox{!}{8.5pt}{\AcronymText{KDE}}}
\newcommand{\MFC}{\resizebox{!}{8.5pt}{\AcronymText{MFC}}}

\newcommand{\HGDM}{\resizebox{!}{8pt}{\AcronymText{HGDM}}}

\newcommand{\lQt}{\resizebox{!}{10.5pt}{\AcronymText{Qt}}}

\newcommand{\lNCN}{\resizebox{!}{9pt}{\AcronymText{NCN}}}
\newcommand{\lAThreeR}{\resizebox{!}{9pt}{\AcronymText{A3R}}}
\newcommand{\lNAThree}{\resizebox{!}{9pt}{\AcronymText{NA3}}}

\newcommand{\lsNCN}{\resizebox{!}{10.5pt}{\AcronymText{NCN}}}
\newcommand{\lsAThreeR}{\resizebox{!}{10.5pt}{\AcronymText{A3R}}}
\newcommand{\lsNAThree}{\resizebox{!}{10.5pt}{\AcronymText{NA3}}}

%\newcommand{\NGML}{\resizebox{!}{8pt}{\AcronymText{NGML}}}

\newcommand{\Cpp}{\resizebox{!}{8.5pt}{\AcronymText{C++}}}

\newcommand{\WhiteDB}{\resizebox{!}{8pt}{\AcronymText{WhiteDB}}}

\colorlet{drp}{darkRed!70!purple}

%\newcommand{\MOSAIC}{{\color{drp}{\AcronymTextNC{\scriptsize{MOSAIC}}}}}

\newcommand{\MOSAIC}{\resizebox{!}{8pt}{\AcronymText{MOSAIC}}}


\newcommand{\mMOSAIC}{{\color{drp}{\AcronymTextNC{\normalsize{MOSAIC}}}}}

\newcommand{\MOSAICVM}{\mMOSAIC-\mAcronymText{VM}}

\newcommand{\sMOSAICVM}{\resizebox{!}{8pt}{\MOSAICVM}}
\newcommand{\sMOSAIC}{\resizebox{!}{8pt}{\MOSAIC}}


%\newcommand{\lMOSAIC}{{\color{drp}{\lAcronymTextNC{M}{OSAIC}}}}
\newcommand{\lfMOSAIC}{\resizebox{!}{9pt}{{\color{drp}{\lAcronymTextNC{M}{OSAIC}}}}}

\newcommand{\Mosaic}{\resizebox{!}{8pt}{\MOSAIC}}
\newcommand{\MosaicPortal}{{\color{drp}{\AcronymTextNC{MOSAIC Portal}}}}

\newcommand{\RnD}{\resizebox{!}{7.5pt}{\AcronymText{R\&D}}}
\newcommand{\QtCpp}{\resizebox{!}{8.5pt}{\AcronymText{Qt/C++}}}
\newcommand{\Qt}{\resizebox{!}{9pt}{\AcronymText{Qt}}}
\newcommand{\SQL}{\resizebox{!}{8pt}{\AcronymText{SQL}}}

\newcommand{\CoNLLU}{\resizebox{!}{8pt}{\AcronymText{CoNLL-U}}}



\newcommand{\HTML}{\resizebox{!}{8pt}{\AcronymText{HTML}}}
\newcommand{\PDF}{\resizebox{!}{8pt}{\AcronymText{PDF}}}

%\newcommand{\HTXN}{\resizebox{!}{8pt}{\AcronymText{HTXN}}}
%\newcommand{\lHTXN}{\resizebox{!}{8.5pt}{\AcronymText{HTXN}}}

\newcommand{\p}{

\vspace{.75em}}

\newcommand{\q}[1]{{\fontfamily{qcr}\selectfont ``}#1{\fontfamily{qcr}\selectfont ''}} 

%\newcommand{\deconum}[1]{{\textcircled{#1}}}


\renewcommand{\thesection}{\protect\mbox{\deconum{\Roman{section}}}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\newcommand{\llMOSAIC}{\mbox{{\LARGE MOSAIC}}}
%\newcommand{\lfMOSAIC}{\mbox{M\small{OSAIC}}}

\newcommand{\llMosaic}{\llMOSAIC}
\newcommand{\lMosaic}{\lMOSAIC}
\newcommand{\lfMosaic}{\lfMOSAIC}


\newcommand{\llWC}{\mbox{{\LARGE WhiteCharmDB}}}

\newcommand{\llwh}{\mbox{{\LARGE White}}}
\newcommand{\llch}{\mbox{{\LARGE CharmDB}}}

\usepackage{enumitem}

\setlist[description]{%
  topsep=30pt,               % space before start / after end of list
  itemsep=5pt,               % space between items
  font={\bfseries\sffamily}, % set the label font
%  font={\bfseries\sffamily\color{red}}, % if colour is needed
}

\setlist[enumerate]{%
  topsep=3pt,               % space before start / after end of list
  itemsep=-2pt,               % space between items
  font={\bfseries\sffamily}, % set the label font
%  font={\bfseries\sffamily\color{red}}, % if colour is needed
}

%\usepackage{tcolorbox}

\newcommand{\slead}[1]{%
\noindent{\raisebox{2pt}{\relscale{1.15}{{{%
\fcolorbox{logoCyan!50!black}{logoGreen!5}{#1}
}}}}}\hspace{.5em}}


\let\OldLaTeX\LaTeX

\renewcommand{\LaTeX}{\resizebox{!}{8pt}{\color{orr!35!black}{\OldLaTeX}}}

\newcommand{\LargeLaTeX}{\resizebox{!}{8.5pt}{\color{orr!35!black}{\OldLaTeX}}}


\setlength\parindent{40pt}
%\input{commands}



%\newcommand{\lun}[1]{\parbox{9in}{{{\fontfamily{qcr}\selectfont{%
%\LARGE{\textbf{\raggedleft #1}}}}}}}

\usepackage[official]{eurosym}

\newcommand{\lun}[1]{{\fontfamily{qcr}\selectfont{\LARGE{\textbf{#1}}}}}


\begin{document}
	
{\linespread{1.1}\selectfont

\vspace*{-5em}

\begin{center}
%{\relscale{1.2}{\fontfamily{qcr}\fontseries{b}\selectfont 
%{\colorbox{black}{\color{blue}{\llWC{} Database Engine \\and 
%\llMOSAIC{} Native Application Toolkit}}}}}

\colorlet{ctmp}{logoPeach!20!gray}
\colorlet{ctmpp}{ctmp!90!yellow}
\colorlet{ctmppp}{ctmpp!50!black}
\colorlet{ctmpppp}{ctmppp!90!logoRed}

\vspace{1em}

%{\colorbox{darkBlGreen!30!darkRed}{%
\begin{tcolorbox}
[
%%enhanced,
%%frame hidden,
%interior hidden
arc=2pt,outer arc=0pt,
enhanced jigsaw,
width=.7\textwidth,
colback=ctmpppp!60,
colframe=logoRed!30!darkRed,
drop shadow=logoPurple!50!darkRed,
%boxsep=0pt,
%left=0pt,
%right=0pt,
%top=2pt,
]
\begin{minipage}{\textwidth}	
\begin{center}		
{\setlength{\fboxsep}{18pt}
	\relscale{1.4}{{\fontfamily{qcr}\fontseries{b}\selectfont%
{NCN/A3R Native Application Framework
\\\vspace{.5em}

 \large{(\q{Native-Cloud/Native} 
 	services and \q{Application-as-a-Resource})}}}}}
\end{center}
\end{minipage}
\end{tcolorbox}
\end{center}

\vspace{-1em}

%\noindent\lun{Overview}
\fontfamily{ptm}\fontsize{13pt}{18pt}\selectfont
{\sectsp}
\p{\NCN{}/\AThreeR{} (hereafter \NAThree{}) is a \Qt{}-based 
application-development framework which prioritizes 
hybrid solutions combining cloud and desktop/native 
components.  The \NCN{} (Native-Cloud/Native) 
model refers to desktop client applications that 
are integrated with Cloud/Native back-ends; 
by sharing code libraries and data formats across 
both end-points, \NCN{} solutions are more streamlined 
than native front-ends with generic back-ends, or 
Cloud/Native back-ends with web-application clients.  
The \AThreeR{} (Application-as-a-Resource) model promotes 
self-contained, downloadable applications that can 
be distributed in source-code fashion and compiled 
with few (if any) non-\Qt{} dependencies.  The 
combined \NAThree{} framework yields a 
comprehensive application-development toolkit 
with numerous components to streamline the 
implementation of \Qt{} applications 
(\NAThree{} can also be used as a template 
for implementations based on frameworks other 
than \Qt{}, such as wxWidgets or 
Operating-System-specific options).           
}

{\lunvs}
\noindent\lun{The Current Status of \lQt{} Cloud Integration}
{\lunvsa}
\p{There has been considerable demand in the native-application sector for a systematized Cloud Services model designed to interoperate with cross-platform native applications.  Cloud/Native components can augment the functionality of native/desktop software by providing remote storage for user data; enabling users to share content for collaborative work; maintaining domain-specific repositories (i.e., spaces of resources whose format is specialized so that only select applications can access them properly); and upgrading or extending applications without re-install.  
We use the term \q{Native-Cloud/Native} to describe hybrid applications whose server and client endpoints are both internally native -- in contrast to conventional Cloud/Native where native servers are paired with (potentially) non-native clients. 
}

\p{Cloud/Native support in existing cross-platform native-application frameworks is fairly primitive.  Since \Qt{} is by far the most widely-used such framework, the \Qt{} case is instructive.  In 2013 (following an earlier beta phase) the \Qt{} company introduced \q{\Qt{} Cloud Services}, which provided a convenient, \Qt{}-aware cloud-hosting platform for \Qt{} accounts (in the company's words: \q{\lQt{} Cloud Beta has solved an immense need for \Qt{} developers when it comes to backend-as-a-service and believe that there is an even greater need to provide the \Qt{} ecosystem with an all-in-one \Qt{} solution for cloud computing}).  However --- to the consternation of the \Qt{} community --- this project was discontinued several years later (retroactively we can identify some design flaws which might have hindered the project).  Meanwhile, OpenShift discontinued their free-tier Cloud/Native hosting last year, and another company with Cloud/Native options, Arukas, is folding at the end of this month.  This means that \Qt{} developers have limited options even for hosting hand-rolled \Qt{} cloud solutions (which can be done by compiling \Qt{} into a Ubuntu container)
}

\p{Considering the prominence of both \Qt{} and Cloud/Native technologies in the contemporary computing landscape, it is disconcerting that no standard framework or hosting service provides a cloud platform which works with \Qt{} \q{out-of-the-box.}  The existence of such a platform would be a boon to software in sectors like scientific computing, bioinformatics, bioimaging, pharmaceuticals, academic publishing, and other fields where (due to complex \GUI{} and/or data-analytic requirements) the software is predominantly native-compiled and desktop-oriented.}
 
\p{Of course, many desktop applications have some web integration, but the current architecture forces the client-facing and web-facing components of the application to be almost completely separate, which adds to development time and expense.  Moreover, current native-application environments do not fully leverage Cloud/Native services; they may well be implemented via more old-fashioned non-cloud servers.  The great possibility of a \q{Native-Cloud/Native} approach is a peer-to-peer client-server relationship, sharing libraries and data formats on both ends; and the infrastructure to bring the benefits of Cloud Computing (e.g. faster development and deployment, and less expensive hosting, as compared to non-cloud web services) to the native-application ecosystem.}

{\lunvs}
\noindent\lun{Native Cloud/Native in the Context of \lsNAThree{}}
{\lunvsa}
\p{In light of the Cloud/Native limitations just identified, 
LTS (Linguistic Technology Systems) intends to contribute 
tools or hosting arrangements that would bring 
some of the capabilities of \Qt{} Cloud Services 
back to the market.  The simplest commercial model for 
such a product is to license a containerized 
\Qt{}-based \HTTP{} server that can run as a local 
application during testing and development, 
before being deployed to a container hosting service.  
We have implemented a prototype server along these lines 
that we call \NDPCloud{} (for \q{Native-Driven Platform on the Cloud}).  
\lNDPCloud{} is fully self-contained in a \Qt{} context 
(it bundles portions of the Node.js code base and 
utilizes the \Qt{} network module, so it requires no 
external \HTTP{} or sockets libraries).  One significant 
benefit of \NDPCloud{} is that it is fully transparent: 
all of the code for parsing and routing \HTTP{} 
requests can be loaded into \IDE{}s (such as \Qt{} creator)
and examined by the debugger.  Another benefit is that 
project-specific libraries can be compiled into both 
\NDPCloud{} instances and client front-ends; therefore, 
clients and servers can share procedures for serializing 
and deserializing domain-specific data structures.  
For development and prototyping, \NDPCloud{} 
can be launched as an ordinary (non-virtual) 
Operating System process, which can receive 
requests via \HTTP{} but also via sockets, or 
the command line (allowing request-management 
logic to be tested in abstraction from the 
\HTTP{} layer).  Further testing can then be performed 
running \NDPCloud{} as a local Docker container, 
before eventually deploying the application to 
a remote Docker hosting environment. 
}

\p{Via \NDPCloud{}, \NCN{} applications can be 
deployed on any Docker cloud service, 
such as OpenShift.  In this guise LTS has 
no direct involvement with the hosting service 
(although \NDPCloud{} includes some tools 
to streamline cloud deployment).  Ideally, 
however, LTS would like to secure its own 
hosting capabilities, perhaps by using an 
LTS-specific container deployed on OpenShift 
or a similar platform.  LTS would allocate 
cloud assets to \NDPCloud{} licensees 
(e.g. a limited free-tier hosting plan) 
for testing and development.  A further 
possibility is to provide free 
hosting, subject to data-space constraints, 
to scientific institutions.  The dwindling 
availability of free-tier Cloud/Native options 
is a hindrance to projects' adoption of 
Cloud/Native solutions for sharing and 
disseminating scientific data; this can 
result in researchers hosting data sets on 
platforms such as Mendeley or DataVerse, 
which have limited functionality or 
customizability compared to Cloud/Native 
containers.  Use-cases for \NAThree{} in 
the context of scientific data sets are explained in 
the discussion of \AThreeR{} below.}

{\lunvs}
\noindent\lun{Application Development via \lsAThreeR{}}
{\lunvsa}
\p{The \AThreeR{} model facilitates implementation of 
standalone native applications, whose data models and 
\UI{} logistics are described via integrated metadata.
As much as possible, \AThreeR{} applications 
are entirely self-contained, so that all application 
code and data can be packaged into single 
downloadable resource.  In a \Qt{} environment, 
\Qt{} modules are available for concerns such 
as networking, database management, \Cpp{} reflection, 
\XML{} or \JSON{} parsing/querying, 
and embedded web viewers, so that 
\AThreeR{} can leverage these capabilities without 
requiring separate library installs.  For many use-cases, 
then, an entire desktop application can be deployed 
in source-code form, to be compiled and launched 
via a single click within \Qt{} creator.  
Self-contained in this manner, \AThreeR{} 
applications can be treated as single 
resource units --- somewhat analogous 
to container images, but achieving their 
autonomy by leveraging the \Qt{} ecosystem 
rather than by virtualization.  
}

\p{\lAThreeR{} applications are also autonomous resources 
by virtue of detailed metadata bundled with application code.  
This metadata provides a summary of application-specific 
data models, capabilities, \UI{} features, and 
user documentation.  The metadata may be accessed 
by human users or by automated tools to help 
users become familiar with a 
newly-acquired \AThreeR{} resource.}

\p{The \AThreeR{} architecture is especially 
warranted when applications are designed to 
work with one or several non-standardized, 
domain-specific data formats (including those 
unique to an individual data set).  In these 
scenarios, \AThreeR{} applications provide 
both libraries for parsing and manipulating 
the domain-specific formats and a \q{reference 
implementation} documenting the proper 
visualization and User Experience optimal 
for the unique data structures involved.  
This structural profiling is advanced not 
only by domain-specific \GUI{} components 
implemented within \AThreeR{} applications, 
but also by \AThreeR{} metadata which 
describes application-specific data types, 
and declares interface requirements for
any software components targeting 
such data types.}

\p{The \lAThreeR{} toolkit includes numerous 
components which may be useful to programmers 
implementing cross-platform, desktop-style 
applications, including a library 
for in-memory hypergraph-structured data, 
a built-in database engine for persistent data, 
a parsing and grammar library, and a foundation 
for building customized scripting languages.  
These components have no external requirements 
and are distributed as raw \Cpp{} files 
that could be dropped in to any \Qt{}/\Cpp{} 
project.  As with \NDPCloud{} on the 
server side, these components are therefore 
\q{transparent}: their code is directly 
bundled with application sources, and may 
be clearly examined in a debugging session.  
This is in contrast to typical libraries 
providing application-development features 
such as database engines or code parsers, 
which typically require separate installation 
(often with separate build tools) and are 
opaque to the debugger.  Another benefit 
of using internal \AThreeR{} components is 
that they can be simultaneously compiled 
into \NCN{} instances developed alongside them.  
With that said, developers could certainly 
use non-\AThreeR{} components in modular 
fashion (e.g., \Qt{}'s \SQL{}-based 
data persistence features) to replace their \AThreeR{} 
equivalents (either initially or after an 
\AThreeR{}-standalone protyping phase).}

\p{While \NCN{} applications need not use \AThreeR{}, 
or vice-versa, the two models are organically 
paired together.  Their integration can take the form of 
\NCN{} servers hosting \AThreeR{} applications 
as resources, and/or \AThreeR{} software 
connecting to \NCN{} instances as a domain-specific 
cloud back-end.  The \AThreeR{} metadata 
paradigm, based on \q{Hypergraph Ontologies}, 
provides tools to streamline the encoding and 
distribution of application-specific data structures.  
This model thereby accelerates the process of 
implementing cloud services procedurally 
aligned with \AThreeR{} components, because 
complementary \AThreeR{} and \NCN{} endpoints 
can share the same information representations.  
Moreover, \AThreeR{} interface definitions 
can serve as references for implementing 
compatible \NCN{} server-side code; 
the interface specification illustrates which 
client-side procedures will handle any 
server-originating data structures, so the 
server-side data providers can be constructed 
accordingly.
}

{\lunvs}
\noindent\lun{Hypergraph Data Modeling and Requirements Engineering}
{\lunvsa}
\p{\AThreeR{} uses a so-called \q{Hypergraph Data Modeling Protocol} 
(\HGDM{}) to describe and serialize application data.  Hypergraphs are a 
flexible and expressive representation mechanism; this permits data to 
be marshaled with less boilerplate code than would be needed for 
more restrictive formats such as \SQL{} or \RDF{}.}

\p{\lHGDM{}'s expressiveness is further enhanced by the introduction of 
a structuring element called \q{channels}, which are aggregates of 
edges (by analogy to hypernodes being aggregates of nodes).  Channels 
in this sense are a mechanism not previously developed in Hypergraph 
databases or libraries (channels aggregate edges --- most 
often edges that are each incident to one hypernode --- without 
likewise grouping their other vertices; in this sense 
channels are distinct from hypernodes, which collapse edges into a single 
hyperedge).  The theoretical basis for channels is discussed in 
Chapter Three of \textit{Advances in Ubiquitous Computing, 
Cyber-Physical Systems, Smart Cities and Ecological Monitoring} 
(previewed \href{https://www.elsevier.com/books/advances-in-ubiquitous-computing/neustein/978-0-12-816801-1}{here}).  Channels are particularly useful when modeling procedure 
types, leading to a version of type theory formalized in a 
Hypergraph context (see \textit{Advances in Ubiquitous Computing}, page 94).  
In \AThreeR{}, channel notations can be employed to identify procedure 
types; similar notation is then used for an Interface Definition 
Language, describing interrelated groups of procedures with 
their corresponding types.}

\p{Aside from streamlining data serialization and deserialization, 
an arguably more substantial benefit of expressive data models 
(such as via Hypergraphs) concerns how precise data models 
document coding assumptions and requirements, which promotes 
the long-term maintenance of an application.  \lAThreeR{} 
supports several Requirements Engineering features, including:

\begin{itemize}[itemsep=10pt,
	topsep=21pt,leftmargin=14pt]
\item Range-based numeric values, which prohibits data being constructed 
when it fails to lie within empirically meaningful ranges

\item The option to use Universal Numbers for non-integer values, in lieu 
of floating-point types.  (Universal Numbers are a mathematical representation developed 
by John Gustafson, which in many contexts are more precise than floats). 

\item An overall preference for employing application-specific data types instead 
of generic types like integers and strings.  Using types which expressly model 
a particular empirical phenomenon facilitates Requirements Engineering insofar as 
the custom type becomes a basic unit of asserting and verifying requirements.

\item A novel channel/hypergraph-based \Cpp{} reflection mechanism, which can be 
used in addition to or in place of \Qt{} meta-objects.  This in turn promotes 
scripting and testing for custom data types, so that types' testing and implementation 
can proceed in modular fashion, with requirements observed at the individual 
type level.

\item Leveraging \Qt{}'s model/view architecture to pair up application-specific 
data types with corresponding \GUI{} component types.  In general, 
documenting inter-type relations --- particularly the connections between 
data structures and their corresponding \GUI{} representations --- leads 
to rigorous application development and effective maintenance 
(see \textit{Advances in Ubiquitous Computing}, page 55).
\end{itemize}
\vspace{-1em}
}

\p{Hypergraph data models provide some of the same documentary 
benefits as Semantic Web Ontologies, only potentially more so, 
insofar as ordinary \q{Semantic} Ontologies have fewer resources 
to describe multi-tier structures (at least Ontologies in the 
conventional sense targeting single-tier graph structures, 
canonically those of \RDF{}).  The data and type representation 
architecture for \HGDM{} aims to develop an expressive, 
general-purpose type system which is naturally suited 
to data serialization and which is compatible with 
mainstream programming languages (we can provide 
more details about the space of type constructions 
recognized according to this system on request).  
In effect, almost any kind of function signature can be 
mapped to a corresponding \HGDM{}-modeled type 
(technically, to a \textit{channel complex}), 
and then used in an Interface Definition.  
Analogously, data structures which are instances of almost 
any type can be converted to a 
hypegraph structure, where they may be automatically serialized.}

%{\vspace{4em}}
{\lunvs}
\noindent\lun{Native Application Development in the Larger \lsIT{} Context}
{\lunvsa}
\p{While users have gravitated to web and phone applications for some 
day-to-day tasks (social networking, banking, e-commerce), desktop-style 
native software remains the preeminent front-end paradigm in 
sectors where complex, highly interactive \GUI{}s are needed: 
science, engineering, industrial design, architecture, 
biomedical, pharmaceutical, military, and so forth.  
\lQt{} is the most popular framework among companies 
who develop native \textit{cross-platform} software, as opposed 
to applications targeting a single Operating System.  
Supporting those developers, in turn, is a network of companies 
(many of them \Qt{} \q{partners}) implementing \GUI{} components, 
developer tools, \Qt{} Creator plugins, and other enhancements 
to the \Qt{} ecosystem.  On purely technical grounds, 
it is reasonable to say --- via its Cloud/Native, scripting, 
and data-modeling strategies --- that \NAThree{} can likewise be a 
significant addition to the \Qt{} ecosystem, assuming it is 
developed and stress-tested to production-grade maturity.}

\p{This document has focused on \NAThree{}'s 
default implementation via the \Qt{} platform, 
although  
it is worth adding that the unique technical 
innovations expressed via \NAThree{} have applications 
beyond the \Qt{} ecosystem.  In most cases, \Qt{} 
data types and protocols have corresponding 
equivalents in other application frameworks, 
both cross-platform and Operating-System-specific, 
such as wxWidgets (cross-platform), Xcode 
(Apple) or \MFC{} (Microsoft Foundation Classes).  
A reasonable estimate is that porting \NAThree{} 
to non-\Qt{} platforms would comprise a 
six-month project for a two- or three-person 
development team.  In order to stay focused on 
the near-term strategy for \NAThree{}, however, 
the remainder of this presentation will restrict 
attention to the \Qt{}-specific version.} 

\p{\lQt{} has approximately 
one million active developers, over 5,000 client 
companies, and tens of mullions of downloads of 
recent \Qt{} versions (metrics according to the 
\Qt{} Group).  These official figures may actually 
undercount the full \Qt{} market size; in particular, 
they do not appear to reflect open-source \Qt{} licenses 
(e.g., Linux software for the \KDE{}/Plasma environment).  
\lQt{} is used for many scientific computing 
applications, in numerous disciplines; a representative 
sample includes  
CERN ROOT (CERN's physics/subatomic analytics 
platform), IQmol (for chemistry/molecular physics), 
medInria (for radiology), TeXstudio (for \LaTeX{} processing), 
Mendeley Desktop (for Reference/Citation Management), \QGIS{} (for Geoinformatics), 
MeshLab (for \ThreeD{} modeling), 
OpenSCAD (for \ThreeD{} geometry), 
Octave (a MATLAB emulator), 
ParaView (for data visualization), 
and the \Qt{} Creator \IDE{} (Integrated Development Environment).  
Most of these applications would not be included 
in the \Qt{} company's official user metrics because 
they are maintained by academic or research 
institutions with an open-source \Qt{} license; 
nevertheless, institutions allocate resources 
for developing and maintaining technical applications.  
In sum, academic and Linux-oriented projects should 
be included in the commercial \Qt{} market, because 
organizations may contract for the implementation of 
\Qt{} software, even if the finished product will be 
released non-commercially.}

\p{A further consideration is that academic projects often 
split off to become commercial products; \Qt{} software 
used in academia may at some point be commercialized.  
This is not only a matter of software products themselves 
being marketed; it applies to any product (such as biomedical, 
military, Cyber-Physical, automotive, or industrial equipment) 
where \Qt{} software is essential to the operational or 
maintenance of the deployed product.  In these scenarios 
the software originally built in an open-source context 
for Research and Development then becomes an operational 
asset in a commercialized infrastructure.}      

\p{History suggests that most commercial 
software products generate revenue, in their 
early stages, primarily from customer-specific 
customizations, but then eventually derive 
their most valuable profit-stream from 
commercial licenses.  Special-license customizations 
help mold the product into a widely-usable standard 
version, given the natural feedback loop which emerges 
as the product's development team  
implements project-specific deployments, observing 
\q{in the field} which features are most useful and 
how these features are best made available to 
developers.  As a \q{standardized} version of the 
product rounds into shape, an increasing user-base 
who simply downloads and develops solutions with the 
standard version gradually overtakes, in terms of 
licensing revenue, the organizations who contract 
for customizations.}

\p{Taking the official \q{\Qt{} partners} cohort as a 
representative cross-section of the \Qt{} market, 
we can find companies whose revenue is driven 
by custom software development (ICS, Woboq, KDAB, Base2, 
Bitfactor, Sequality), by commercial licensing 
(Wind River, VNC Automotive, FrogLogic, NXP), 
by realtime and/or platform services (Mender, Timesys, Mapbox), 
as well as hardware/mircroprocessor providers (Toradex, ARM, 
Texas Instruments).  It is probably true that 
companies whose products depend in whole or 
in significant part on \Qt{} generate revenue from 
customization and consulting more than in other 
technology sectors.  This may reflect the position  
of front-end technology in relation to software in general: 
many software projects begin with new kinds of 
data or new user-interaction models, and only 
later address the need for implementing high-quality 
\GUI{}s.  
Given that desktop-style front-end development 
is a rather specialized subdiscipline, many 
companies end up hiring \Qt{}-focused companies 
as service contractors, which in turn supports a robust 
ecosystem of \Qt{} partner companies 
(data from sources such as 
Glassdoor suggest that larger \Qt{} consulting 
partners have revenues roughly comparable to 
\Qt{} itself, indicating that the worldwide 
\Qt{} consulting/contracting market falls in 
the US \$150-\$250 Million range; factoring 
commercial licenses, \Qt{}-enabled 
hardware, and \Qt{}-based software reasonably 
projects the overall \Qt{} market to roughly one-half 
billion US dollars).}

\p{This being said, financial records released by the 
\Qt{} company itself suggest that commercial 
(\q{Developer} and \q{Distribution}) licenses 
are \Qt{}'s largest revenues source (targets 
released in 2018 indicate that The \Qt{} Group Plc 
aims for 60\% revenue from licenses, 20\% from 
consulting, and 20\% for \q{support and maintenance}, 
which is an offshoot of developer licenses; 
total net revenue across these sources from 2018, 
the most recent figures available, was 
\euro{}45.6 Million, just over 
US \$57 Million at 2018 rates).}

\p{It is premature to estimate a comparable partonomy 
of revenue share for \NAThree{}, but we can 
identify four distinct profit streams appropriate for 
\NAThree{} as an integrated platform: 

\begin{enumerate}[itemsep=13pt,
	topsep=14pt,leftmargin=14pt]
\item \textbf{Customization} \hspace{.5em} Custom-implemented applications 
using project-specific versions of \NCN{} and/or \AThreeR{}.

\item \textbf{Licensing}  \hspace{.5em} Commercial licenses required for 
any deployment of \NCN{} outside LTS-controled 
servers and/or any deployment of \AThreeR{} 
applications (or of software including 
\AThreeR{} components for such 
development requirements as databases, data modeling, 
scripting, data serializing/deserialization, 
and text parsing) in a commercial context.

\item \textbf{Hosting}  \hspace{.5em} LTS anticipates running proprietary 
containers via a Cloud-Native service such as 
OpenShift, and then leasing access to this service 
to \NAThree{} users.  LTS can offer integrated hosting and consulting 
wherein LTS fully implements and maintains a back-end 
paired to any desktop/native client software.
Because the expertise involved 
in building native desktop applications is very different 
from the techniques required to deploy a Cloud-Native container 
image, the option of delegating all 
backend responsibilities to LTS may 
appeal to \Qt{}-oriented development teams.

\item \textbf{Sponsorship}  \hspace{.5em} As discussed below, LTS anticipates 
running a data-sharing platform which would be a 
publicly-visible introduction to LTS's in-house 
\NCN{} service (whereas other sub- or para-containers 
would be leased to third parties and provide 
publicly-visible content only at their discretion).  
This \q{demo} container, while being a vehicle for 
the general public to learn about \NAThree{}, 
would also host research data sets and 
would therefore be a resource in the public 
interest, allowing LTS to receive compensation 
from companies financially supporting the 
portal because of its merits as a technology 
benefitting science or scholarship.
\end{enumerate}

\vspace{-12pt}
\p{The remainder of this summary, to elaborate 
further on the hosting and sponsorship 
possibilities, will focus on cloud services 
expressly maintained by LTS (in contrast 
to commercial \NCN{} instances whose licensees 
host the \NCN{} code on their own).  In 
\NCN{} parlance, sub- or para-containers 
are units within a larger \NCN{} environment 
utilizing isolated \HTTP{} access protocols 
and data/file storage.  Each such partial container 
can be twinned with a specific \AThreeR{} 
application, providing a cloud end-point for 
storing application-specific data and/or sharing 
such data between different executable instances 
of the application.  Potentially, then, 
any \AThreeR{} project developed by LTS 
may have a corresponding presence on 
LTS's cloud resources.} 
     
\p{At the same time, the \AThreeR{} (Application-as-a-Resource) 
model also envisions desktop applications as 
self-contained, shareable units, which can 
be hosted on web servers (including \NCN{} instances) 
as zip and metadata files.  Therefore, LTS's 
\NCN{} deployment can serve as an access-point 
for users acquiring or obtaining information about 
\AThreeR{} applications (including data sets 
published as \q{Research Objects} using \AThreeR{} 
within their code base).}

{\lunvs}
\noindent\lun{The Hypergraph Text Encoding Protocol}
{\lunvsa}
\p{Correlated with \HGDM{}, which uses hypergraphs to model raw 
data, \AThreeR{} defines a Hypergraph Text Encoding Protocol 
(\HTXN{}) for natural-language text.  \lHTXN{} is 
relevant for \AThreeR{} applications when users wish to 
compose manuscripts (e.g., technical papers describing 
research findings) related to data managed by an \AThreeR{} application 
(although \HTXN{} can equally well be used as a general-purpose 
document-preparation tool, outside the \AThreeR{} context).  
The \HTXN{} parsers and document generators are designed to 
be embedded in a host application; if this host recognizes the 
\HTXN{} protocol, it is possible for \HTXN{} documents to include 
instructions which call procedures exposed by the host application 
(so as to insert application data into a manuscript, for example).  
In general, \HTXN{} is engineered to prioritize integrating 
and cross-referencing publications and data sets.} 

\p{The benefits of \HTXN{} include:
\vspace{-1.5em}
\begin{description}[leftmargin=13pt,
labelsep=15pt,itemsep=12pt]

\item[Mix-and-Match Formats] Once a document has been constructed 
in \HTXN{} --- this becomes the \q{primary} document --- 
a choice of \q{generators} is then available (or can be 
implemented) to produce
secondary documents, or \q{views}, in a 
variety of conventional formats (canonically \LaTeX{} and \XML{}). 
\lHTXN{} employs \q{stand-off} annotation, which allows multiple 
markup protocols to be defined simultaneously on the same 
document.  Accordingly, an \HTXN{} document may be prepared 
for eventually use by both \LaTeX{} and \XML{} generators, 
including \XML{} content (such as attributes) ignored 
by the \LaTeX{} generator, and vice-versa.  
In addition, \lHTXN{} uses a flexible 
character-encoding protocol that ensures 
compatibility with diverse text representations
(such as {\XML}, {\LaTeX}, Unicode, and {\Qt}/QString).  
Overall, then, \HTXN{} can be useful when it is 
necessary to employ different formats for a single 
manuscript at different stages of the publication workflow: 
for instance, \XML{} for editing and \LaTeX{} for \PDF{} generation.   

\item[Fine-Grained Character Encoding] The \HTXN{} 
protocol includes more detailed document structure 
information compared to conventional 
markup.  For example, \HTXN{} identifies 
sentence boundaries and punctuation features, 
disambiguating logically distinct 
but often visually identical 
characters (such as \makebox{dots/periods or dashes/hyphens, 
	which have different structural meanings in different contexts}).   

\item[A LaTeX-Compatible Document Object Model] 
\lHTXN{} files have a graph-based structure that 
can be searched and traversed similar to the \XML{} 
Document Object Model.  \lHTXN{}'s document model, 
however, is designed to represent most structural 
features of \LaTeX{} representation as well as \XML{}. 
Therefore, in conjunction with generating \LaTeX{} views 
on an \HTXN{} manuscript, \HTXN{} provides in effect a 
means to traverse \LaTeX{} documents via software 
(e.g., via \Cpp{} procedures).

\item[A Transparent and Extensible Parsing Model] 
\lHTXN{} is a text-encoding system, so it is impractical 
to compose documents in \HTXN{} directly.  Instead, \HTXN{} 
files need to be built from text sources in some other 
format (\NAThree{} has its own markup style, called 
\q{\NGML{}} for \q{Next-Generation Markup Language}, 
which outputs \HTXN{} and then \LaTeX{} or \XML{}).  
The \NGML{} parsers can be readily 
adapted and modified, so that projects can use a 
custom-built document language if desired.  The parsers 
and generators are also \q{transparent} in the sense 
that they are self-contained \Qt{}/\Cpp{} libraries that 
can be dropped into any \Cpp{} project which can link 
against the \Qt{} core (which also makes the components 
easy to examine through debugging sessions, when implementing 
alternative grammars or generators for customized 
markup languages targeting \HTXN{}). 

\item[\lsHTXN{} Plugins]
As a standalone library, \HTXN{} (along with a document-composition 
language such as \NGML{}) can be included in almost any 
application that is equipped to call procedures in \Qt{}/\Cpp{} 
libraries (obviously this includes scientific software 
written with \Qt{} to begin with).  Many scientific and technical 
applications have a built-in plugin or 
extension mechanism, which makes it possible to introduce \HTXN{} 
as an added feature; others are open-source projects where 
plugins can simply be inserted as new components in the source code.  
\lHTXN{} Plugins can then make \HTXN{} available to authors who 
regularly use the host application for their scientific or 
research work.
 

\item[Publisher-Specific \lsXML{}]
When generating \XML{} from \HTXN{} documents, applications 
can target a specific \DTD{} depending on the publisher 
to which a manuscript will be submitted.  The resulting 
\XML{} files can then be included alongside \LaTeX{} 
and \PDF{} in the documents sent to the publisher.  This 
benefits publishers in turn, because it eliminates the 
need for a separate conversion process; submitted manuscripts 
will already have a version which is compatible with the 
remainder of their publication workflow. 
\end{description}
\vspace{-1em}
}

\p{The option of validating \HTXN{}-generated \XML{} against 
publisher-specific \DTD{}s --- combined with \HTXN{} plugins 
to new or pre-existing scientific or technical applications 
--- opens up the possibility of \textit{publisher-specific} 
plugins, which can include \HTXN{} but also other 
features of the publisher's platform (such as access to 
\API{}s).  In effect, publisher-specific plugins serve 
as miniature \NAThree{} applications embedded in some 
other software.  Aside from practical document-preparation benefits, 
these plugins may also serve as a 
promotional vehicle for publishers --- the plugin documentation, as well as a 
splash-screen when the plugin is loaded, could describe advanced features of 
the publishers' online and/or document-curation capabilities.  
Publishers are branching out away from conventional 
text documents to incorporate data sets and multi-media content; it behooves 
them therefore to find opportunities to describe and promote the more advanced 
features of their platform.  Moreover, plugins demonstrate a level 
of technical sophistication; implementing plugins to scientific and 
technical applications demands advanced software-engineering techniques, 
so a publisher-specific plugin signals to the academic community that 
the publisher is comfortable engineering or designing complex 
scientific-computing components.}  
%\p{}
%\vspace{-1em}
%\noindent\Large{\underline{\lsHTXN{} Plugins}}
%\p{}

{\lunvs}
\noindent\lun{Using \lsHTXN{} and \lsHGDM{} In Consort: A case study}
{\lunvsa}
\p{As hypergraph text and data encoding protocols, respectively, 
\HTXN{} and \HGDM{} can interoperate organically.  The 
typical scenario where both formats would be used is that 
of preparing academic manuscripts accompanied by data sets 
which are serialized or documented via \HGDM{}.  Specific 
data samples, or figure illustrations derived from the 
data set, may then need to be inserted into \HTXN{} 
publications.  \AThreeR{} components would be 
implemented accordingly to track text-to-data cross-references 
(and vice-versa).}

\p{A typical \AThreeR{} data set provides native front-end 
code so that the shared data can be viewed and manipulated 
through custom \GUI{} components.  In conjunction with \PDF{} 
manuscripts explicating or analyzing the corresponding data, 
readers then have two potentially interrelated components 
(typically two top-level windows), one for the \PDF{} 
and one for the raw data.  Ideally, the two windows would 
interoperate, e.g. via (in \AThreeR{} parlance) 
\q{Coordinated Context Menus}.  In the canonical case, 
a context menu action activated on a particular sample, field, 
or other data set element (such as a table column) would 
load the \PDF{} to the text location where that aspect 
of the data set is discussed.  In the other direction,  
links embedded in the \PDF{} can trigger a signal to 
manipulate the data set \GUI{} in correlation with the 
relevant text location --- again the canonical case is 
scrolling and \q{unhiding} to ensure that a data sample 
or field, mentioned at that text point, is visible.}

\p{To concretely illustrate \HTXN{}/\HGDM{} interop, 
consider the following scenario (essentially 
typified by one of the data sets accompanying 
\textit{Advances in Ubiquitous Computing}).  Consider a 
data set including linguistic corpora annotated with a 
grammar format such as \CoNLLU{} (named after 
the Conference on Computational Natural Language Learning).  
Assuming that some corpus samples are discussed in an 
article accompanying the data set, these samples are 
then found in two places: as numbered examples (according 
to linguistic convention) within the text, as well as in 
the raw data.  Here is a good example of text/data 
cross-references: assuming that the \GUI{} components for the 
data set are some kind of list, table, or tree view 
where users can scroll through the language samples, 
optimal integration implies that context menus associated 
with individual samples on the data end are correlated 
with locations where the corresponding sample is printed in the 
article text.  This is an especially substantial case of 
cross-referencing because the actual raw data (sentences or 
other language/dialog excerpts) is fully present in the 
text (in the form of numbered linguistic examples).  
The essential step in this cross-referencing is to embed 
data in the \PDF{} file which uniquely identifies each sample, 
to be read by customized \PDF{} viewers so as to 
orchestrate the desired \GUI{} coordination.}

\p{A further requirement comes into play if the text will include 
figures documenting samples' syntactic structure (perhaps 
generated by a \LaTeX{} package such as TikZ-dependency).  Building 
such illustrations requires extracting certain fields from the 
\CoNLLU{} data and using the selected information to 
populate \LaTeX{} code inserted at the desired document position.  
This can be achieved by bundling a \CoNLLU{} library 
(such as \q{UDPipe}) with the data set and implementing a 
\Cpp{} procedure to call the relevant UDPipe functions, 
build an intermediate data structure, and use the result 
to fill in a \LaTeX{} template.  This \Cpp{} procedure can 
then be triggered by instructions at the relevant locations 
in the article's \HTXN{} file.}

\p{In this scenario generating publisher-specific \XML{} may be 
important to help ensure that the data/text cross-references 
get preserved.  If instead the publisher derives 
their \XML{} files by conversion (e.g., from 
\LaTeX{}), the labels engineered to enable 
\q{Context Menu Coordination} may be eliminated or 
renamed, forcing a time-consuming task of 
reconstructing text anchors.}


{\lunvs}
\noindent\lun{\lsNAThree{} and the Research Object Protocol}
\p{Open-access data sets conforming to the Research 
Object protocol are a good example of use-cases 
where the \AThreeR{} development strategies may 
be beneficial.  According to the Research Object protocol, 
data sets are paired with code and metadata to help 
subsequent researchers use and interact with the 
published data.  Via \AThreeR{}, the Research Object 
can be implemented as a standalone, desktop-style 
\q{dataset application} whose data models and 
\GUI{} components are uniquely designed for the 
associated data set, reflecting its scientific 
and theoretical provenance (experimental 
setup, data-acquisition methodology, 
data-structural rationale, etc.).  \lAThreeR{} 
employs unusually rigorous modeling for application 
components and data types, which makes it 
particularly appropriate for this Research Object 
context wherein a data set's technology --- its 
structural organization and custom code base 
--- becomes itself a scientific artifact.}

\p{Academic data-hosting is also a sector where 
LTS has a marketing head-start, insofar 
as LTS founder Dr. Amy Neustein serves as editor 
of the International Journal of Speech Technology 
and has authored or edited 14 academic/technical 
volumes.  LTS is currently in discussions with
several publishers to make \AThreeR{} tools available 
to authors for document and/or data-set preparation, 
collaborations which LTS is pursuing partly 
to introduce \NAThree{} within the scientific 
community and partly to curate and spur the emergence 
of an \AThreeR{} application corpus.}
 
\p{\lAThreeR{} data sets serve two distinct 
purposes in the context of marketing \NAThree{}.  
On the one hand, these data sets may be 
published on respected scientific platforms (notwithstanding 
their being hosted on an \NCN{} service), which 
provides a forum for promoting \NAThree{} 
to the scientific, academic, and Information Technology 
communities (through included \AThreeR{} code as 
well as documentation that will explain both 
the \NCN{} and \AThreeR{} frameworks).  Second, 
open-access \AThreeR{} data sets model a specific 
non-commercial version of \AThreeR{}, which serves as a 
baseline demonstration of \AThreeR{} features.  
The open-source \AThreeR{} implementation provides 
rudimentary support for scripting, data persistence, 
cloud integration, \ThreeD{} graphics, 
embedded web viewers, \GUI{}-based unit and integration testing, 
multi-application networking/workflows, and other features 
often desired for contemporary application development.  
Licensee developers (or LTS itself in a consulting/contracting  
role) can then extend whichever of these features are relevant 
for a commercial project.  The minimal dataset applications 
serve to concretize the overall structure of 
\AThreeR{} software, helping developers and/or 
acquisition teams visualize 
the practical benefits of \AThreeR{} and also 
decide on which \AThreeR{} features they 
will use on a commercial-grade scale in their project.}

\p{Generalizing to \NAThree{} overall, the 
concrete example of \AThreeR{} data sets helps 
illustrate \NCN{} features, because server-side 
capabilities are best understood in terms of 
how they complement client-side User Experience.  
Desirable cloud-integration features include 
persisting one user's application state across 
computers (home/school/office, etc.), sharing 
data in application-specific formats between users, 
collaborative editing, non-local backup, 
web-searching application corpora, and 
dynamic or non-recompile upgrades to running applications.  
Although such capabilities in the context of 
\NAThree{} depend on properly implemented 
\NCN{} services, they can be tangibly demonstrated 
for prospective customers through prototypical 
\AThreeR{} front-ends.}

\p{In this sense open-access data sets created via 
\AThreeR{} serve as demonstrations and 
concrete examples of \NAThree{} technology, and 
an opportunity to (indirectly) market \NAThree{} 
in the relevant scientific, publishing, and  
computer-scientific communities.  Currently 
three \AThreeR{} data sets have been published 
in the fields of linguistics, speech technology, 
and biomedical Cyber-Physical systems.  Several 
additional data sets will be made publicly 
available in conjunction with the upcoming 
publication of  
\textit{Advances in Ubiquitous Computing}.}

\p{LTS can therefore arrange to demonstrate the various 
facets of \NAThree{} using published data sets as a 
case-study.  We can supply additional references, or 
more detailed information about \NAThree{} 
components and technical innovations, as desired.}

%\p{}

\end{document}

