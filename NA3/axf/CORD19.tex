\documentclass[11pt,letterpaper]{article}

% pmml  arff  openannotation

\usepackage[T1]{fontenc}
\usepackage{tgtermes}

\usepackage[hang,flushmargin]{footmisc}

\usepackage{titlesec}

\titlespacing*{\section}
{0pt}{5ex plus 1ex minus .2ex}{1.1ex plus .2ex}

%\usepackage{mathptmx}

\usepackage{eso-pic}

%\setlength\parindent{0pt}

\AddToShipoutPictureBG{%

\ifnum\value{page}>1{
\AtTextUpperLeft{
\makebox[20.5cm][r]{
\raisebox{-1.3cm}{%
{\transparent{0.3}{\includegraphics[width=0.29\textwidth]{e-logo.png}}	}} } }
}\fi
}

\AddToShipoutPicture{%
{
 {\color{blGreen!70!red}\transparent{0.9}{\put(0,0){\rule{3pt}{\paperheight}}}}%
 {\color{darkRed!70!purple}\transparent{1}\put(3,0){{\rule{4pt}{\paperheight}}}}
% {\color{logoPeach!80!cyan}\transparent{0.5}{\put(0,700){\rule{1cm}{.6cm}}}}%
% {\color{darkRed!60!cyan}\transparent{0.7}\put(0,706){{\rule{1cm}{.6cm}}}}
% \put(18,726){\thepage}
% \transparent{0.8}
}
}

\AddToShipoutPicture{%
\ifnum\value{page}=1
\put(257.5,975){%
	\transparent{0.7}{
		\includegraphics[width=0.2\textwidth]{logo.png}}}
\fi
}	



\AddToShipoutPicture{%
\ifnum\value{page}>1
{\color{blGreen!70!red}\transparent{0.9}{\put(300,8){\rule{0.5\paperwidth}{.3cm}}}}%
{\color{inOne}\transparent{0.8}{\put(300,10){\rule{0.5\paperwidth}{.3cm}}}}%
{\color{inTwo}\transparent{0.3}\put(300,13){{\rule{0.5\paperwidth}{.3cm}}}}

\put(301,16){%
\transparent{0.7}{
\includegraphics[width=0.2\textwidth]{logo.png}} }

{\color{blGreen!70!red}\transparent{0.9}{\put(5.6,5){\rule{0.5\paperwidth}{.4cm}}}}%
{\color{inOne}\transparent{1}{\put(5.6,10){\rule{0.5\paperwidth}{.4cm}}}}%
{\color{inTwo}\transparent{0.3}\put(5.6,15){{\rule{0.5\paperwidth}{.4cm}}}}

\fi
}

%\pagestyle{empty} % no page number
%\parskip 7.2pt    % space between paragraphs
%\parindent 12pt   % indent for new paragraph
%\textwidth 4.5in  % width of text
%\columnsep 0.8in  % separation between columns

%\setlength{\footskip}{7pt}

\usepackage[paperheight=14.5in,paperwidth=8.5in]{geometry}
\geometry{left=.73in,top=.7in,right=.52in,bottom=1.3in} %margins

\renewcommand{\thepage}{\raisebox{-4pt}{\arabic{page}}}

\renewcommand{\footnoterule}{%
	\kern -3pt
	\hrule width .92\textwidth height .5pt
	\kern 10pt
}


\usepackage[hyphens]{url}
\newcommand{\biburl}[1]{ {\fontfamily{gar}\selectfont{\textcolor[rgb]{.2,.6,0}%
{\scriptsize {\url{#1}}}}}}

%\linespread{1.3}

\newcommand{\sectsp}{\vspace{12pt}}

\usepackage{graphicx}
\usepackage{color,framed}

\usepackage{textcomp}

\usepackage{float}

\usepackage{mdframed}


\usepackage{setspace}
\newcommand{\rpdfNotice}[1]{\begin{onehalfspacing}{

\Large #1

}\end{onehalfspacing}}

\usepackage{xcolor}

\usepackage[hyphenbreaks]{breakurl}
\usepackage[hyphens]{url}

\usepackage{hyperref}
\newcommand{\rpdfLink}[1]{\href{#1}{\small{#1}}}
\newcommand{\dblHref}[1]{\href{#1}{\small{\burl{#1}}}}
\newcommand{\browseHref}[2]{\href{#1}{\Large #2}}

\colorlet{blCyan}{cyan!50!blue}

\definecolor{darkRed}{rgb}{.2,.0,.1}


\definecolor{blGreen}{rgb}{.2,.7,.3}

\definecolor{darkBlGreen}{rgb}{.1,.3,.2}

\definecolor{oldBlColor}{rgb}{.2,.7,.3}

\definecolor{blColor}{rgb}{.1,.3,.2}

\definecolor{elColor}{rgb}{.2,.1,0}
\definecolor{flColor}{rgb}{0.7,0.3,0.3}

\definecolor{logoOrange}{RGB}{108, 18, 30}
\definecolor{logoGreen}{RGB}{85, 153, 89}
\definecolor{logoPurple}{RGB}{200, 208, 30}

\definecolor{logoBlue}{RGB}{4, 2, 25}
\definecolor{logoPeach}{RGB}{255, 159, 102}
\definecolor{logoCyan}{RGB}{66, 206, 244}
\definecolor{logoRed}{rgb}{.3,0,0}

\newcommand{\colorq}[1]{{\color{logoOrange!70!black}{\q{\small\textbf{#1}}}}}

\definecolor{inOne}{rgb}{0.122, 0.435, 0.698}% Rule colour
\definecolor{inTwo}{rgb}{0.122, 0.698, 0.435}% Rule colour

\definecolor{outOne}{rgb}{0.435, 0.698, 0.122}% Rule colour
\definecolor{outTwo}{rgb}{0.698, 0.435, 0.122}% Rule colour

\usepackage[many]{tcolorbox}% http://ctan.org/pkg/tcolorbox

\usepackage{transparent}

\newlength{\bsep}
\setlength{\bsep}{-1pt}
\let\xbibitem\bibitem
\renewcommand{\bibitem}[2]{\vspace{\bsep}\xbibitem{#1}{#2}}

\newenvironment{cframed}{\begin{mdframed}[linecolor=logoPeach,linewidth=0.4mm]}{\end{mdframed}}

\newenvironment{ccframed}{\begin{mdframed}[backgroundcolor=logoGreen!5,linecolor=logoCyan!50!black,linewidth=0.4mm]}{\end{mdframed}}

\usepackage{aurical}
\usepackage[T1]{fontenc}

\usepackage{relsize}

\newcommand{\bref}[1]{\hspace*{1pt}\textbf{\ref{#1}}}

\newcommand{\pseudoIndent}{

\vspace{10pt}\hspace*{12pt}}

\newcommand{\YPDFI}{{\fontfamily{fvs}\selectfont YPDF-Interactive}}

%
\newcommand{\deconum}[1]{{\protect\raisebox{-1pt}{{\LARGE #1}}}}

\newcommand{\visavis}{vis-\`a-vis}

\newcommand{\VersatileUX}{{\color{red!85!black}{\Fontauri Versatile}}%
{{\fontfamily{qhv}\selectfont\smaller UX}}}

\newcommand{\NDPCloud}{{\color{red!15!black}%
{\fontfamily{qhv}\selectfont {\smaller NDP C{\smaller LOUD}}}}}

\newcommand{\MThreeK}{{\color{blGreen!45!black}%
{\fontfamily{qhv}\fontsize{10}{8}\selectfont {M3K}}}}


\newcommand{\lfNDPCloud}{{\color{red!15!black}%
{\fontfamily{qhv}\selectfont N{\smaller DP C{\smaller LOUD}}}}}

\newcommand{\textds}[1]{{\fontfamily{lmdh}\selectfont{%
\raisebox{-1pt}{#1}}}}

\newcommand{\dsC}{{\textds{ds}{\fontfamily{qhv}\selectfont \raisebox{-1pt}
{\color{red!15!black}{C}}}}}

\definecolor{tcolor}{RGB}{24,52,61}

\newcommand{\CCpp}{\resizebox{!}{7pt}{\AcronymText{C}}/\Cpp{}}
\newcommand{\NoSQL}{\resizebox{!}{7pt}{\AcronymText{NoSQL}}}
\newcommand{\SQL}{\resizebox{!}{7pt}{\AcronymText{SQL}}}

\newcommand{\NCBI}{\resizebox{!}{7pt}{\AcronymText{NCBI}}}

\newcommand{\HTXN}{\resizebox{!}{7pt}{\AcronymText{HTXN}}}
\newcommand{\lHTXN}{\resizebox{!}{7.5pt}{\AcronymText{HTXN}}}
\newcommand{\lsHTXN}{\resizebox{!}{9.5pt}{\AcronymText{\textcolor{tcolor}{HTXN}}}}


\usepackage{mdframed}

\newcommand{\cframedboxpanda}[1]{\begin{mdframed}[linecolor=yellow!70!blue,linewidth=0.4mm]#1\end{mdframed}}


\newcommand{\PVD}{\resizebox{!}{7pt}{\AcronymText{PVD}}}

\newcommand{\THQL}{\resizebox{!}{7pt}{\AcronymText{THQL}}}
\newcommand{\lTHQL}{\resizebox{!}{7.5pt}{\AcronymText{THQL}}}

\newcommand{\SDK}{\resizebox{!}{7pt}{\AcronymText{SDK}}}
\newcommand{\NLP}{\resizebox{!}{7pt}{\AcronymText{NLP}}}

\newcommand{\AXF}{\resizebox{!}{7pt}{\AcronymText{AXF}}}
\newcommand{\lAXF}{\resizebox{!}{7.5pt}{\AcronymText{AXF}}}
\newcommand{\lsAXF}{\resizebox{!}{8.5pt}{\AcronymText{AXF}}}

\newcommand{\IJST}{\resizebox{!}{7pt}{\AcronymText{IJST}}}

\newcommand{\BioC}{\resizebox{!}{7pt}{\AcronymText{BioC}}}

\newcommand{\CoNLL}{\resizebox{!}{7pt}{\AcronymText{CoNLL}}}
\newcommand{\CoNLLU}{\resizebox{!}{7pt}{\AcronymText{CoNLL-U}}}

\newcommand{\sapp}{\resizebox{!}{7pt}{\AcronymText{Sapien+}}}
\newcommand{\lsapp}{\resizebox{!}{8.5pt}{\AcronymText{Sapien+}}}
\newcommand{\lssapp}{\resizebox{!}{9.5pt}{\AcronymText{Sapien+}}}

\newcommand{\ePub}{\resizebox{!}{7pt}{\AcronymText{ePub}}}

%\lsLPF


\newcommand{\GIT}{\resizebox{!}{7pt}{\AcronymText{GIT}}}

\newcommand{\LPF}{\resizebox{!}{7pt}{\AcronymText{LPF}}}
\newcommand{\lLPF}{\resizebox{!}{8.5pt}{\AcronymText{LPF}}}
\newcommand{\lsLPF}{\resizebox{!}{9.5pt}{\AcronymText{LPF}}}

\makeatletter

\newcommand*\getX[1]{\expandafter\getX@i#1\@nil}

\newcommand*\getY[1]{\expandafter\getY@i#1\@nil}
\def\getX@i#1,#2\@nil{#1}
\def\getY@i#1,#2\@nil{#2}
\makeatother
	
\newcommand{\rectann}[9]{%
\path [draw=#1,draw opacity=#2,line width=#3, fill=#4, fill opacity = #5, even odd rule] %
(#6) rectangle(\getX{#6}+#7,\getY{#6}+#8)
({\getX{#6}+((#7-(#7*#9))/2)},{\getY{#6}+((#8-(#8*#9))/2)}) rectangle %
({\getX{#6}+((#7-(#7*#9))/2)+#7*#9},{\getY{#6}+((#8-(#8*#9))/2)+#8*#9});}


\definecolor{pfcolor}{RGB}{94, 54, 73}

\newcommand{\EPF}{\resizebox{!}{7pt}{\AcronymText{ETS{\color{pfcolor}pf}}}}
\newcommand{\lEPF}{\resizebox{!}{8.5pt}{\AcronymText{ETS{\color{pfcolor}pf}}}}
\newcommand{\lsEPF}{\resizebox{!}{9.5pt}{\AcronymText{ETS{\color{pfcolor}pf}}}}


\newcommand{\XPDF}{\resizebox{!}{7pt}{\AcronymText{XPDF}}}

\newcommand{\GRE}{\resizebox{!}{8.5pt}{\AcronymText{GRE}}}

\newcommand{\lMOSAIC}{\resizebox{!}{8.5pt}{\AcronymText{MOSAIC}}}

\newcommand{\XML}{\resizebox{!}{7pt}{\AcronymText{XML}}}
\newcommand{\RDF}{\resizebox{!}{7pt}{\AcronymText{RDF}}}
\newcommand{\DOM}{\resizebox{!}{7pt}{\AcronymText{DOM}}}

\newcommand{\Covid}{\resizebox{!}{7pt}{\AcronymText{Covid-19}}}

\newcommand{\CLang}{\resizebox{!}{7pt}{\AcronymText{C}}}

\newcommand{\HNaN}{\resizebox{!}{7pt}{\AcronymText{HN%
\textsc{a}N}}}

\newcommand{\JSON}{\resizebox{!}{7pt}{\AcronymText{JSON}}}

\newcommand{\MeshLab}{\resizebox{!}{7pt}{\AcronymText{MeshLab}}}
\newcommand{\IQmol}{\resizebox{!}{7pt}{\AcronymText{IQmol}}}

\newcommand{\SGML}{\resizebox{!}{7pt}{\AcronymText{SGML}}}

\newcommand{\ASCII}{\resizebox{!}{7pt}{\AcronymText{ASCII}}}

\newcommand{\GUI}{\resizebox{!}{7pt}{\AcronymText{GUI}}}

\newcommand{\API}{\resizebox{!}{7pt}{\AcronymText{API}}}

\newcommand{\SDI}{\resizebox{!}{7pt}{\AcronymText{SDI}}}

\newcommand{\IDE}{\resizebox{!}{7pt}{\AcronymText{IDE}}}

\newcommand{\ThreeD}{\resizebox{!}{7pt}{\AcronymText{3D}}}

\newcommand{\FAIR}{\resizebox{!}{7pt}{\AcronymText{FAIR}}}

\newcommand{\QNetworkManager}{\resizebox{!}{7pt}{\AcronymText{QNetworkManager}}}
\newcommand{\QTextDocument}{\resizebox{!}{7pt}{\AcronymText{QTextDocument}}}
\newcommand{\QWebEngineView}{\resizebox{!}{7pt}{\AcronymText{QWebEngineView}}}
\newcommand{\HTTP}{\resizebox{!}{7pt}{\AcronymText{HTTP}}}


\newcommand{\lAcronymTextNC}[2]{{\fontfamily{fvs}\selectfont {\Large{#1}}{\large{#2}}}}

\newcommand{\AcronymTextNC}[1]{{\fontfamily{fvs}\selectfont {\large #1}}}


\colorlet{orr}{orange!60!red}

\newcommand{\textscc}[1]{{\color{orr!35!black}{{%
						\fontfamily{Cabin-TLF}\fontseries{b}\selectfont{\textsc{\scriptsize{#1}}}}}}}


\newcommand{\textsccserif}[1]{{\color{orr!35!black}{{%
				\scriptsize{\textbf{#1}}}}}}


\newcommand{\iXPDF}{\resizebox{!}{7pt}{\textsccserif{%
\textit{XPDF}}}}

\newcommand{\iEPF}{\resizebox{!}{7pt}{\textsccserif{%
\textit{ETSpf}}}}

\newcommand{\iSDI}{\resizebox{!}{7pt}{\textsccserif{%
\textit{SDI}}}}

\newcommand{\iHTXN}{\resizebox{!}{7pt}{\textsccserif{%
\textit{HTXN}}}}


\newcommand{\AcronymText}[1]{{\textscc{#1}}}

\newcommand{\AcronymTextser}[1]{{\textsccserif{#1}}}


\newcommand{\mAcronymText}[1]{{\textscc{\normalsize{#1}}}}

\newcommand{\FASTA}{{\resizebox{!}{7pt}{\AcronymText{FASTA}}}}
\newcommand{\SRA}{{\resizebox{!}{7pt}{\AcronymText{SRA}}}}
\newcommand{\DNA}{{\resizebox{!}{7pt}{\AcronymText{DNA}}}}
\newcommand{\MAP}{{\resizebox{!}{7pt}{\AcronymText{MAP}}}}
\newcommand{\EPS}{{\resizebox{!}{7pt}{\AcronymText{EPS}}}}
\newcommand{\CSV}{{\resizebox{!}{7pt}{\AcronymText{CSV}}}}
\newcommand{\PDB}{{\resizebox{!}{7pt}{\AcronymText{PDB}}}}

\newcommand{\TeXMECS}{\resizebox{!}{7pt}{\AcronymText{TeXMECS}}}

% pmml  arff  openannotation

\newcommand{\PMML}{\resizebox{!}{7pt}{\AcronymText{PMML}}}
\newcommand{\ARFF}{\resizebox{!}{7pt}{\AcronymText{ARFF}}}
\newcommand{\IeXML}{\resizebox{!}{7pt}{\AcronymText{IeXML}}}


\newcommand{\NGML}{\resizebox{!}{7pt}{\AcronymText{NGML}}}

\newcommand{\Cpp}{\resizebox{!}{7pt}{\AcronymText{C++}}}

\newcommand{\WhiteDB}{\resizebox{!}{7pt}{\AcronymText{WhiteDB}}}

\colorlet{drp}{darkRed!70!purple}

%\newcommand{\MOSAIC}{{\color{drp}{\AcronymTextNC{\scriptsize{MOSAIC}}}}}

\newcommand{\MOSAIC}{\resizebox{!}{7pt}{\AcronymText{MOSAIC}}}


\newcommand{\mMOSAIC}{{\color{drp}{\AcronymTextNC{\normalsize{MOSAIC}}}}}

\newcommand{\MOSAICVM}{\mMOSAIC-\mAcronymText{VM}}

\newcommand{\sMOSAICVM}{\resizebox{!}{7pt}{\MOSAICVM}}
\newcommand{\sMOSAIC}{\resizebox{!}{7pt}{\MOSAIC}}

\newcommand{\LDOM}{\resizebox{!}{7pt}{\AcronymText{LDOM}}}
\newcommand{\Cnineteen}{\resizebox{!}{7pt}{\AcronymText{CORD-19}}}


\newcommand{\LXCR}{\resizebox{!}{7pt}{\AcronymText{LXCR}}}
\newcommand{\lLXCR}{\resizebox{!}{8.5pt}{\AcronymText{LXCR}}}
\newcommand{\lsLXCR}{\resizebox{!}{9.5pt}{\AcronymText{LXCR}}}

%\newcommand{\lMOSAIC}{{\color{drp}{\lAcronymTextNC{M}{OSAIC}}}}
\newcommand{\lfMOSAIC}{\resizebox{!}{9pt}{{\color{drp}{\lAcronymTextNC{M}{OSAIC}}}}}

\newcommand{\Mosaic}{\resizebox{!}{7pt}{\MOSAIC}}
\newcommand{\MosaicPortal}{{\color{drp}{\AcronymTextNC{MOSAIC Portal}}}}

\newcommand{\RnD}{\resizebox{!}{7pt}{\AcronymText{R\&D}}}
\newcommand{\QtCpp}{\resizebox{!}{8.5pt}{\AcronymText{Qt/C++}}}
\newcommand{\Qt}{\resizebox{!}{7pt}{\AcronymText{Qt}}}
\newcommand{\QtSQL}{\resizebox{!}{7pt}{\AcronymText{QtSQL}}}

\newcommand{\HTML}{\resizebox{!}{7pt}{\AcronymText{HTML}}}
\newcommand{\PDF}{\resizebox{!}{7pt}{\AcronymText{PDF}}}

\newcommand{\R}{\resizebox{!}{7pt}{\AcronymText{R}}}
\newcommand{\SciXML}{\resizebox{!}{7pt}{\AcronymText{SciXML}}}



\newcommand{\lGRE}{\resizebox{!}{7pt}{\AcronymText{GRE}}}

\newcommand{\p}[1]{

\vspace{.75em}#1}

\newcommand{\q}[1]{{\fontfamily{qcr}\selectfont ``}#1{\fontfamily{qcr}\selectfont ''}} 

%\newcommand{\deconum}[1]{{\textcircled{#1}}}


\renewcommand{\thesection}{\protect\mbox{\deconum{\Roman{section}}}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\newcommand{\llMOSAIC}{\mbox{{\LARGE MOSAIC}}}
%\newcommand{\lfMOSAIC}{\mbox{M\small{OSAIC}}}

\newcommand{\llMosaic}{\llMOSAIC}
\newcommand{\lMosaic}{\lMOSAIC}
\newcommand{\lfMosaic}{\lfMOSAIC}


\newcommand{\llWC}{\mbox{{\LARGE WhiteCharmDB}}}

\newcommand{\llwh}{\mbox{{\LARGE White}}}
\newcommand{\llch}{\mbox{{\LARGE CharmDB}}}

\usepackage{enumitem}

\colorlet{dsl}{purple!20!brown}
\colorlet{dslr}{dsl!50!blue}

\setlist[description]{%
  topsep=10pt,
  labelsep=12pt,
  itemsep=12pt,               % space between items
  %font={\bfseries\sffamily}, % set the label font
  font=\normalfont\bfseries\color{dslr!50!black}, % if colour is needed
}

\setlist[enumerate]{%
  topsep=3pt,               % space before start / after end of list
  itemsep=-2pt,               % space between items
  font={\bfseries\sffamily}, % set the label font
%  font={\bfseries\sffamily\color{red}}, % if colour is needed
}

%\usepackage{tcolorbox}

\newcommand{\slead}[1]{%
\noindent{\raisebox{2pt}{\relscale{1.15}{{{%
\fcolorbox{logoCyan!50!black}{logoGreen!5}{#1}
}}}}}\hspace{.5em}}


\let\OldLaTeX\LaTeX

\renewcommand{\LaTeX}{\resizebox{!}{7pt}{\color{orr!35!black}{\OldLaTeX}}}

\let\OldTeX\TeX

\renewcommand{\TeX}{\resizebox{!}{7pt}{\color{orr!35!black}{\OldTeX}}}


\newcommand{\LargeLaTeX}{\resizebox{!}{8.5pt}{\color{orr!35!black}{\OldLaTeX}}}

\setlength\parindent{0pt}
%\setlength\parindent{24pt}
%\input{commands}


\newcommand{\lun}[1]{\raisebox{-4pt}{\fontfamily{qcr}\selectfont{%
\LARGE{\textbf{\textcolor{tcolor}{#1}}}}}\vspace{-2pt}}

\newcommand{\inditem}{\itemindent10pt\item}

\usepackage{soul}

\definecolor{hlcolor}{RGB}{114, 54, 203}
\colorlet{hlcol}{hlcolor!35}
\sethlcolor{hlcol}

\makeatletter
\def\SOUL@hlpreamble{%
	\setul{}{3ex}%         !!!change this value!!! default is 2.5ex
	\let\SOUL@stcolor\SOUL@hlcolor
	\SOUL@stpreamble
}
\makeatother

\usepackage{scrextend}
%\vspace*{3em}
\newenvironment{mldescription}{\vspace{1em}%
  \begin{addmargin}[4pt]{1em}
    \setlength{\parindent}{-1em}%
    \newcommand*{\mlitem}[1][]{\vspace{5pt}\par\medskip%
%\colorbox{hlcolor}{\textbf{##1}}\quad}\indent
\hl{ \textbf{##1} }\quad}\indent
}{%
  \end{addmargin}
  \medskip
}

\usepackage{marginnote}

\newcommand{\mnote}[1]{%
\vspace*{-2em}
\reversemarginpar
\raisebox{1em}{\marginnote{\parbox{4em}{%
\begin{mdframed}[innerleftmargin=4pt,
	innerrightmargin=1pt,innertopmargin=1pt,
	linecolor=red!20!cyan,userdefinedwidth=4em,
	topline=false,
	rightline=false]
{{\fontfamily{ppl}\fontsize{12}{0}\selectfont
		\textit{#1}}}
\end{mdframed}}
	}[3em]}}

\newcommand{\mnotel}[1]{%
\vspace*{-2em}
\reversemarginpar
\raisebox{-4em}{\marginnote{\parbox{4em}{%
\begin{mdframed}[innerleftmargin=4pt,
	innerrightmargin=1pt,innertopmargin=1pt,
	linecolor=red!20!cyan,userdefinedwidth=4em,
	topline=false,
	rightline=false]
{{\fontfamily{ppl}\fontsize{12}{0}\selectfont
		\textit{#1}}}
\end{mdframed}}
	}[3em]}}

\newcommand{\mnoteh}[3]{%
	\vspace*{#1}
	\reversemarginpar
	\raisebox{#2}{\marginnote{\parbox{4em}{%
				\begin{mdframed}[innerleftmargin=4pt,
					innerrightmargin=1pt,innertopmargin=1pt,
					linecolor=red!20!cyan,userdefinedwidth=4em,
					topline=false,
					rightline=false]
					{{\fontfamily{ppl}\fontsize{12}{0}\selectfont
							\textit{#3}}}
				\end{mdframed}}
			}[3em]}}


\newcommand{\mnoteb}[1]{%
	\vspace*{1em}
	\reversemarginpar
	\raisebox{1em}{\marginnote{\parbox{4em}{%
				\begin{mdframed}[innerleftmargin=4pt,
					innerrightmargin=1pt,innertopmargin=1pt,
					linecolor=red!20!cyan,userdefinedwidth=4em,
					topline=false,
					rightline=false]
					{{\fontfamily{ppl}\fontsize{12}{0}\selectfont
							\textit{#1}}}
				\end{mdframed}}
			}[3em]}}
	
\usepackage{wrapfig}

\usetikzlibrary{arrows, decorations.markings}
\usetikzlibrary{shapes.arrows}

\newcommand{\curicon}[2]{%
	\node at (#1,#2) [
	draw=black,
	%minimum width=2ex,
	inner sep=.7pt,
	fill=white,
	single arrow,
	single arrow head extend=3pt,
	single arrow head indent=1.5pt,
	single arrow tip angle=45,
	line join=bevel,
	minimum height=4.6mm,
	rotate=115
	] {};
}

\makeatletter
\def\@cite#1#2{[\textbf{#1\if@tempswa , #2\fi}]}
\def\@biblabel#1{[\textbf{#1}]}
\makeatother

\hypersetup{
	colorlinks=true,
	citecolor=blCyan!40!green,
	filecolor=magenta,
	urlcolor=blue,
}

\renewcommand{\thefootnote}{\textcolor{logoGreen!80!logoBlue}{{\fontfamily{qcr}\fontseries{b}\fontsize{10}{4}\selectfont\arabic{footnote}}}}


\newcommand{\LVee}{{\colorbox{cyan!40!yellow}{\textcolor{red!70!navy}{\textbf{\LARGE$\vee$}}}}}
\newcommand{\LWedge}{{\colorbox{cyan!40!yellow}{\textcolor{red!70!navy}{\textbf{\LARGE$\wedge$}}}}}

\urlstyle{same}

%\setmainfont{QTChanceryType}

\begin{document}

\setlength{\skip\footins}{18pt}	
	
{\linespread{1.2}\selectfont

\vspace*{.5em}

\begin{center}
%{\relscale{1.2}{\fontfamily{qcr}\fontseries{b}\selectfont 
%{\colorbox{black}{\color{blue}{\llWC{} Database Engine \\and 
%\llMOSAIC{} Native Application Toolkit}}}}}

\colorlet{ctmp}{logoPeach!20!gray}
\colorlet{ctmpp}{ctmp!90!yellow}
\colorlet{ctmppp}{ctmpp!50!black}
\colorlet{ctmpppp}{ctmppp!90!logoRed}
\colorlet{ctmcyan}{ctmpppp!70!cyan}

%\vspace{2em}


%{\colorbox{darkBlGreen!30!darkRed}{%
\begin{tcolorbox}
[
%%enhanced,
%%frame hidden,
%interior hidden
arc=2pt,outer arc=0pt,
enhanced jigsaw,
width=.92\textwidth,
colback=ctmcyan!50,
colframe=logoRed!30!darkRed,
drop shadow=logoPurple!50!darkRed,
%boxsep=0pt,
%left=0pt,
%right=0pt,
%top=2pt,
]
%\hspace{22pt}
\begin{minipage}{.99\textwidth}	
\begin{center}	
{\setlength{\fboxsep}{28pt}
	\relscale{1.2}{{\fontfamily{qcr}\fontseries{b}\selectfont%
{Proposing a CORD-19 Software Development 
Kit to Improve \\\vspace{.25em}Machine Readability 
and Text Mining}
}}}
\end{center}
\end{minipage}
\end{tcolorbox}
\end{center}

\vspace*{.5em}
\begin{center}
\parbox{.86\textwidth}{%
{\fontfamily{pzc}\selectfont   
LTS is founded by Amy Neustein, PhD, 
Series Editor of {\bf Speech Technology and 
Text Mining in Medicine and Health Care} (de Gruyter); 
and Editor of {\bf Advances in Ubiquitous Computing: 
Cyber-Physical Systems, Smart Cities, 
and Ecological Monitoring} 
(Elsevier, forthcoming).  These 
publishers have placed Dr. Neustein's 
publications on their open access portals 
linked from \Cnineteen{}.}}
\end{center}
\vspace*{.5em}	
	
\p{\Cnineteen{} (the \q{\Covid{} Open Research Dataset}) 
is a new coronavirus data collection which was released in conjunction with a White House initiative to 
spur \hspace{-1pt} \Covid{} \hspace{-1pt} research.  
This initiative is described as a 
\q{call to action ... to develop new text and data mining techniques that can help the science community answer high-priority scientific questions related to \Covid{}} (see \href{https://www.whitehouse.gov/briefings-statements/call-action-tech-community-new-machine-readable-covid-19-dataset/}{https://www.whitehouse.gov/briefings-statements/call-action-tech-community-new-machine-readable-covid-19-dataset/}).  The White House 
is spearheading a consortium of industry and academic 
institutions, led by the Allen Institute for AI Research, 
which curated a \q{machine-readable Coronavirus literature collection} 
that includes article metadata and (in most cases) 
publication text, both encoded as \JSON{} files, 
for over 44,000 coronavirus research papers.  This 
corpus of publication texts and metadata 
is also paired with links to publisher portals 
(including Springer Nature, 
Wiley, Elsevier, the American Society for Microbiology, and the New England Journal of Medicine), so as to provide 
scientists with full open access to selected \Covid{}-related literature; these 
resources collectively constitute 
\Cnineteen{} (see \cite{CORD}).}

\p{Linguistic Technology Systems (LTS) 
would like to create a Software 
Development Kit (\SDK{}) to 
help scientists utilize \Cnineteen{}.  
This \SDK{} would be divided into three main part.  
(1) \LVee{}The basic foundation of this \SDK{} is 
a framework that we call \q{Annotation Exchange Format} 
(\AXF{}).  This framework is designed to facilitate 
document preparation as well as interoperability 
between text and/or data mining tools.  
\lAXF{} is employed as a querying format that is 
integrated with data sets which will accompany the 
forthcoming volume, \textit{Advances in Ubiquitous Computing}, 
which is part of Elsevier's \textit{Advances in Ubiquitous 
Sensing Applications for Healthcare} series.\LWedge{}  
(2) Our proposed \SDK{} 
would also include new code libraries explicitly 
implemented for data-management operations 
specific to \Cnineteen{}, as well as a package of 
applications, modified to support \Covid{} research, 
that would collectively create an integrated 
and self-contained computing environment.  
(3) These three parts of the \SDK{} --- 
the new code libraries, 
the application package, and \AXF{} --- 
are outlined in this paper.}

\section{New Code Libraries within the Proposed SDK}
\p{The \Cnineteen{} 
collection was formulated with the explicit goal 
of promoting both \textit{text mining} and 
\textit{data mining} solutions 
to advance coronavirus research.  This means that 
\Cnineteen{} is intended to be used both as a document 
archive for text mining and as a repository for 
finding and obtaining coronavirus data for subsequent 
research.  Because the White House announcement requests 
institutions to develop additional technologies 
which would help scientists and jurisdictions to 
take advantage of \Cnineteen{}, 
the collection was released with the 
anticipation that industry and academia would 
augment the underlying data by layering on additional 
software.  Our proposed \Cnineteen{} \SDK{} would 
do just that: this \SDK{} would serve as a component 
that would provide analytic capabilities 
to make the raw \Cnineteen{} data 
more valuable; it would also serve as a toolkit through which 
other developers could create 
new solutions targeting the \Cnineteen{} repository.}

\p{To accomplish these goals, our 
proposed \SDK{} would include a collection of 
new code libraries to aid programmers in the 
implementation of algorithms to investigate the 
\Cnineteen{} corpus.  These code libraries would 
enhance the underlying data by providing the following 
useful features: 

%\vspace{-2em}
\begin{description}[leftmargin=9pt,itemsep=4pt]
	
\item[Tools for Correcting Transription Errors]  
Transription errors can cause the machine-readable 
text archive to misrepresent the structure 
and content of documents.  For instance, 
there are cases in \Cnineteen{} 
of scientific notation and terminology 
being improperly encoded.  As a concrete example, \colorq{2{\textquotesingle}-C-ethynyl} is encoded incorrectly in one \Cnineteen{} file 
as \makebox{\colorq{2 0 -C-ethynyl}} (see \cite{Eyer} for 
the human-readable publication where this error is 
observed; the corresponding index in the corpus is \textcolor{blGreen!45!black}{9555f44156bc5f2c6ac191dda2fb651501a7bd7b.json}).  
To help address these sorts of errors --- 
which could stymie text searches 
against the \Cnineteen{} corpus --- 
our \SDK{} would 
augment the \Cnineteen{} repository by providing 
alternate machine-readable encodings 
of the archived documents in formats such as \XML{}, 
whenever they are available, 
as a supplement to \Cnineteen{}'s 
\JSON{} representation.  
Compared to article content obtained indirectly 
by \q{scraping} text from \HTML{} or \PDF{} 
files, these \XML{} representations 
(which would be derived from the structured documents used 
in the editing process prior to publication) 
would not be subject to transcription 
errors.  The \SDK{} would then provide tools to 
cross-reference multiple versions of each document, 
so as to correct errors in the original \JSON{} encodings. 
    
\item[Tools for Converting Between Data Formats]
Although the \Cnineteen{} corpus is published 
as \JSON{} files, many text-mining tools such 
as those reviewed in \cite{NeusteinText} recognize 
input in alternative formats, such as \XML{},  
\BioC{}, or \JSON{} trees with different 
schema than \Cnineteen{}.  Our proposed 
\SDK{} would provide libraries to read 
\Cnineteen{}'s \JSON{} files and output 
data in one of these alternative formats, 
so as to initiate a text mining workflow. 
The \SDK{} would also include tools for 
manipulating the \textit{results} of 
text mining algorithms, which is 
often represented in formats such as 
\XML{} and \CoNLL{} (Conference on Natural 
Language Learning; this is a schema for representing 
sentences via parse-graphs). 
   
\item[Tools for Enhanced Annotation]
Currently \Cnineteen{} does not 
directly provide a mechanism for asserting 
annotations related to text mining, 
such as Named Entity Recognition or 
formally recognized biomedical concepts.  
However, because the archival schema supports standoff 
annotation for intra-document references,  
our \SDK{} can provide code for additional 
standoff annotation categories of the kinds 
commonly used in biomedical text mining.  
As a concrete example, the corrected 
text segment \colorq{2{\textquotesingle}-C-ethynyl} mentioned 
earlier can be annotated as a molecular component. 

\item[Tools for Research Data-Mining]  Even though 
many papers in \Cnineteen{} are paired with 
published data sets, there is currently no tool for 
locating  research \textit{data} 
through \Cnineteen{}. 
For example, the collection of manuscripts available 
through the Springer Nature portal linked 
from \Cnineteen{} includes over 30 \Covid{} data sets,
but researchers can only discover that these data 
sets exist by looking for a \q{supplemental materials} or 
a \q{data availability} addendum near the end of each article.
These Springer Nature data sets encompass a wide array of file types 
and formats, including \FASTA{} (which stands for Fast-All, 
a genomics format), \SRA{} (Sequence Read Archive, for 
\DNA{} sequencing), \PDB{} (Protein Data Bank,  
representing the \ThreeD{} geometry of protein 
molecules), \MAP{} (Electron Microscopy Map), \EPS{} 
(Embedded Postscript), \CSV{} (comma-separated values), 
and tables represented in Microsoft Word 
and Excel formats.  To promote data mining 
in the context of \Cnineteen{}, our 
\SDK{} would (1) maintain an index of 
data sets linked to \Cnineteen{} articles 
and (2) merge these resources into a common representation 
(such as \XML{}) wherever possible.  

\item[Wrappers for Network Requests]  Scientific 
use of \Cnineteen{} will often require communicating 
with remote servers.  For example, genomics 
information in the \Covid{} data sets (such as 
those mentioned above that are available through 
Springer Nature) is generally 
provided in the form of accession numbers which 
are used to query online genomics services.  
Similarly, text mining algorithms often 
rely on dedicated servers to perform 
Natural Language Processing; these services 
might take requests in \BioC{} format and respond 
with \CoNLL{} data.  As another case study epidemiological 
studies of \Covid{} may need to access \API{}s or data 
sets such as the John Hopkins University \q{dashboard} 
(see \href{https://coronavirus.jhu.edu/map.html}{https://coronavirus.jhu.edu/map.html}, which is paired with a \GIT{} archive updated almost daily).  To reduce the amount 
of \q{biolerplate code} which developers need 
for these networking requirements, our 
company's \SDK{} 
would provide code libraries based on the 
\Qt{} Networking Module to manage networking 
requests and responses.  Programmers would 
therefore have a unified framework with which 
to construct remote queries and route responses, 
a framework which could be used across 
disparate scientific disciplines 
(genomics, \NLP{}, epidemiology, and so forth). 
\end{description}}

\p{In short, the code libraries decribed above would 
augment the value of \Cnineteen{} by providing 
tools out-of-the-box to help scientists 
(and their codewriters) leverage \Cnineteen{} data.  
Although we can expect that numerous code libraries 
will be implemented so that researchers can 
use \Cnineteen{}, a \Cnineteen{} \SDK{} 
would be beneficial because it would integrate 
\textit{multiple} libraries into a single package, 
designed to be easily interoperable.  
In particular, these libraries would be implemented 
in a manner which prioritizes rapid development: 
the \SDK{} would comprise a \textit{standalone} 
and \textit{self-contained} development 
environment with minimal external dependencies.  
This priority would extend also to software 
tools that would be bundled together with 
the new code libraries.  These software 
tools are discussed next.}

\section{The Software Application Package within the Proposed SDK}
\p{In addition to the code libraries described 
above, whose purpose would be to manipulate 
\Cnineteen{} data to prepare for text mining and 
data mining operations, our proposed \SDK{} would 
bundle numerous applications used for database 
storage, data visualization, and scripting.  
The goal of this application package would be to 
provide researchers with a self-contained computing 
platform optimized for scientific research 
and findings related to 
\Covid{}.  The components within this application 
package would be selected with an emphasis on 
tools that could be distributed in source-code 
fashion, and then compiled within the \SDK{}'s 
development framework with few, if any, external 
dependencies.  In short, the \SDK{} would try 
to eliminate almost all scenarios where 
programmers would need to perform a \q{system 
install}; for the most part, the entire 
computing platform (including scripting 
and database capabilities) could be compiled 
from source \q{out-of-the-box}.  The 
\SDK{} would also modify the applications 
included in the package (e.g., embedding 
plugins to enable the applications to share 
data amongst themselves) so as to enhance 
their interoperability and 
their usefulness for \Covid{} research.} 

\p{The applications bundled with the \SDK{} would 
likely include the following components:

\begin{itemize}

\item \XPDF{}: A \PDF{} viewer for reading full-text articles 
(augmented with \Cnineteen{} features, such as integration 
with biomedical ontologies);

\item AngelScript: An embeddable scripting engine 
that could be used for analytic processing 
of data generated by text and data mining operations 
on \Cnineteen{} (see \cite{AS});

\item WhiteDB: A persistent database 
engine that supports both relational 
and \NoSQL{}-style architectures 
(see \cite{EnarReilent});

\item IQmol: Molecular Visualization software 
that can be used to study chemical data 
presented in formats such as \PDB{} which 
are employed by some \Covid{} data sets;

\item MeshLab: A general-purpose \ThreeD{} graphics 
viewer;
 
\item UDPipe: a \Cpp{} library for manipulating 
\CoNLL{} data;

\item LaTeXML: a \LaTeX{}-to-\XML{} converter;

\item PositLib: a library for use in high-precision computations based on the \q{Universal Number} format, 
which is more accurate than traditional floating-point 
encoding in some scientific contexts 
(see \cite{JohnGustafson}).
 
\end{itemize}}
  

\p{It is worth noting that a data-mining platform requires 
\textit{machine-readable} open-access research data
(which is a more stringent requirement than simply 
pairing publications with data that can only 
be understood by domain-specific 
software).  For example, radiological imaging can be a source 
of \Covid{} data insofar as patterns of lung 
scarring, such as \q{ground-glass opacity,} are a leading 
indicator of the disease.  Consequently, diagnostic 
images of \Covid{} patients are a relevant kind of 
content for inclusion in a \Covid{} data set 
(see \cite{Shi} as a case-study).  However, 
diagnostic images are not in themselves 
\q{machine readable.}  When medical imaging is 
used in a quantitative context (e.g., applying 
Machine Learning for diagnostic pathology), it is necessary 
to perform Image Analysis to convert the raw data 
--- in this case, radiological graphics --- into 
quantitative aggregates.  For instance, by using image 
segmentation to demarcate geometric boundaries one 
is able to define diagnostically relevant features (such 
as opacity) represented as a scalar field over the segments.  
In short, even after research data is openly published, 
it may be necessary to perform 
additional analysis on the data for it to be 
a full-fledged component of a 
machine-readable information space.\footnote{%
\raisebox{-10pt}{\hspace{3pt}\parbox{.9\textwidth}{This does not mean that diagnostic images (or 
other graphical data) should not be placed in a 
data set; only that computational reuse of such 
data will usually involve certain numeric 
processing, such as image segmentation.  
Insofar as this subsequent analysis is performed, 
the resulting data should wherever possible 
be added to the underlying image data as a 
supplement to the data set.}}}  To 
deal with this sort of situation, our 
proposed \SDK{} would include a \textit{procedural 
data-modeling vocabulary} that would both identify the 
interrelationships between data representations 
and define the workflows needed to 
convert \Cnineteen{}-linked research data 
into machine-readable data sets.} 

\p{Another concern in developing an integrated \Cnineteen{} 
data collection is that of indexing \Covid{} data 
for both text mining \textit{and} data mining.  
In particular, 
our proposed \SDK{} would introduce a 
system of \textit{microcitations} that apply 
to portions of manuscripts \textit{as well as} data sets.  
In the publishing context, a microcitation is defined as a 
reference to a partially isolated fragment of a larger 
document, such as a table or figure illustration, or a 
sentence or paragraph defining a technical term, 
or (in mathematics) the statement/proof of a definition, axiom, 
or theorem.  In data publishing, \q{data citations} are 
unique references to data sets in their entirety or to 
their smaller parts.  A data microcitation is then a 
fine-grained reference into a data set.  For example, 
a data microcitation can consist of one 
column in a spreadsheet, 
one statistical parameter in a quantitative analysis, 
or \q{the precise data records actually used in a study} 
(in the words adopted by the Federation of Earth Science Information Partners to define microcitations; 
see \cite{ESIP}).}

\p{The unique feature we propose 
for our \SDK{} would be to combine the text-mining and 
data-mining notions of microcitation into a \textit{unified} 
framework.  In particular, text-based searches 
against the \Cnineteen{} corpus 
would try to find matches in the 
data sets indexed by our \SDK{} alongside matches within textual content.  As a concrete example, 
a concept such as \q{expiratory flow} appears in \Cnineteen{} 
both as a table column in research data and as a medical concept 
discussed in research papers; a unified microcitation framework 
should therefore map \textit{\color{drp}{expiratory flow}} as a keyphrase 
to both textual locations and data set parameters.  
Similarly, a concept such as 
\textit{\color{drp}{2{\textquotesingle}-C-ethynyl}} (mentioned earlier, in the context of transcription errors) 
should be identified both as a phrase in 
article texts and as a molecular component 
present within compounds whose scientific 
properties are investigated through \Cnineteen{} 
research data.  In so doing, a search for this 
concept would then trigger both publication and 
data-set matches at the same time.}

\LVee{}
\section{The AXF (Annotation Exchange) Format}
\p{Conceptually, \AXF{} is intended for document 
preparation as well as for text mining.  
As a rule, annotations deliberately introduced 
by authors or editors are more likely to be 
accurate than annotations which depend on 
Machine Learning or Natural Language Processing.  
As a result, the best paradigm for machine-readable 
document corpora 
(that are well-suited for text mining purposes) 
are publications composed in anticipation of 
archival text-mining requirements.  The goal 
of \AXF{} is to facilitate the creation of 
such archives in the future while \textit{also} 
supporting text mining technology in the present.  
These two goals are interrelated, because the 
data structures supporting human-annotated 
documents can also serve as guidelines for 
aggregating information gleaned from Natural Language Processing 
modules.}

\p{Producing annotations as part of the document-preparation 
process represents a relatively minor extension to the tasks 
of authoring and compositing documents.  
For example, many text segments that would be 
annotated as Named Entities --- such as acronyms, 
chemical formulae, technical jargon, etc. --- 
require distinct typesetting rules to visually 
differentiate them from normal text.  In \LaTeX{}, 
the corresponding commands can then be redefined 
to output annotation data to an auxiliary file, 
before applying the relevant typesetting instructions.  
Similarly, for \XML{}-based documents, tag and attribute 
names may be used to isolate charater sequences which 
are candidates for annotation.  Manuscript composition 
rules also regulate document structure in ways that 
promote trivial pattern extraction: paragraphs are 
always denoted by tags or commands, and sentence 
boundaries are identified by bare punctuation (in 
well-formed \LaTeX{}, for instance, periods which 
are \textit{not} punctuation markers have distinct 
kerning rules and therefore should be notated with 
distinct commands).  Consequently, when dealing 
with either \LaTeX{} or \XML{}, relatively trivial 
authoring or editing paradigms can be readily applied 
in order to generate highly structured documents 
with built-in sentence and Named Entity demarcations.}

\p{The \AXF{} format is built around data 
structures that may be produced automatically 
by pre- and post-processing manuscripts which 
adhere to certain simple conventions.  In particular, 
these data structures assert the character indices, 
paragraph and sentence ids, page numbers, and 
\PDF{} page/viewport coordinates for Named Entities 
(as well as quotations, hyperref links, equations, and 
other semantically consequential locations in publication 
content).  This degree of semantic detail is 
possible when text-mining operations are anticipated 
during the publication process.  Of course, 
\NLP{}-based text-mining 
technology is needed 
for the relatively less-well-structured publications 
which constitute most of our digital ecosystem.  
With the manuscript-based genre of annotation --- produced 
directly from pre-publication manuscripts --- serving as a 
foundation, \AXF{}, accordingly, generalizes to include 
notation related to text and data mining \API{}s and 
file formats.  For example, an \AXF{} representation 
can decribe requests and responses against the 
BeCAS or NextBio \API{}s, or encapsulate 
a file in formats such as \CoNLL{} or \PMML{} 
(Predictive Model Markup Language).}

\p{Operationally, \AXF{} is modeled most 
directly on the BeCAS \API{} \cite{TiagoNunes}.  
In particular, 
the \AXF{} toolkit includes a command-line 
tool to \q{query} manuscripts using an 
interface based on BeCAS.  However, \AXF{} 
also supports the representation of data 
structures used by a variety of 
data and text mining tools and methodologies, 
such as \PMML{}, \ARFF{} (Attribute-Relation File Format), 
\IeXML{}, \CoNLLU{}, OpenAnnotations, and \SciXML{}.  
Moreover, \AXF{} can certainly expand 
to support new capabilities or resources, 
based on the practical requirements of projects 
such as \Cnineteen{}.}

\p{For document preparation, \AXF{} is 
paired with our Hypergraph Text Encoding Protocol 
(\HTXN{}), which provides a canonical character 
encoding against which annotations can be 
defined.  Within this protocol, an annotation target is 
a character-index interval in the context of an 
\HTXN{} character stream.  On that basis, 
\HTXN{} treats documents as graphs whose nodes 
are ranges in a character stream, where text can 
be recovered as an operation on one or more nodes 
(e.g., the text of a sentence is derived from a 
pair of nodes representing the sentence's start 
and end).  \lHTXN{} code-points 
are distinguished in terms of their semantic 
role, which may be more granular than their 
visible appearance --- for example, 
a period glyph is assigned different code-points 
depending on whether it marks a sentence-ending 
punctuation, an abbreviation, a decimal point, 
or part of an ellipsis.  Procedures are then implemented to 
represent text in different formats, such as 
\ASCII{}, Unicode, \XML{}, or \LaTeX{}.  In 
contrast to a format such as Web Annotations, 
any particular human-readable text presentation 
(including \ASCII{}) is considered a \textit{derived} 
property of the annotation, not a foundational 
representation.}

\p{Both \AXF{} and \HTXN{} are integrated with 
tools which have been proposed for the 
\Cnineteen{} \q{application package}.  In particular, 
LTS has implemented a modified version of the 
\XPDF{} viewer which extracts embedded files 
containing \AXF{} and \HTXN{} data, using this 
information to make context menus sensitive to the 
location of text which is an annotation 
target, as well as to sentence boundaries, 
in the \PDF{} viewport (allowing the reader, 
for instance, to automatically copy one sentence's 
text to the clipboard, were the relevant 
sentence is identified by mouse position).  
Similarly, LTS has implemented an AngelScript 
interface which can be used to query 
manuscripts for \AXF{} data.  These 
viewer and query capabilities are 
provided as Research Object code that may be 
included in published data sets.  Anyone 
who downloads data sets constructed according 
to this protocol therefore has access to a 
document viewer which internally supports 
\AXF{} text-extraction features.}
\LWedge{}

\section{Conclusion}
\p{The LTS vision of a \textit{standalone} and 
\textit{self-contained} \Covid{} data-set 
collection is consistent with 
new publishing initiatives such as 
Research Objects (see \cite{KhalidBelhajjame}) 
and \FAIR{} (\q{Findable, Accessible, 
Interoperable, Reusable}; see \cite{TrifanOliveira}).  
Indeed, our \Cnineteen{} \SDK{} would 
function as a macro-scale Research Object, 
which would be (1) \textit{self-contained} (with few or no external 
dependencies); (2) \textit{transparent} (meaning that 
all computing operations should be implemented by 
source code within the bundle that can be examined 
as code files and within a debugging session); 
and (3) interactive (meaning that the bundle does not 
only include raw data but also software to interactively 
view and manipulate this data).  Research Objects which 
embrace these priorities attempt to provide data visualization, 
persistence, and analysis through \GUI{}, database, and 
scripting engines that can be embedded as source 
code in the Research Object itself.  
Our proposed \SDK{} would be based on the 
same paradigm, but instead of applying the Research Object 
model to a single data set, our \SDK{} would 
translate it to a larger data space, integrating 
the information contained in multiple 
\Covid{} data sets as well as the entire 
corpus of \Cnineteen{} articles.}

\vspace{-.5em}
%\noindent\lun{ETS\textsc{pf} for Scientific and Technical Applications}

\setlength{\bsep}{-2pt}
%\setlength{\parskip}{0pt}
%\setlength{\itemsep}{-2pt}

\makeatletter
    \clubpenalty10000
    \@clubpenalty \clubpenalty
    \widowpenalty10000
\makeatother

\begin{thebibliography}{99}
\vspace{1.5em}
\bibitem{KhalidBelhajjame}{%
	Khalid Belhajjame, \textit{et. al.},
	\q{Workflow-centric research objects:  First class citizens in scholarly discourse}.	\biburl{https://pages.semanticscholar.org/coronavirus-research}}

\bibitem{CORD}{%
	\q{COVID-19 Open Research Dataset (CORD-19)}. 2020. Version 2020-03-13. Retrieved from https://pages.semanticscholar.org/coronavirus-research. Accessed 2020-03-20. doi:10.5281/zenodo.3715506
	\biburl{https://pages.semanticscholar.org/coronavirus-research}}
\bibitem{Eyer}{%
	Lud\"ek Eyer, \textit{et. al.},
	\q{Nucleoside analogs as a rich source of antiviral agents active against arthropod-borne flaviviruses}.
	\biburl{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5890575/}}

\bibitem{JohnGustafson}{%
	John Gustafson,
	\q{Beating Floating Point at its Own Game: Posit Arithmetic}, 
	\biburl{http://www.johngustafson.net/pdfs/BeatingFloatingPoint.pdf}}


\bibitem{AS}{%
	Andreas J\"onsson,
	\q{AngelCode Scripting Library}, 
	\biburl{www.AngelCode.com/AngelScript/}}

\bibitem{NeusteinText}{%
	Amy Neustein, \textit{et. al.},
	\q{Application of Text Mining to Biomedical Knowledge Extraction: Analyzing Clinical Narratives and Medical Literature}, 
	\biburl{https://www.researchgate.net/publication/262372604_Application_of_Text_Mining_to_Biomedical_Knowledge_Extraction_Analyzing_Clinical_Narratives_and_Medical_Literature}}

\bibitem{TiagoNunes}{%
	Tiago Nunes, \textit{et. al.},
	\q{BeCAS: biomedical
concept recognition services and visualization}.
	\biburl{https://www.ncbi.nlm.nih.gov/pubmed/23736528}}

\bibitem{ESIP}{%
Mark A. Parsons and Ruth Duerr,
\q{Data Identifiers, Versioning, and Micro-citation}, 
\biburl{https://www.thelancet.com/action/showPdf?pii=S1473-3099\%2820\%2930086-4}}

\bibitem{EnarReilent}{%
	Enar Reilent,
	\q{Whiteboard Architecture for the Multi-agent Sensor Systems}, 
	\biburl{https://www.thelancet.com/action/showPdf?pii=S1473-3099\%2820\%2930086-4}}
\bibitem{Shi}{%
	Heshui Shi, \textit{et. al.},
	\q{Radiological findings from 81 patients with COVID-19 
		pneumonia in Wuhan, China: a descriptive study}.
	\biburl{https://www.thelancet.com/action/showPdf?pii=S1473-3099\%2820\%2930086-4}}

\bibitem{TrifanOliveira}{%
	Alina Trifan and Jos\'e Lu\'\i{}s Oliveira,
	\q{FAIRness in Biomedical Data Discovery}.
	\biburl{https://www.researchgate.net/publication/331775411_FAIRness_in_Biomedical_Data_Discovery}}


\end{thebibliography}

\end{document}


