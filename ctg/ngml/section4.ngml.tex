
\section{Pragmatics and Logical Incompleteness}
\p{Another motivation for something like an Interface Theory of Meaning 
comes from cases where language users seem to traffic in 
a relative \i{absence} of semantic determinism, with no 
detrimental effects to the \i{telos} of language in context.  
This buttresses an idea that language is not targeted at 
doxic specificity as a precondition for meaning in general, 
but rather packages doxa along with other contextualizing 
constituents in the service of pragmatic ends.  
Consider:
\begin{sentenceList}\sentenceItem{} My colleague Ms. O'Shea would like to interview
Mr. Jones, who's an old friend of mine.  Can he take this call?
\sentenceItem{} \label{itm:Jones} I'm sorry, this is his secretary.  Mr. Jones
is not available at the moment.
\end{sentenceList}
It sounds like Ms. O'Shea is trying to use personal
connections to score an interview with Mr. Jones.  Hence
her colleague initiates a process intended to
culminate in Ms. O'Shea getting on the telephone
with Mr. Jones.  But his secretary demurs with a
familiar phrase, deliberately formulated to
foment ambiguity: (\ref{itm:Jones}) could mean that Mr. Jones
is not in the office, or that he is in a meeting, or he is
unwilling to talk, or even missing (like
the ex-governor consummating an affair in Argentina
while his aides thought he was hiking in Virginia).
Or:
\begin{sentenceList}\sentenceItem{} Mr. Jones, were you present at a meeting where
the governer promised your employer
a contract in exchange for campaign contributions?
\sentenceItem{} After consulting with my lawyers, I decline
to answer that question on the grounds that it
may incriminate me.
\end{sentenceList}
Here Mr. Jones neither confirms nor denies his
presence at a corrupt meeting.
}
\p{As these examples intimate, the processes language
initiates do not always result in a meaningful
logical structure.  But this is not necessarily
a complete breakdown of language:
\begin{sentenceList}\sentenceItem{} \label{itm:isJones} Is Jones there?
\sentenceItem{} \label{itm:not} He is not available.
\end{sentenceList}
The speaker of (\ref{itm:not}) does not
provide any prima facie logical content: it neither affirms
nor denies Jones's presence.  Nonetheless that speaker
is a cooperative conversational partner
(even if they are not being very cooperative in real life):
(\ref{itm:not}) responds to the implicature in
(\ref{itm:isJones}) that what the
first speaker really wants is
to interview Jones.
So the second speaker conducts what I called
a \q{transform} and maps \i{Jones is here} to
\i{Jones is willing to be interviewed}.
Responding to this \q{transformed} question allows
(\ref{itm:not}) to be (at least) linguistically cooperative
while nonetheless avoiding a response at the
\i{logical} level to (\ref{itm:isJones}).  (\ref{itm:not}) obeys
conversational maxims but is still rather obtuse.
}
\p{So one problem for theories that read meanings in terms
of logically structured content \mdash{} something like, the
meaning of an (assertorial) sentence is what the world would be
like if the sentence were true \mdash{} is that the actual
logical content supplied by some constructions
(like \i{Jones is not available}) can be pretty
minimal \mdash{} but these are still valid and
conversationally cooperative segments of discourse.  To be sure, this
content does not appear to be \i{completely}
empty: \q{Jones is not available} means the
conjunction of several possibilities (he cannot be found
or does not want to talk or etc.).
So (\ref{itm:not}) does seem to evoke some
disjunctive predicate.  But such does not mean
that this disjunctive predicate is the \i{meaning} of
(\ref{itm:not}).  It does not seem as if (\ref{itm:not})
when uttered by a bodyguard is intended first and foremost to
convey the disjunctive predicate.  Instead, the
bodyguard is responding to the implicature
in the original \i{Is Jones there?} query \mdash{} the
speaker presumably does not merely want
to know Jones's location, but to see Jones.
Here people are acting out social roles, and just happen
to be using linguistic expressions to negotiate
what they are able and allowed to do.
}
\p{Performing social roles \mdash{} including through language \mdash{}
often involves incomplete information: possibly
the secretary or bodyguard themselves do not know
where Jones is or why he's not available.
We could argue that there is \i{enough} information to
still ground \i{some} propositional content.  But this
is merely saying that we can extract some propositional content from
what speakers are supposed to say as social acts, which seems
to make the content (in these kinds of cases)
logically derivative on the enactive/performative
meaning of the speech-acts, whereas a truth-theoretic
paradigm would need the derivational dependence
to run the other way.  By saying \i{Jones is unavailable}
the speaker is informing us that our own prior speech
act (asking to see or talk to him) cannot have
our desired effect \mdash{} the process we initiated cannot be
completed, and we are being informed of that.  The
person saying \i{Jones is unavailable} is likewise
initiating a \i{new} process, one that counters our process
and, if we are polite and cooperative, will have its
own effect \mdash{} the effect being that we do not insist on
seing Jones.  The goal of \q{Jones is unavailable} is to create
that effect, nudging our behavior in that direction.
Any \i{logic} here seems derivative on the practical initiatives.
}
\p{And moreover this practicality is explicitly marked by how
the chosen verbiage is deliberately vague.  The declaration
\q{Jones is unavailable} does not \i{need} logical precision to
achieve its effect.  It needs \i{some} logical content, but it exploits a
kind of disconnect between logicical and practical/enactive
structure, a disconnect which allows \q{Jones is unavailable} to
be at once logically ambiguous and practically clear \mdash{}
in the implication that we should not try to see Jones.
I think this example has some structural
analogs to the grandma's window case: \i{there} we
play at logical substitutions to respond practically
to grandma's request in spirit rather than \i{de dicto}.
\i{Here}  a secretary or bodyguard can engage in logical
substitution to formulate a linguistic performance
designed to be conversationally decisive
while conveying as little information as possible.  The logical
substitution in grandma's context \i{added} logical content by
trying alternatives for the window being closed; here,
the context allows a \i{diminution} in
logical content.  We can strip away logical detail from
our speech without diminishing the potency of
that speech to achieve affects.  And while the remaining residue
of logical content suggests that some basic logicality is still
essential to meaning, the fact that logical content can
be freely subtracted without altering practical effects
suggests that logic's relation to meaning is something
other than fully determinate: effect is partially autonomous from
logic, so a theory of effect would seem to be
partially autonomous from a theory of logic.
I can be logically vague without being
conversationally vague.   This evidently means that conversational
clarity is not identical to logical clarity.
}
\subsection{Interpretive Processes and Triggers}
\p{We can, indeed, find certain analogs between formal logic 
and Natural Language \mdash{}
for example, singular/plural \i{can} be a basically straightforward 
translation of the
individual/set distinction in symbolis logic.  Such
formal intuitions are limited in the sense that (to
continue this example) the conceptual mapping from
single to plural can reflect a wide range of
residual details beyond just quantity and multitudes.
Compare \i{I sampled some chocolates} (where the count-plural
suggests \i{pieces} of chocolate) and
\i{I sampled some coffees} (where the count-plural implies
distinguishing coffees by virtue of grind, roast, and other
differences in preparation) (note that both are contrasted
to mass-plural forms like \i{I sampled some coffee} where
plural agreement points toward material continuity; there
is no discrete unit of coffee qua liquid).  Or compare
\i{People love rescued dogs} with \i{People fed the rescued dogs}
\mdash{} the second, but not the first, points toward
an interpretation that certain \i{specific} people
fed the dogs (and they did so \i{before} the dogs
were rescued).
}
\p{The assumption that logical modeling can capture all the
pertinent facets of Natural-Language meaning can
lead us to miss the amount of situational reasoning
requisite for commonplace understanding.  In
\i{People fed the rescued dogs} there is an exception to the
usual pattern of how tense and adjectival modification
interact: we read \q{people fed} in
\i{People fed the rescued dogs} as occurring \i{before} the rescue;
because we assume that \i{after} being rescued the dogs would be
fed by veterinarians and other professionals (who would
probably not be designated with the generic \q{people}), and
also we assume the feeding helped the dogs survive.  We also
hear the verb as describing a recurring event; compare
with \i{I fed the dog a cheeseburger}.
}
\p{To be sure, there are patterns and templates governing
scope/quantity/tense interactions that help us build logical models
of situations described in language.  Thus
\i{I fed the dogs a cheeseburger} can be read such that there
are multiple cheeseburgers \mdash{} each dog gets one \mdash{}
notwithstanding the singular form on \i{a cheeseburger}:
the plural \i{dogs} creates a scope that can elevate
the singular \i{cheeseburger} to an implied plural;
the discourse creates multiple reference frames each
with one cheeseburger.  Likewise the morphosyntax is
quite correct in: \i{All the rescued dogs are taken to an
experienced vet; in fact, they all came from the same
veterinary college} \mdash{} the singular on \i{vet} is properly
alligned with the plural \i{they} because of the scope-binding
(from a syntactic perspective) and space-building
(from a semantic perspective) effects of the \q{dogs} plural.
Or, in the case of \i{I fed the dog a cheeseburger every day}
there is an implicit plural because \q{every day} builds
multiple spaces: we can refer via the spaces collectively
using a plural (\i{I fed the dog a cheeseburger every day \mdash{}
I made them at home with vegan cheese}) or refer within
one space more narrowly, switching to the singular
(\i{Except Tuesday, when it was a turkey burger}).
}
\p{Layers of scope, tense, and adjectives interact in complex ways that
leave room for common ambiguities: \i{All the rescued dogs are [/were]
taken to an experienced [/specialist] vet} is consistent with a reading
wherein there is exactly one vet, and she has or had treated every dog.
It is \i{also} consistent with a reading where there
are multiple vets and each dog is or was treated
by one or another.  Resolving such ambiguities
tends to call for situational reasoning and a \q{feel} for situations,
rather than brute-force logic.  If a large dog shelter describes
their operational procedures over many years, we might assume
there are multiple vets they work or worked with.  If instead the
conversation centers on one specific rescue we would be
inclined to imagine just one veterinarian.  Lexical and tense
variation also guides these impressions: the past-tense
form (\i{...the rescued dogs were taken...}) nudges us
toward assuming the discourse references one rescue (though it
could also be a past-tense retrospective of general operations).
Qualifying the vet as \i{specialist} rather than the vaguer
\i{experienced} also nudges us toward a singular interpretation.
}
\p{What I am calling a \q{nudge}, however, is based on situational
models and arguably flows from a conceptual stratum outside
of both semantics and grammar proper; maybe it is even prelinguistic.
Consider
\begin{sentenceList}\sentenceItem{} \label{itm:pf} People fed the rescued dogs.
\sentenceItem{} \label{itm:ve} Vets examined the rescued dogs.
\end{sentenceList}
There appears to be no explicit principle either in the semantics
of the lexeme \i{to feed}, or in the relevant tense agreements,
stipulating that the feeding in (\ref{itm:pf})
was prior to the rescue \mdash{} or conversely that
(\ref{itm:ve}) describes events
\i{after} the rescue.  Instead, we interpret the discourse through
a narrative framework that fills in details not provided by
the language artifacts explicitly (that abandoned dogs are
likely to be hungry; that veterinarians treat dogs in clinics, which
dogs have to be physically brought to).  For a similar case-study,
consider the sentences:
\begin{sentenceList}\sentenceItem{} Every singer performed two songs.
\sentenceItem{} Everyone performed two songs.
\sentenceItem{} Everyone sang along to two songs.
\sentenceItem{} Everyone in the audience sang along to two songs.
\end{sentenceList}
The last of these examples strongly suggests that of potentially
many songs in a concert, exactly two of them were popular and singable
for the audience.  The first sentence, contrariwise, fairly strongly
implies that there were multiple pairs of songs, each pair performed
by a different singer.  The middle two sentences imply either
the first or last reading, respectively (depending on how we
interpret \q{everyone}).  Technically, the
first two sentences imply a multi-space reading and the latter two
a single-space reading.  But the driving force
behind these implications are the pragmatics of \i{perform} versus
\i{sing along}: the latter verb is bound more tightly to
its subject, so we hear it less likely that
\i{many} singers are performing \i{one} song pair, or conversely that
every audience member \i{sings along} to one song pair, but
each chooses a \i{different} song pair.
}
\p{The competing interpretations for \i{perform} compared to
\i{sing along}, and \i{feed} compared to \i{treat}, are grounded
in lexical differences between the verbs, but I contend
the contrasts are not laid out in lexical specifications
for any of the words, at least so that the implied readings
follow just mechanically, or on logical considerations
alone.  After all, in more exotic but not implausible
scenarios the readings would be reversed:
\begin{sentenceList}\sentenceItem{} The rescued dogs had been treated by vets in the past
(but were subsequently abandoned by their owners).
\sentenceItem{} Every singer performed (the last) two songs
(for the grand finale).
\sentenceItem{} Everyone in the audience sang along to two songs
(they were randomnly handed lyrics to different songs when
they came in, and we asked them to join in when the song being
performed onstage matched the lyrics they had in hand).
\end{sentenceList}
In short, it's not as if dictionary entries would specify that
\i{to feed} applies to rescued dogs before they are rescued,
and so forth; these interpretations are driven by narrative
construals narrowly specific to given expressions.  The
appraisals would be very different for other uses of the verbs in
(lexically) similar (but situationally different) cases:
to \q{treat} a wound or a sickness, to \q{perform} a gesture or a
play.  We construct an interpretive scaffolding
for resolving issues like scope-binding and space-building based
on fine-tuned narrative construals that can vary alot
even across small word-sense variance:
As we follow along with these sentences, we have to build a narrative
and situational picture which matches the speaker's intent,
sufficiently well.
}
\p{And that requires prelinguistic background
knowledge which is leveraged and activated (but not mechanically
or logically constructed) by lexical, semantic, or grammatical
rules and forms: \i{rescued dogs} all alone constructs a fairly
detailed mental picture where we can fill in many details by
default, unless something in the discourse tells otherwise
(we can assume such dogs are in need of food, medical care,
shelter, etc., or they would not be describd as
\q{rescued}).  Likewise \i{sing along} carries a rich mental
picture of a performer and an audience and how they interact, one
which we understand based on having attended concerts rather than
by any rule governing \i{along} as a modifier to \q{sing}
\mdash{} compare the effects of \i{along} in \i{walk along},
\i{ride along}, \i{play along}, \i{go along}.  Merely
by understanding how \i{along} modifies \i{walk}, say
(which is basically straightforward; to
\q{walk along} is basically to \q{walk alongside}) we
would not automatically generalize to more idiomatic
and metaphorical uses like \q{sing along} or \q{play along}
(as in \i{I was skeptical but I played along (so as not to
start an argument)}).
}
\p{We have access to a robust collection of \q{mental scripts} which
represent hypothetical scenarios and social milieus where
language plays out.  Language can activate various such
\q{scripts} (and semantic as well as grammatical formations
try to ensure that the \q{right} scripts are selected).
Nonetheless, we can argue that the conceptual and cognitive
substance of the scripts comes not from language per se
but from our overall social and cultural lives.
We are disposed to make linguistic inferences \mdash{} like
the timeframes implied by \i{fed the rescued dogs} or the scopes
implied by \i{sang along to two songs} \mdash{} because of
our enculturated familiarity with events like dog rescues
(and dog rescue organizations) and concerts
(plus places like concert halls).  These concepts are not
produced by the English language, or even by any dialect
thereof (a fluent English speaker from a different
cultural background would not necessarily make the
same inferences \mdash{} and even if we restrict attention to,
say, American speakers, the commonality of disposition
reflects a commonality of the relevant cultural
anchors \mdash{} like dog rescues, and concerts \mdash{} rather than
any homogenizing effects of an \q{American} dialect).
For these reasons, I believe that trying to account for
situational particulars via formal language models alone
is a dead end.  This does not mean that formal language
models are unimportant, only that we need to picture them
resting on a fairly detailed prelinguistic
world-disclosure.
}
\p{There are interesting parallels in this thesis to the role
of phenomenological analysis, and the direct thematization
of issues like attention and intentionality: analyses
which are truly \q{to the things themselves} should take for
granted the extensive subconscious reasoning that undergirds
what we consciously thematize and would be aware of, in terms of
what we deliberately focus on and are conscious of
believing (or not knowing), for a first-personal \expose{}.
Phenomenological analysis should not consider itself as
thematizing every small quale, every little patch of
color or haptic/kinasthetic sensation which by some subconscious
process feeds into the logical picture of our surroundings that
props up our conscious perception.  Analogously, linguistic
analysis should not thematize every conceptual and inferential
judgment that guides us when forming the mental, situational
pictures we then consult to set the groundwork for linguistic
understanding proper.
}
\p{These comments apply to both conceptual \q{background knowledge} and
to situational particulars of which we are cognizant in
reference to our immediate surroundings and actions.  This
is the perceptual and operational surrounding that gets
linguistically embodied in deictic reference and other
contextual \q{groundings}.  Our situational awareness therefore
has both a conceptual aspect \mdash{} while attending a concert,
or dining at a restaurant, say, we exercise cultural background
knowledge to interpret and participate in social events
 \mdash{} and also our phenomenological construal of our locales,
our immediate spatial and physical surroundings.
Phenomenological philosophers have explored in detail how these
two facets of situationality interconnect (David Woodruff Smith and
Ronald McIntyre in \i{Husserl and Intentionality:
A Study of Mind, Meaning, and Language}, for instance).
Cognitive Linguistics covers similar territory; the \q{cognitive}
in Cognitive Semantics and Cognitive Grammar generally tends
to thematize the conception/perception interface and
how both aspects are merged in situational understanding
and situationally grounded linguistic activity (certainly
more than anything involving Artificial Intelligence or
Computational Models of Mind as are connoted by terms like
\q{Cognitive Computing}).  Phenomenological and Cognitive
Linguistic analyses of situationality and perceptual/conceptual
cognition (cognition as the mental synthesis of
preception an conceptualization) can certainly enhance and
reinforce each other.
}
\p{But in addition, both point to a cognitive and situational
substratum underpinning both first-person
awareness and linguistic formalization proper \mdash{} in other words,
they point to the thematic limits of
phenomenology and Cognitive Grammar and
the analytic boundary where they give way to
an overarching Cognitive Science.  In the case of
phenomenology, there are cognitive structures that suffuse
consciousness without being directly objects of attention
or intention(ality), just as sensate hyletic experience is
part our consciousness but not, as explicit content,
something we in the general case are conscious \i{of}.
Analogously, conceptual and situational models
permeate our interpretations of linguistic forms, but
are not presented explicitly \i{through} these
forms: instead, they are solicited obliquely and
particularly.
}
\p{What phenomenology \i{should} explicate is not background situational
cognition but how attention, sensate awareness, and intentionality
structure our orientation \i{\visavis{}} this background: how variations
in focus and affective intensity play strategic roles in our engaged
interactions with the world around us.  Awareness is a scale, and
the more conscious we are of a sense-quality, an attentional focus,
or an epistemic attitude, reflects our estimation of the
importance of that explicit content compared to a muted experiential
background.  Hence when we describe consciousness as a stream
of \i{intentional} relations we mean not that the intended
noemata (whether perceived objects or abstract thoughts)
are sole objects of consciousness (even in the moment)
but are that within conscious totality which we are most aware
of, and our choice to direct attention here and there reflcts our
intelligent, proactive interacting with the life-world.
Situational cognition forms the background,
and phenomenology addresses the structure of intentional
and attentional modulations constituting the conscious
foreground.
}
\p{Analogously, the proper role for linguistic
analysis is to represent how multiple layers or strands
of prelinguistic understanding, or \q{scripts}, or
\q{mental spaces}, are woven
together by the compositional structures of language.
For instance, \i{The rescued dogs were treated by an experienced vet}
integrates two significantly different narrative frames
(and space-constructions, and so forth): the frame implied
by \q{rescued dogs} is distinct from that implied
by \q{treated by a veterinarian}.  Note that both spaces are
available for follow-up conversation:
\begin{sentenceList}\sentenceItem{} The rescued dogs were treated by an experienced vet.
One needed surgery and one got a blood transfusion.  We went there
yesterday and both looked much better.
\sentenceItem{} The rescued dogs were treated by an experienced vet.
One had been struck by a car and needed surgery on his leg.  We
went there yesterday and saw debris from another car crash
\mdash{} it's a dangerous stretch of highway.
\end{sentenceList}
In the first sentence \i{there} designates the veterinary clinic, while in
the second it designates the rescue site.  Both of these locales are
involved in the original sentence (as locations and also
\q{spaces} with their own environments and configurations:
consider these final three examples).
\begin{sentenceList}\sentenceItem{} The rescued dogs were treated by an experienced vet.
We saw a lot of other dogs getting medical attention.
\sentenceItem{} The rescued dogs were treated by an experienced vet.
It looked very modern, like a human hospital.
\sentenceItem{} The rescued dogs were treated by an experienced vet.
We looked around and realized how dangerous that road is \mdash{}
for humans as well as dogs.
\end{sentenceList}
}
\p{What these double space-constructions reveal is that accurate
language understanding does not only require
the proper activated \q{scripts} accompanying words and
phrases, like \q{rescued dogs} and \q{treated by a vet}.
It also requires the correct integration of each script,
or each mental space, tieing them togther in accord with
speaker intent.  So in the current example we should read that
the dogs \i{could} be taken to the vet \i{because} they were
rescued, and \i{needed} to be taken to the vet \i{because} they
needed to be rescued.  Language structures guide us
toward how we should tie the mental spaces, and the
language segments where they are constructed, together: the
phrase \q{\i{rescued} dogs} becomes the subject of the passive-voice
\i{were treated by a vet} causing the two narrative strands of the
sentence to encounter one another, creating a hybrid space
(or perhaps more accurately a patterning between
two spaces with a particular temporal and causal
sequencing; a hybrid narration bridging the spaces).
It is of course this hybrid space, this narrative
recount, which the speaker intends via the sentence.  This
idea is what the sentence is crafted to convey \mdash{} not just
that the dogs were rescued, or that they were taken to a vet, but
that a causal and narrative thread links the two events.
}
\p{I maintain, therefore, that the analyses which are proper to linguistics
\mdash{} highlighting what linguistic reasoning contributes above and beyond
background knowledge and situational cognition \mdash{} should focus on
the \i{integration} of multiple mental \q{scripts},
each triggered by different parts and properties of the linguistic
artifact.  The \i{triggers} themselves can be individual words, but
also morphological details (like plurals or tense marking) and
morphological agreement.  On this theory, analysis has two distinct
areas of concerns: identification of grammatical, lexical, and
morphosyntactic features which trigger (assumedly prelinguistic)
interpretive scripts, and reconstructing how these scripts
interoprate (and how language structure determines such integration).
}
\p{In the case of isolating triggers, a wide range of linguistic features
can trigger interpretive reasoning \mdash{} including base lexical choice;
word-senses carry prototypical narrative and situational templates that
guide interpretation of how the word is used in any given context.
\i{Rescued}, for example, brings on board a network of likely
externalities: that there are rescuers, typically understood to be
benevolent and intending to protect the rescuees from harm; that
the rescuees are in danger prior to the rescue but safe afterward;
that they need the rescuers and could not have reachd safety themselves.
Anyone using the word \q{rescue} anticipates that their addressees will
reason through some such interpretive frame, so the speaker's role is
to fill in the details descriptively or deictically: who are the rescuees
and why they are in danger; who are the rescuers and why they are benevolent
and able to protect the rescuees.  The claim that
the word \i{rescue}, by virtue of its lexical properties, triggers an
interpretive \q{script}, is a proposal to the effect that when trying
to faithfully reconstruct speaker intentions
we will try to match the interpretive
frame to the current situation.
}
\p{The \q{script} triggered by word-choice is not just an interpretive
frame in the abstract, but the interpretive \i{process} that matches
the frame to the situation.  This process can be exploited for
metaphorical and figurative effect, broadening the semantic scope
of the underlying lexeme.  In the case of \q{rescue} we have less
literal and more humorous or idiomatic examples like:
\begin{sentenceList}\sentenceItem{} The trade rescued a star athlete from a losing team.
\sentenceItem{} New mathematical models rescued her original research from obscurity.
\sentenceItem{} Discovery of nearby earth-like planets rescued that
star from its reputation as ordinary and boring and revealed that its solar
system may actually be extraordinary.
\end{sentenceList}
Each of these cases subverts the conventional \q{rescue} script by
varying some of the prototypical frame details:  maybe the
\q{danger} faced by the rescuee is actually trivial (as in the
first three), or the rescuee is not a living thing
whose state we'd normally qualify in trms of \q{danger} or \q{safety},
or by overturning the benevolence we typically attribute to
rescue events.  
But in these uses subverting the familiar script does not
weaken the lexical merit of the word choice; instead, the interpretive
act of matching the conventional \q{rescue} script to the matter at hand
reveals details and opinions that the speaker wishes to convey.  The
first sentence, for instance, uses \q{rescue} to connote
that being stuck on a losing team is an unpleasant (even if not life-threatening)
circumstance.  So one part of the frame (that the rescuee needs
outside intervention) holds while the other (that
the rescue is in danger) comes across as excessive but
(by this very hyperbole) communicating speaker sentiment.  By
both invoking the \q{rescue} script and exploiting mismactches between
its template case and the current context, the speaker
conveys both situational facts and personal opinions quite
economically.  Similarly, \i{rescue a paper from obscurity} is
an economical way of saying that research work has been rediscovered
in light of new science; and \q{rescued from a reputation} is a 
clever way of describing, with rhetorical force, 
how opinion of changed about someone or something.
}
\p{All of these interpretive effects \mdash{} both conventional
and unconventional usages \mdash{} stem from the interpretive
scripts bound to words (and triggered by word-choice) at
the underlying lexical level \mdash{} we can assess these by reference
to lexical details alone, setting aside syntactic and morphological
qualities.  When morphosyntactic details \i{are} considered 
\mdash{} e.g. plurals, as in (\ref{itm:coffeetable})-(\ref{itm:coffeepot}) 
\mdash{} we then have a spectrum of other linguistic \q{triggers}, 
involving perceptual and enactive figurations (e.g. how 
plurality/multiplicities are conceived), alongside interpretive 
\q{scripts}.  My essential point however is that language 
needs to \i{trigger} certain interpretive, perceptual, and 
enactive/operational processes.  
}
\p{I contend, moreover, that these cognitive processes are not 
\i{themselves} linguistic: while they may overlap with 
some language-relevant concerns (like conceptualization, and 
doxic specificity) they are not woven from the cloth of 
syntactic, semantic, or pragmatic elements internal to language.  
It is not within the purview of linguistics then to analyze 
interpretive scripts (except as a subsidiary case-study), or 
perceptual understanding, or situationally-mediated action.  
What \i{can} be left for linguistics proper is identifying the 
\i{triggers} to these cognitive realities \mdash{} insofar as content or 
formations in language, within our goal-directed attempt to 
understand others' linguistic performances, compels us toward 
these extra-linguistic registers.
}
\p{Linguistics on this perspective is necessarily and properly incomplete: 
we should not look to linguistic analysis to materially or structurally 
explain the cognitive processes triggered by language.  But we \i{can} 
analyze the triggers themselves \mdash{} potentially via formal and 
even computational methods.  So the formal models I reviewed 
earlier \mdash{} such as the combination of Dependency graphs 
with typed S-Expressions encoded via double-indices \mdash{} can be adopted 
in a basically non-formalized, cognitive-linguistic paradigm, 
insofar as we ascribe to the global picture of language as an 
\q{interface} or \q{trigger} to extralinguistic cognition.
}
\spsubsectiontwoline{Gaps in Logical Phrase-Models}
Assume we have a baseline lamba-calculus-like 
functional summary of sentences and derived types.  That is, 
any sentence can be rewritten as if a sequence of \q{function calls}, 
assuming an underlying representational vocabulary of a typed 
lambda calculus, with sentences having overall \Prop{} types.
S-Expression reconstruction presents one layer of structure 
\mdash{} for example, the connection of verbs to their one, two, or three arguments 
\mdash{} which can then be overlaid with Link-Grammar style pairs, 
like verb-to-subject and verb-to-direct-object. 
`p`
\p{My overall goal is to embrace a hybrid methodology \mdash{} 
accepting formal analyses when they shed light on linguistic 
processes, but not going so far as to treat logical, mathematical, 
or computational models as full explanations for linguistic 
rationality qua scientific phenomenon.  
The path toward such a hybrid methodology, as I will sketch it 
here, takes its inspiration and orientation from Cognitive Grammar.  
This perspective, in particular, challenges our assumption that 
grammar and semantics are methodologically separate.  Received 
wisdom suggests that grammar concerns the \q{form} of sentences 
whereas semantics considers the meaning of words \mdash{} implicitly 
assuming that \i{word combinations} produce new meanings, and 
that the \i{order} by which words are combines determines how 
new meanings are produced.  This notion, in turn, is allied 
with the essentially logical or propositional picture of 
signifying via doxa: the idea that inter-word relations cue up 
different logically salient transformations of an underlying 
predicate model.  Thus \i{many students} as a phrase is 
more significatorily precise than \i{students} as a word, because 
the phrase (with intimations of quantitative comparison) has 
more logical detail.  Similarly \i{many students complained} 
is more logically complete because, provisioning both a verb-idea 
and a noun-idea, it represents a whole proposition. 
}
\p{In general, then, phrases are more complete than words because 
they pack together more elements which have some logical role, 
establishing individuals, sets, spatiotemporal setting, and 
predicates which collectively establish sufficiently 
completed propositional attitudes.  On this account the 
key role of phrase-structure is to establish phrases as 
signifying units on a logical level analogous to 
how lexemes are signifying units on a referential or conceptual 
level.  Moreover, phrases' internal structure are understood 
to be governed by rule defining \i{how} word-combinations 
draw in extra logical detail.  A link between words is not a 
random synthesis of concepts, but rather implies a certain 
logical connective which acts as a de facto \q{third party} in 
a double-word link, proscribing with orientation to predicate 
structures \i{how} the words' semantic concepts are to be 
joined.  In \i{many students} the implied connector is 
the propositional act of conceiving a certain quantitative 
scale to a conceptualized set; in \i{students complained} the 
implied connector is a subject-plus-verb-equals-proposition 
assertiveness.  Phrases acquire logical specificity by 
building up word-to-word connections into 
more complex aggregates.
}
\p{One implication of this model is that phrases are semantically 
substitutable with individual lexemes that carry similar meanings, 
having been entrenched by convention to capture a multipart concept 
which would otherwise be conveyed with the aggregation of a 
phrase: consider \q{MP} for \i{member of parliament}, or 
\q{primaried} for \i{subject without your own party to a primary 
challenge}.  Conversely, phrases can be repeatedly used in a 
specific context until they function as quasi lexical units in 
their own right.  These patterns of entrenchment imply that we 
hear language in term of phrases bearing semantic content; and 
insofar as we are comfortable with how we parse a sentence, each 
word sited in its specific phrasal hierarchy, we do not tend to 
consider individual words semantically outside of their 
constituent phrases.
}
\p{This theory of the syntax-to-semantic relationship is a paradigmatic 
partner, at the grammatic level, to truth-theoretic semantics and as
such, I maintain, is subject to similar critiques as I developed 
semantically in the last two sections.  A critique of grammatic theories 
based on, let's say, \q{\i{proprositional semantics of phrase-structure}} 
can address two concerns: first, the idea that lexemes retain some 
syntactic and semantic autonomy even within clearly defined phrases 
where they are included; and, second, that the shape of phrases 
insofar as they are perceived as holistic signifying units 
is often driven by figurative or \q{gestalt} principles rather than 
neat logical structuration.  I'll call the former the issue of 
\q{phrasal isolation} (or lack thereof): syntactic and semantic effect 
often cross phrasal boundaries, even outside the overarching hierarchy 
whose apex is the whole sentence.  Both of these lines of reasoning 
\mdash{} arguably especially the second \mdash{} are developed in 
Cognitive Grammar literature.   
}
\p{In Ronald Langacker's \i{Foundations of Cognitive Grammar}, the sentence
\begin{sentenceList}\sentenceItem{} \label{itm:threetimes} Three times, students asked an interesting question.
\end{sentenceList}
is used to demonstrate how
grammatical principles follow from cognitive \q{construals} of the relevant situations,
those which language seeks to describe or takes as presupposed context.\footnote{For example, \cite[pp. 119 and 128]{LangackerFoundations},
discussed by \cite[p. 189]{LineBrandt}, and \cite[p. 9]{EstherPascual}.
}
In particular, Langacker argues that \q{students} and \q{question} can both be either singular or
plural: syntax is open-ended here, with neither form more evidently correct.  Langacker uses this
example to make the Cognitive-Linguistic point that
we assess syntactic propriety relative to cognitive frames and conversational context.  In this
specific case, we are actually working with two different cognitive frames which are interlinked
\mdash{} on the one hand, we recognize distinct events consisting of a student asking a question, but
the speaker calls attention, too, to their recurrence, so the events can also be understood
as part of a single, larger pattern.  There are therefore two different cognitive foci, at two
different scales of time and attention, a \q{split focus} which makes both singular and plural
invocations of \q{student} and \q{question} acceptable.
}
\p{Supplementing this analysis, however, we can additionally focus attention directly on
grammatical relations.  The words \i{student} and \i{question} are clearly linked as the subject and
object of the verb \i{asked}; yet, contrary to any simple presentation of rules,
no agreement of singular or plural is required between them (they can be singular and/or plural in
any combination).  Moreover, this anomaly is only in force due to the context established
by an initial phrase like \i{three times}; absent some such framing, the singular/plural
relation would be more rigid.  For example, \q{A student asked interesting questions} would
(in isolation) strongly imply \i{one} student asking \i{several} questions.  So the initial
\q{Three times} phrase alters how the subsequent phrase-structure is understood while remaining
structurally isolated from the rest of the sentence.  Semantically, it suggests a
\q{space builder} in the manner of Gilles Fauconnier or Per Aage Brandt
\cite{Fauconnier}; \cite{PerAageBrandt}, but we
need to supplement Mental Space analysis with a theory of how these spaces
influence syntactic acceptability, which would seem to be logically prior to the stage where Mental Spaces
would come in play.
}
\p{The mapping of (\ref{itm:threetimes}) to a logical
substratum would be more transparent with a case like: 
\begin{sentenceList}\sentenceItem{} \label{itm:threes} Three students asked interesting questions.
\end{sentenceList}
(\ref{itm:threes}) is a more direct translation of the facts
which the original sentence conveys.  But this \q{more logical} example has different
connotations than the sentence Langacker cites; (\ref{itm:threetimes}) places the emphasis
elsewhere, calling attention more to the idea of something temporally drawn-out,
of a recurrence of events and a sense of time-scale.  The \q{more logical} sentence
lacks this direct invocation of time scale and temporal progression.
}
\p{We can say that the \q{Three students} version is a more direct statement of fact, whereas
Langacker's version is more speaker-relative, in the sense that it elaborates more
on the speaker's own acknowledgment of belief.  The speaker retraces the steps of her
coming to appreciate the fact \mdash{} of coming to realize that the \q{interesting questions}
were a recurrent phenomenon and therefore worthy of mention.  By situating expressions
relative to cognitive processes rather than to the facts themselves, the sentence
takes on a structure which models the cognition rather than the states of affairs.
But this shift of semantic grounding from the factual to the cognitive also apparently
breaks down the logical orderliness of the phrase structure.  \q{Three times}, compared
to \q{three students}, leads to a morphosyntactic choice-space which is
\q{underdetermined} and leaves room for speakers' shades of emphasis.
}
\p{This is not an isolated example.  Many sentences can be provided with similar
phrase-structure complications, particularly with respect to singular/plural agreement.
\begin{sentenceList}\sentenceItem{} Time after time, tourists (a tourist) walk(s) by this building
with no idea of its history.
\sentenceItem{} The streets around here are confusing; often people (someone)
will ask me for directions.
\sentenceItem{} Student after student came with their (his/her)
paper to compain about my grade(s).
\sentenceItem{} Student after student \mdash{} and their (his/her) parents
\mdash{} complained about the tuition increase.
\end{sentenceList}
On a straightforward phrase-structure reading, \i{student after student} reduces to an
elegant equivalent of \i{many students}, with the rhetorical flourish abstracted away
to a logical form.  But our willingness to accept both singular and plural agreements
(his/her/their parents, grades, papers) shows that clearly we don't simply substitute
\i{many students}; we recognize the plural as a logical gloss on the situation but
engage the sentence in a more cogntively complex way, recognizing connotations of temporal
unfolding and juxtapositions of cognitive frames.  The singular/plural underdeterminism
is actually a signification in its own right, a signal to the listener that the
sentence in question demands a layered cognitive attitude.  Here again, syntactic
structure (morphosyntactic, in that syntactic allowances are linked with
variations in the morphology of individual words, such as singular or plural form)
serves to corroborate conversants' cognitive frames rather than to model logical
form.
}
\p{The contrast between the phrases \i{Student after student} and \i{Many students}
cannot be based on \q{abstract} semantics alone \mdash{} how the evident temporal implications of the
first form, for example, are concretely understood, depends on conversants' mutual recognition
of a relevant time frame.  The dialog may concern a single day, a school year, many
years.  We assume that the speakers share a similar choice of time \q{scale}
(or can converge on one through subsequent conversation).  \i{Some} time-frame
is therefore presupposed in the discursive context, and the first phrase invokes
this presumed but unstated framing.  The semantics of the phrase are therefore somewhat open-ended:
the phrase \q{hooks into} shared understanding of a temporal cognitive framing without referring
to it directly.  By contrast, the second phrase is less open-ended: it is consistent with both
a more and less temporally protracted understanding of \i{many}, but leaves such details (whatever
they may be) unsignified.  The factual circumstance is designated with a level of abstraction that sets
temporal considerations outside the focus of concern.  The second (\q{\i{Many students}}) phrase 
is therefore both
less open-ended and also less expressive: it carries less detail but accordingly also relies
less on speaker's contextual understanding to fill in detail.\footnote{The examples I have used so far may also imply that a choice of phrase structure is
always driven by semantic connotations of one structure or another;
but seemingly the reverse can happen as
well \mdash{} speakers choose a semantic variant because its grammatic realization lends a useful
organization to the larger expression.  There are many ways to say \q{many},
for example: \i{a lot of},
\i{quite a few}, not to mention \q{time after time} style constructions.  Whatever their
subtle semantic variations, these phrases also have different syntactic properties:
\i{Quite a few} is legitimate as standalone (like an answer to a question);
\i{A lot of} is not, and \i{A lot} on its own is awkward.  On the other hand the \q{of} in
\i{A lot of} can \q{float} to be replicated further on: \q{A lot of students, of citizens,
believe education must be our top priority} sounds more decorous than the equivalent sentence with the
second \q{of} replaced by \q{and}.  If the cadence of that sentence appeals to the speaker, then
such stylistic preference will influence taking \q{A lot of} as the \q{many} variant of choice.
So speakers have leeway in choosing grammatic forms that highlight one or another aspect of
situations; but they also have leeway in choosing rhetorical and stylistic pitch.  Both cognitive
framings and stylistic performance can be factored when reconstructing what compels the
choice of one sentence over alternatives.
}
}
\p{One consequence of these analyses is that grammar
needs to be approached holistically: the grammatic structure of phrases cannot,
except when deliberate oversimplification is warranted, be isolated from
surrounded sentences and still larger discourse units.  Semantic roles
of phrases have some effect on their syntax, but phrases are nonetheless chosen
from sets of options, whose variations reflect subtle semantic and syntactic
maneuvers manifest at super-phrasal scales.  The constituent words of phrases retain some
autonomy, and can enter into inter-word and phrasal structures with other words outside their
immediate phrase-context.  We can still apply formal models to phrase
structure \mdash{} for example, as I mentioned, Applicative and Cognitive Grammar considers phrases
as \q{applications} of (something like) linguistic or cognitive functions,
with (say) an adjective modeled as a function applied to a noun,
to yield a different noun (viz., something playing a noun's conceptual role)
\cite{Descles2010}.
But we should not read these transformations
\mdash{} like \i{rescued dogs} from \i{dogs} \mdash{}
too hastily as a purely semantic correlation within a space of denotable concepts
\mdash{} \i{such that} the new concept wholly replaces the
contained parts, which then cease to have further linguistic role and effect.
Instead, applicative structures represent shifts or evolutions in
mental construal, which proceed in stages as conversants form
cognitive models of each others' discourse.  Even if phrase structure
sets landmarks in this unfolding, phrases do not wholly subsume their
constituents; the parts within phrases do not \q{vanish} on the higher scale,
but remain latent and may be \q{hooked} by other, overlapping phrases.
}
\p{Consider the effect of \q{Many students complained}.  Propositionally, this appears
to say essentially that \i{students} complained; but, on hermeneutic charity, the
speaker had \i{some} reason to say \q{many}.  The familiar analysis is that
\q{many} suggests relative size; but this
is only half the story.  If the speaker chose merely \i{students complained}, we would hear an assertion
that more than one student did, but we would also understand that there were several
occasions when complaints happened.  Adding \q{many} does not just
imply \q{more} students, but suggests a mental shift away from the particular episodes.
In the other direction, saying \i{a student complained} is not just
asserting how at least one student did so, but
apparently reports one specific occasion (which perhaps the speaker wishes to
elaborate on).  In other words, we cannot really capture the singular/plural semantics,
or different varieties of plural, just by looking at the relative size of implied
sets; we need to track how representations of singleness or multitude imply
temporal and event-situational details.
}
\p{Against this backdrop, \i{Student after student complained} captures both dimensions,
implying both a widespread unrest among the student body and also
temporal recurrence of complainings.
By way
of illustration, Figure ~\ref{fig:ESA} shows a
destructuring in the fashion of Dependency Grammar, 
along with implicit type annotations.  \input{figure2.tex}
As this shows, the \q{Student after Student} idiom can be notated as, say,
\AfterNSingAndNSingToNPl{} (using \NSing{} and \NPl{} to mean singular
and count-plural nouns, respectively), but with the special case that the \q{argument} to
\i{after} is repeated in both positions, suggesting an unusual degree of repetition,
something frustratingly recurrent: \i{He went on and on}; \i{Car after car passed
us by}; \i{Time after time I got turned down}.
Although I have no problem
treating these constructions as idiomatic plurals, I also contend (on the
premise of phrase-overlap) that the dependent constituents in the \BlankAfterBlank{}
construction can be hooked to other phrases as well (which is why
\q{and [their/his/her] parents} can also be singular, in this case).  I dwell on
this example because it shows how type/functional accounts of phrase structure
can be useful even if we treat phrases more as frames which overlay linguistic
structure, not as rigid compositional isolates.  Each \q{students} variation uses
morphology to nudge cognitive attention in one direction or another, toward events or the
degree to which events are representative of some global property (here of
a student body), or both.  The \NSingToNPl{} transformation is not \i{the}
morphosyntactic meaning, but instead the skeleton on which the full meaning
(via cognitive schema) is designed.
}
\p{If this analysis has merit, it suggests that an \ACG{} or type-logical
approach to phrases like \i{many students} or \i{student after student}
(singular-to-plural or plural-to-plural mappings) should be understood not just
as functions among Part of Speech (\POS{}) types but as adding cognitive shading, foregrounding
or backgrounding cognitive elements like events or typicality in some context.
In other words, \i{many students} is type-theoretically \NtoN{} or \NpltoNpl{};
but, in more detail, it adds a kind of cognitive rider attached to the mapping which focuses
cognition in the subsequent discourse onto events (their recurrence and temporal distribution);
similarly \q{student after student} has a \q{rider} suggesting more of a temporal
unfolding.  The second form implies not only that many students complained, but that
the events of these complainings were spread out over some stretch of time.
Each such functional application (mappings between \POS{} understood as linguistic types)
produces not only a resulting \POS{} \q{type}, but also a reconfiguration of cognitive
attitudes toward the relevant situation and context.
Language users have many ways to craft a sentence with similar meanings, and arguably one
task for linguistic analysis is to model the space of choices which are available in a
given situation and represent what specific ideas and effects are invoked by one
choice over others.
}
\subsection{Types, Sets, and Concepts}
\p{In formal/computational contexts, types can be defined as sets of both values and
\q{expectations} \cite{MathieuBouchard} (meaning assumptions which may be made about
all values covered by the type); alternatively, we can (perhaps better) consider types as
\i{spaces} of values.  Types' extensions have internal structure; there
can be \q{null} or \q{invalid} values, default-constructed values, and
so forth, which are \q{regions} of the conceptual space spanned or 
encompassing types.\footnote{Conceptual Space theory is outside the scope of this paper, but I'll note that 
it suggests a promising link between natural linguistics and formal/computational 
type theory, as suggested by computational or scientific expositions of 
the original Conceptual Space account developed by Peter \Gardenfors{}: 
cf. \cite{Zenker}, \cite{RaubalAdams} \cite{RaubalAdamsCSML}, 
\cite{Strle}.  Meanwhile, projects to develop formal models for 
Cognitive Grammar have also adopted Conceptual Space theory as an 
underlying semantics: \cite{KennethHolmqvist}, \cite{HolmqvistDiss}, 
\cite{MattSelway}, \cite{InteractingConceptualSpaces}.    
}
There is definitional interdependence
between types and functions: a function is defined in terms of the types it accepts as parameters and
returns \mdash{} rather than its entire set of possible inputs and outputs, which can
vary across computing environments.
\footnote{Moreover, expectations in a particular case
may be more precise than what is implied by the type itself \mdash{} it is erroneous
to assume that a proper type system will allow a correct \q{set of values} to
be stipulated for each point in a computation (the kind of contract enforced via
by documentation and unit testing).  So state-space in a given context may include many
\q{unreasonable} values, implying that within the overall space there is a \q{reasonable}
subspace, except that this subspace may not be crisply defined.
}  These are some reasons why in theoretical
Computer Science types are not \q{reduced} to underlying sets; instead, extensions
are sometimes complex spaces that model states of, or internal organization of comparisons
among, type instances.
}
\p{An obvious paradigm is organizing type-extensions around prototype/borderline
cases \mdash{} there are instances which are clear examples of types and
ones whose classification is dubious.  I contend, however, 
that common resemblance is not always a good marker
for types being well-conceived \mdash{} many useful concepts are common
precisely because they cover many cases, which makes defining
\q{prototypes} or \q{common properties} misleading.  
Also, sometimes the clearest
\q{representative} example of a type or concept is actually not a
\i{typical} example: a sample latter or model home is actually not (in
many cases) a real letter or home.  So resemblance-to-prototype is at
best one kind of \q{inner organization} of concepts' and types' spaces
of extension.  
}
\p{Sets, concepts, and types represent three different primordial thought-vehicles for
grounding notions of logic and meaning.  To organize systems around \i{sets} is
to forefront notions of inclusion, exclusion, extension, and intersection,
which are also formally essential to mathematical logic and undergird the
classical interdependence of sets, logic, and mathematics.
To organize systems around \i{concepts} is to forefront practical engagement
and how we mold conceptual profiles, as collections of ideas and pragmas,
to empirical situations.  To organize systems around \i{types} is to forefront
\q{functions} or transformations which operate on typed values, the interrelationships
between different types (like subtypes and inclusion \mdash{} a type can itself
encompass multiple values of other types), and the conceptual abstraction
of types themselves from the actual sets of values they may exhibit
in different environments.  Sets and types are
formal, abstract phenomena; whereas concepts are characterized by
gradations of applicability, and play flexible roles in thought and language.
The cognitive role of concepts can be discussed with some rigor, but there is a
complex interplay of cognitive schema and practical engagements which
would have to be meticulously sketched in many real-world scenarios, if
our goal were to translate conceptual reasoning to formal structures
on a case-by-case basis.  We can, however, consider in general
terms how type-theoretic semantics can capture conceptual structures
as part of the overall transitioning of thoughts to langauge.
}
\p{A concept does not merely package up a definition, like \q{restaurant} as
\q{a place to order food}; instead concepts link up with other concepts
as tools for describing and participating in situations.  Concepts are
associated with \q{scripts} of discourse and action, and find their
range of application through a variegated pragmatic scope.
We should be careful not to overlook these pragmatics, and
assume that conceptual structures can be simplistically
translated to formal models.
Cognitive Linguistics critiques
Set-Theoretic or Modal Logic reductionism (where a concept is just a set
of instances, or an extension across different possible worlds) \mdash{} George Lakoff and Mark Johnson,
prominently, argue for concepts' organization around
prototypes (\cite[p. 18]{LakoffJohnson}; \cite[p. 171, or p. \textit{xi}]{Johnson})
and embodied/enactive patterns of interaction (\cite[p. 90]{LakoffJohnson};
\cite[p. 208]{Johnson}).
Types, by contrast, at least in linguistic applications of type theory, are abstractions
defined in large part by quasi-functional notions of phrase struture.
Nevertheless, the \i{patterns} of how types may inter-relate
(mass-noun or count-noun, sentient or non-sentient, and so forth)
provide an infrastructure for conceptual understandings to be
encoded in language \mdash{} specifically, to be signaled by which typed
articulations conversants choose to use.  A concept like
\i{restaurant} enters language with a collection of understood
qualities (social phenomena, with some notion of spatial location and
being a \q{place}, etc.) that in turn can be marshaled by sets of
allowed or disallowed phrasal combinations, whose parameters
can be given type-like descriptions.  Types, in this sense,
are not direct expressions of concepts but vehicles for
introducing concepts into language.
}
\p{Concepts (and types also) are not cognitively the same as their
extension \mdash{} the concept \i{restaurant}, I believe, is distinct from
concepts like \i{all restaurants} or \i{the set of all restaurants}.
This is for several reasons.  First, concepts can be pairwise different
not only through their instances, but because they highlight different
sets of attributes or indicators.  The concepts \q{American President} and \q{Commander in Chief}
refer to the same person, but the latter foregrounds a military role.
Formal Concept Analysis considers \i{extensions} and \q{properties}
\mdash{} suggestive indicators that inhere in each
instance \mdash{} as jointly (and co-dependently) determinate: concepts
are formally a synthesis of instance-sets and property-sets \cite{YiyuYao},
\cite{Belohlavek}, \cite{Wille}.  Second,
in language, clear evidence for the contrast between \i{intension} and
\i{extension} comes from phrase structure: certain constructions specifically
refer to concept-extension, triggering a mental shift from thinking of the
concept as a schema or prototype to thinking of its extension (maybe in some context).
Compare:
\begin{sentenceList}\sentenceItem{} \label{itm:rhinor} Rhinos in that park are threatened by poachers.
\sentenceItem{} Young rhinos are threatened by poachers.
\end{sentenceList}
Both sentences focus a conceptual lens in greater detail than \i{rhino} in general, but
the second does so more intensionally, by adding an extra indicative criterion; while
the former does so extensionally, using a phrase-structure designed to operate on
and narrow our mental construal of \q{the set of all rhinos}, in the sense of
\i{existing} rhinos, their physical place and habitat, as opposed to
the \q{abstract} (or \q{universal}) type.  So there is a familiar semantic
pattern which mentally transitions from a lexical type to its extension and
then extension-narrowing \mdash{} an interpretation that, if accepted, clearly
shows a different mental role for concepts of concepts' \i{extension} than the
concepts themselves.\footnote{There is a type-theoretic correspondence between intension and
extension \mdash{} for a type \Tnoindex{} there is a corresponding \q{higher-order} type
of \i{sets} whose members are \Tnoindex{} 
(related constructions are the type of \i{ordered sequences} of \Tnoindex{};
unordered collections of \Tnoindex{} allowing repetition; and stacks, queues, and
deques \mdash{} double-ended queues \mdash{} as \Tnoindex{}-lists that can grow or shrink
at their beginning and/or end).  If we take this (higher-order)
type gloss seriously, the extension of a concept is not its \i{meaning}, but a
different, albeit interrelated concept.  Extension is not definition.
\i{Rhino} does not mean \i{all rhinos} (or \i{all possible rhinos}) \mdash{} though arguably
there are concepts \i{all rhinos} and \i{all restaurants} (etc.) along with the concepts
\i{rhino} and \i{restaurant}.
}  
}
\p{Concepts, in short, do not mentally signify sets, or
extensions, or sets-of-shared-properties.  Concepts, rather, are cognitive/dialogic tools.
Each concept-choice, as presentation device,
invites its own follow-up.  \i{Restaurant} or \i{house} have meaning not via
idealized mental pictures, or proto-schema, but via kinds of things
we do (eat, live), of conversations we have, of qualities we deem relevant.  Concepts do not
have to paint a complete picture, because we use them as part of ongoing situations
\mdash{} in language, ongoing conversations.  Narrow concepts \mdash{} which may best exemplify
\q{logical} models of concepts as resemblance-spaces or as rigid designators to
natural kinds \mdash{} have, in practice, fewer use-cases \i{because} there
are fewer chances for elaboration.  Very broad concepts, on the other hand, can have,
in context, too \i{little} built-in \i{a priori} detail.
(We say \q{restaurant} more often than \i{eatery}, and
more often than \i{diner}, \i{steakhouse}, or \i{taqueria}).  Concepts dynamically play
against each other, making \q{spaces} where different niches of meaning, including
levels of precision, converge as site for one or another.  Speakers need freedom to choose
finer or coarser grain, so concepts are profligate, but the most oft-used trend toward middle
ground, neither too narrow nor too broad.  \i{Restaurant} or \i{house} are useful because they are noncommittal, inviting more detail.
These dynamics govern the flow of inter-concept relations (disjointness, subtypes, partonymy, etc.).
}
\p{Concepts are not rigid formulae (like instance-sets or even attributes fixing when
they apply); they are mental gadgets to initiate and
guide dialog.  Importantly, this
contradicts the idea that concepts are unified around instances' similarity (to each other or
to some hypothetical prototype): concepts have avenues for contrasting
different examples, invoking a \q{script} for further elaboration, or for building temporary filters.  
In, say, 
\begin{sentenceList}\sentenceItem{} Let's find a restaurant that's family-friendly.
\end{sentenceList}
allowing such one-off narrowing is a feature
of the concept's flexibility.
}
\p{In essence: no less important, than acknowledged similarities across all instances, are well-rehearsed ways
\visavis{} each concept to narrow scope by marshaling lines of \i{contrast}, of \i{dissimilarity}.
A \i{house} is obviously different from a \i{skyscraper}
or a \i{tent}, and better resembles other houses; but there are also more nontrivial \i{comparisons}
between houses, than between a house and a skyscraper
or a tent.  Concepts are not only spaces of similarity, but of \i{meaningful kinds of differences}.
}
\p{To this account of conceptual breadth we can add the conceptual matrix spanned by
various (maybe overlapping) word-senses: to \i{fly}, for example, names
not a single concept, but a family of concepts all related to airborn
travel.  Variations highlight different features: the path of flight (\i{fly to Korea}, \i{fly over the mountain});
the means (\i{fly Korean air}, \i{that model flew during World War II});
the cause (\i{sent flying (by an explosion)}, \i{the bird flew away (after a loud noise)},
\i{leaves flying in the wind}).  Words allow different use-contexts
to the degree that their various \i{senses} offer an inventory of aspects for
highlighting by \i{morphosyntactic} convention.  Someone who says \i{I hate to fly} is not
heard to dislike hand-gliding or jumping off mountains.\footnote{People, unlike birds, do not fly \mdash{} so the verb, used intransitively
(not flying \i{to} somewhere in particular or \i{in} something in particular),
is understood to refer less to the physical motion and more to the socially
sanctioned phenomenon of buying a seat on a scheduled flight on an airplane. The construction
highlights the procedural and commercial dimension, not the physical mechanism and
spatial path.  But it does so \i{because} we know human flight is
unnatural: we can poetically describe how the sky is filled with flying leaves or birds,
but not \q{flying people}, even if we are nearby an airport.
}  Accordant variations
of cognitive construal (attending more to mode of action, or path, or motives, etc.),
which are elsewhere signaled by grammatic choices, are also spanned by a conceptual
space innate to a given word: senses are finer-grained meanings availing themselves to one construal or another.
}
\p{So situational construals can be signaled by word- and/or
syntactic form choice (locative, benefactive, direct and indirect
object constructions, and so forth).  Whereas conceptual organization
often functions by establishing classifications, and/or invoking
\q{scripts} of dialogic elaboration, cognitive structure tends to apply more
to our attention focusing on particular objects, sets of objects, events, or
aspects of events or situations.  
So the contrast between singular, mass-multiples, and count-multiples,
among nouns, depends on cognitive
construal of the behavior of the referent in question (if singular, its
propensity to act or be conceived as an integral whole; if multiple, its
disposition to either be divisible into discrete units, or not).
Or, events can be construed in terms of their causes
(their conditions at the outset), or their goals (their conditions at
the conclusion), or their means (their conditions in the interim).
Compare \i{attaching} something to a wall (means-focused) to
\i{hanging} something on a wall (ends-focused); \i{baking} a cake
(cause-focus: putting a cake in the oven with deliberate intent to cook it)
to \i{burning} a cake (accidentally overcooking it).\footnote{We can express
an intent to bake someone a cake, but not (well, maybe comedically) to
\i{burn} someone a cake (\q{burn}, at least in this context, implies
something not intended); however, we \i{can} say
\q{I burnt your cake}, while it is a little jarring to say
\q{I baked your cake} \mdash{} the possessive implies that some
specific cake is being talked about, and there is less apparent reason
to focus on one particular stage of its preparation (the baking) once
it is done.  I \i{will} bake a cake, in the future, uses
\q{bake} to mean also other steps in preparation (like \q{make}), while,
in the present, \q{the cake \i{is} baking} emphasizes more its
actual time in the oven.  I \i{baked your cake} seems to focus
(rather unexpectedly) on this specific stage even after it is completed,
whereas \i{I baked you a cake}, which is worded as if the recipient
did not know about the cake ahead of time, apparently uses \q{bake} in
the broader sense of \q{made}, not just \q{cooked in an oven}.
Words' senses mutate in relation to the kinds of situations where they are used
\mdash{} why else would \i{bake} mean \q{make}/\q{prepare} in the past or future tense but
\q{cook}/\q{heat} in the present?
}
These variations are not random assortments of polysemous words' senses:
they are, instead, rather predictably distributed according
to speakers' context-specific knowledge and motives.
}
\p{I claim therefore that \i{concepts} enter language complexly, influenced by
conceptual \i{spaces} and multi-dimensional semantic and syntactic selection-spaces.
Concepts are not simplistically \q{encoded} by types, as if for
each concept there is a linguistic or lexical type that just
disquotationally references it \mdash{} that the type \q{rhino} means the concept
\i{rhino} (\q{type} in the sense that type-theoretic semantics would model lexical
data according to type-theoretic rules, such as \i{rhino} as subtype of \i{animal} or
\i{living thing}).
Cognitive schema, at least in the terms I just laid out, select particularly
important gestalt principles (force dynamics, spatial frames, action-intention)
and isolate these from a conceptual matrix.  On this basis, we can argue that
these schemata form a precondition for concept-to-type association; or,
in the opposite logical direction, that language users' choices to employ
particular type articulations follow forth from their prelinguistic
cognizing of practical scenarios as this emerges out of collections
of concepts used to form a basic understanding of and self-positioning within them.
}
\p{In this sense I called types \q{vehicles} for concepts: not that types \i{denote}
concepts but that they (metaphorically) \q{carry} concepts into language.  
\q{Carrying} is enabled by types' semi-formal rule-bound
interactions with other types, which are positioned to capture concepts' variations and
relations with other concepts.
}
\p{To express a noun in the benefactive case, for example, which can be seen as attributing to
it a linguistic type consistent with being the target of a benefactive,
is to capture the concept in a type-theoretic gloss.
It tells us, I'm thinking about this thing in such a way that it
\i{can} take a benefactive (the type formalism attempting to capture
that \q{such a way}).
A concept-to-type \q{map}, as I just
suggested, is mediated (in experience and practical reasoning) by
cognitive organizations; when (social, embodied) enactions take
linguistic form, these organizing principles can be encoded in how
speakers apply morphosyntactic rules.  
}
\p{So the linguistic structures,
which I propose can be formally modeled by a kind of type theory, work
communicatively as carriers and thereby signifiers of cognitive
attitudes. The type is a vehicle for the concept because it takes part in constructions
which express conceptual details \mdash{} the details
don't emerge merely by virtue of the type itself.
I am not arguing for a neat concept-to-type correspondence; instead, a type system provides a
\q{formal substrate} that models (with some abstraction and simplification) how
properties of individual concepts translate
(via cognitive-schematic intermediaries) to their
manifestation in both semantics and syntax.
}
\p{Continuing with declention as a case study,
consider how an \q{ontology} of word senses 
can interrelate with the benefactive.
A noun as a benefactive target most often is a person or some other
sentient/animate being; an inanimate benefactive is most likely
something artificial and constructed (cf., \i{I got the car new tires}).
How readily hearers accept a sentence \mdash{} and the path they
take to construing its meaning so as to make it grammatically acceptable
\mdash{} involves interlocking morphological and type-related considerations;
in the current example, the mixture of benefactive case and which noun
\q{type} (assuming a basic division of nouns into e.g.
animate/constructed/natural) forces a broader or narrower
interpretation.  A benefactive with an \q{artifact} noun, for example,
almost forces the thing to be heard as somehow disrepaired:
\begin{sentenceList}\sentenceItem{} I got glue for your daughter.
\sentenceItem{} I got glue for your coffee mug.
\end{sentenceList}
We gather (in the second case) that the mug is broken \mdash{} but this is never spelled out
by any lexical choice; it is implied indirectly by using benefactive case.  
It is easy to design similar examples with other cases:
a locative construction rarely targets \q{sentient} nouns, so in
\begin{sentenceList}\sentenceItem{} We're going to Grandma!
\sentenceItem{} Let's go to him right now.
\sentenceItem{} Let's go to the lawyers.
\sentenceItem{} Let's go to the press.
\end{sentenceList}
we mentally substitute the person with the place where they live or work.
}
\p{Morphosyntactic
considerations are also at play: \i{to the lawyers} makes \q{go} sound more like \q{consult with},
partly because of the definite article (\i{the} lawyers implies conversants have some prior involvement
with specific lawyers or else are using the phrase metonymically, as in \q{go to court} or
\q{to the courts}, for
legal institutions generally; either reading draws attention away from literal spatial implications of
\q{go}). \i{Go to him} implies that \q{he} needs
some kind of help, because if the speaker just meant going to wherever he's at, she probably would
have said that instead.
}
\p{Similarly, the locative in \i{to the press} forces the mind to
reconfigure the landmark/trajector structure, where \i{going} is thought not as a literal
spatial path and \i{press} not a literal destination \mdash{} in other words, the phrase must be
read as a metaphor.  But the \q{metaphor} here is not \q{idiomatic} or removed from linguistic rules
(based on mental resemblance, not language structure); here it
clearly works off of formal language patterns: the landmark/trajector
relation is read abstracted from literal spatial movement because the locative is applied
to an expression (\i{the press}) which does not (simplistically) meet
the expected interpretation as \q{designation of place}.
In short, there are two different levels of \i{granularity} where we 
can look for agreement requirements: a more fine-grained level where e.g. 
\i{locative} draws in a type-specification of a \i{place} or \i{location}; 
and a coarser level oriented toward Parts of Speech, and typologies 
of phrasal units.  The former analysis addresses the level I have called 
\q{macrotypes}, while the latter scale is at the \q{macrotype} level. 
}
\p{I envision the unfolding that I have just sketched out as something Phenomenological
\mdash{} it arises from a unified and subjective consciousness, one marked by
embodied personal identity and social situation.  If there are structural stases
that can be found in this temporality of experience, these are not constitutive
of conscious reality but a mesh of rationality that supports it, like the veins in
a leaf.  Stuctural configurations can be lifted from language insofar as it is a
conscious, formally governed activity, and lifted from the ambient situations which
lend language context and meaning intents.  So any analytic emphasis on
structural fixpoints threaded through the lived temporality of consciousness is an
abstraction, but one that is deliberate and necessary if we want to make scientific
or in any other manner disputatable claims about how language and congition works.
}
\p{To return to the example of \i{Student after student}, I 
commented that designating
one word to \q{represent} the phrase seemed arbitrary.  
If we consider functional-typing alone, \i{after} is the only non-noun,
the natural conclusion is that \q{after} should be typed \NNtoN{}
(which implies that \q{after} is analogous to the \q{functional} position, and
in a lambda-calculus style reconstruction would be considered the \q{head}
\mdash{} Figure ~\ref{fig:ESA} is an example of how
the sentence could be annotated, for sake of discussion).
This particular idiom depends however
on the two constituent nouns being the same word (a pattern I've also alluded to with
idioms like \i{time after time}).  
Technically, this appears to be an example of \i{dependent types}: 
specifically, a type-theoretic model of \i{after} in this would seem 
to require that the \NNtoN{} signature be constrained so that the second 
noun matches the first \mdash{} so the second \N{} type is actually constrained 
to be a singleton type dependent on the first \N{}'s value.  
On that account, the parameters
for \i{after} are a dependent type pair 
\cite{BernardyEtAl}, \cite{TanakaEtAl} satisfied by an identity comparison between
the two nouns.  This analysis captures a type-theoretic gloss on the 
structural contrast between \i{Student after student} and 
\i{Many students}, phrases which are similar but not identical 
in meaning (so whose differences need explaining).
}
\p{I have offered a more cognitive account focusing on 
the implicit temporality of \i{Student after student}; this later 
type-oriented model is more formal, or at least leaves open the 
possibility that language is organically taking in structures 
engineered into artificial (e.g., computer programming) languages. 
It is certainly possible to witness formalizable structures in 
langauge patterns \mdash{} Zhaohui Luo finds strong evidence for 
dependent types being a good model for semantic norms in 
\cite{LuoSoloviev}, for example.  Whether these kinds of 
formalisms have important causal influence on 
language acquiring its evident patterns, or are more like 
just convenient representational tools, is perhaps an 
open (and maybe case-by-case) question.   
}
\p{Consider alternatives for \q{many students}.  The phrase as
written suggests a type signature (with \q{many} as the \q{function-like} or
derivative type) \NpltoNpl{}, yielding a syntactic interpretation of the phrase; this
interpretation also suggests a semantic progression, an accretion of intended detail.
From \i{students} to \i{many students} is a conversion between two plural nouns
(at the level of concepts and semantic roles); but it also implies relative size,
so it implies some \i{other} plural, some still larger group of students from which
\q{many} are selected.  While rather abstract and formal, the \NpltoNpl{} representation
points toward a more cognitive grounding which considers this \q{function} as a form
of thought-operation; a refinement of a situational model, descriptive resolution,
and so forth.  If we are prepared to accept a cognitive underpinning to semantic
classification, we can make the intuition of part of speech signatures as \q{functions}
more concrete: in response to what \q{many} (for example) is a function \i{of},
we can say a function of propositional attitude, cognitive schema, or attentional
focus.
}
\p{The schema which usefully captures the sense and picture of \i{students} is
distinct (but arguably a variation on) that for \i{many students}, and there is a
\q{mental operation} triggered by the \i{many students} construction which
\q{maps} the first to the second.  Similarly, \i{student after student} triggers a
\q{scheme evolution} which involves a more explicit temporal unfolding
(in contrast to how \i{many students} instead involves a more explicit
quantitative \i{many/all} relation).  What these examples show is that
associating parts of speech with type signatures is not just a formal
fiat, which \q{works} representationally but does not necessarily capture
deeper patterns of meaning.  Instead, I would argue, type signatures
and their resonance into linkage acceptability structures
(like singular/plural and mass/count agreement) \i{point toward} the
effects of cognitive schema on what we consider meaningful.
}
\p{In \i{Student after student came out against the proposal},
to \i{come out}, for/against, lies in the semantic frame of attitude and expression
(it requires a mental agent, for example), but its reception
carries a trace of spatial form: to come out \i{to} a public place, to
go on record with an opinion (I analyzed this case in Section 2).  Usually
\q{come out [for/against]}, in the context of a policy or idea, is similarly
metaphorical.  But the concrete spatial interpretation remains latent, as a kind
of residue on even this abstract rendition, and the spatial 
undercurrent is poised to emerge
as more literal, should the context warrant.  However literally or metaphorically
the \q{space} of the \q{coming out} is
understood, however explicit or latent its cogitative figuration,
is not something internal to the language; it is a potentiality which
will present in different ways in different circumstances.  This is not to say that
it is something apart from linguistic meaning, but it shows how linguistic meaning
lies neither in abstract structure alone, nor contextual pragmatics, but in their cross-reference.
}
\p{}
\p{}
\p{}
\p{}
\p{}
