`section.Cognitive Transforms and the Accretion of Detail`
`p.
Thus far, I have argued modifier-transform pairs 
form grammatic building blocks which, according to 
combination via certain rules, reconstruct the 
syntactic forms of sentences while also revealing 
their conceptual provenance.  Adequate parse representations 
require distinguishing `i.stages` and `i.columns`/, 
with notation marking each parse-graph edge 
(modeling a transform) via a unique stage/column 
duo.  I also mentioned that parge-graphs have 
the extra organizational structure of `i.channels`/, 
aggregating columns and distinguishing `q.input` 
and `q.output` edges (for networking where a modifier 
in one transform is a target in a second).  The 
`q.channelized` graphs are then `i.hypergraph`/, 
and their use as representational targets 
for structural morphism according to grammatic 
rules becomes an example of `i.hypergraph grammar`/. 
`p`

`p.
The specific category of structures definable as 
hypergraphs via stages and channels (where stages are 
formally an ordering on channels) is more 
general than (natural) linguistics.  Elsewhere 
I have used similar formalisms to analyze 
computer source code; and the data accompanying 
this paper illustrates how Channelized Hypergraphs 
can be an intermediate representation for 
computer languages %-- specifically, a 
`i.hypergraph virtual machine` can translate 
these structures into executable instructions which 
are mapped to predefined software procedures, indexed 
in computer memory.  Hypergraphs with these properties 
are, accordingly, systematic enough to coordinate 
the interactions among computational processes in a general 
sense; they can be the foundation of rigid, formal languages, 
e.g. for computer programming.   
`p`

`p.
I have proposed that constructional rules for 
Channelized Hypergraphs can be specified according 
to a `i.channel algebra`/.  Technical details on 
how such algebras are defined (not that they are 
terribly mathematically sophisticated) is outside 
the scope of this paper, but in overview each 
channel algebra establishes criteria according to 
which parse graphs (or as I more generally call 
them `i.source graphs`/) are computationally 
well-formed; that is, they model feasible orchestrations 
of how multiple procedures are to be sequentially 
ranked and then evaluated.  Honing allowable 
structures for natural language parse graphs also 
produces a channel algebra.  The range of structures 
acceptable as models of natural language are actually 
simpler and more restricted than for programming 
languages.   
`p`

`p.
In sum, among the Category of Channelized Hypegraphs 
constructionally regulated by a `q.channel algebra`/, 
those capturing linguistic patterns are actually tightly 
constrained.  This implies that there are processual 
and/or conceptual dynamics generating language 
structure.  The hypegraph mechanism is not only a summarial 
restaging of language artifacts, but is pointing us 
toward insights about which forces shape the 
coordinative instincts among language elements that 
become syntactic conventions.  I will try to 
elucidate these dynamics through several lines of argument.
`p`

`subsection.Propositions and Transform Dynamics`
`p.

`p`


`p.

`p`

