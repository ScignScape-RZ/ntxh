

LangIntro p. 331/320 



...

`p.
Formal presentations of natural-language grammar are 
often classified as either `q.dependency` grammars 
(concentrating on inter-word relationships) 
or `q.constituency` grammars (focusing on 
phrase structure and phrase hierarchies).  
Unlike more rigidly formal models, 
Ronald Langacker's `i.Cognitive` Grammar 
does not usually engage in very fine-grained, 
schematic representations of all the structuring 
elements contributing to a sentence's or 
expression's meaning.  Instead, Langacker will 
call attention to particular features in an 
overall linguistic artifact those which reveal 
specific facets of language as a conceptualized 
system: cognitive construals of referents, 
extra-linguistic situations, and word-senses; 
relations of current sentences to previous 
discourse; speakers' epistemic attitudes and 
relations to the objects topicalized in their 
speec-acts.  In general, the analytic focus 
gives an impression of prioritizing intermediate 
linguistic scales, larger than individual 
words or word-pairs but smaller than sentences 
or complex phrases.   
`p` 

`p.
Langacker does, however, recognize many established 
linguistic terms and constructs insofar as 
they establish grammatic or lexical categories, phrase-types, 
or salient inter-word relations  
(nominals, clauses, anaphora, periphrasis, complements, 
serial verbs, grammatical cases).  Cognitive Grammar 
incorporates many of the structural features identified 
by syntactic theory, or also `q.generative` semantics; 
it differts from established paradigms however by 
seeking explanatory grounds for these identified 
patterns in cognitive construals of situations and 
dialog, rather than in regulated grammatic behavior or 
logically structured semantic models.  The 
rule-bound and logical core of syntax and semantics 
is, at one level, undeniable %-- certainly we 
do hear certain potential rearrangements of an 
expression as grammatically incorrect, while other
seemingly similar transformations are accepted.  
Likewise, although word senses tend to proliferate, 
there is usually some logical structure binding 
senses together in a lexical network.   
`p`


`p.

`p`

`p.
When linguistic methodology is described as 
`i.computational`/, this usually implies that 
the research is not only developing or employing 
some formal representation of linguistic 
elements, but is moreover using some kind 
of computational mechanism to instantiate 
and/or analyze the relevant formal structures, 
concretely filled in with particular 
linguistic content.  In the case of 
constituency trees or dependency graphs, 
for example, there may be a software 
package which implements the trees or 
graphs as digital data structures, 
manifested by assigning words (or other lexemes) 
to the requisite nodes (or `q.leaves`/).  
In that digital form, the data structures may 
then be available for further manipulation, 
such as being visually presented in some 
diagrammatic manner or being paired with 
other data structures, such as tables itemizing 
the lexical interpretation and/or grammatic 
categorization of the component lexemes.
`p`

`p.
The term `i.computational linguistics` probably also 
implies that these digital representations 
are %-- or will potentially be %-- `i.automatically` 
generated by some Natural Language Processing 
system.  For most researchers, that is, the use of 
computers as linguistic tools is bound up with a 
goal to automate various dimensions of linguistic 
processing, which in turn could provide for Artificial 
Intelligent agents that mimic human linguistic 
competence.  Machine translation, for instance, 
could be effectuated by parsing sentences to 
dependency graphs, transforming the resulting graphs 
by translating words between languages, and 
synthesizing sentences in the target language 
via the output graphs.  The machine-translation `q.problem` 
is thereby reduced to three smaller problems whose 
`q.solutions` can be chained together %-- starting 
with the problem of mapping linguistic content to 
formal re-constructions.  
`p`

`p.
For linguists, of course, automating the annotation of 
linguistic components is more convenient than 
doing the same work manually.  In the context of 
Natural Language Processing, automation is more 
than just a convenience: here, theoretical 
paradigms and concrete models are assessed 
specifically on how well they engender 
computational artifacts which manipulate 
linguistic givens in human-like ways without 
human intervention.  A module which transforms 
unadorned sentences into formal dependency 
graphs, say, would be deemed successful if 
most such parses are identical to those 
produced by human annotators.  To be sure, 
the more that reconstruction of linguistic 
content between different surface-level or 
formal representations can be automated, 
the more that Artificially Intelligent 
language engines can be constructed merely 
by interconnecting these automated capabilities.  
However, we should not assume that formal 
representations are `i.only` valuable in 
the context of these automated systems.  
`p`

`p.
Instead, it is possible to employ 
formal or, indeed, computational structures 
as vehicles for linguistic explanation or 
exploration, whether or not the structures 
can be automatically obtained from 
surface-level language (or from other formalisms).  
As a case in point, I will here propose a 
formal model for Cognitive Grammar which, 
in broad outline, takes its structure from 
recent investigations merging Conceptual 
Space Theory, in the sense of Peter `Gardenfors;, 
with a notion of `q.hypergraph` grammar.  
This combination %-- proposed in a schematic 
manner particularly in `cite<BobCocke>;, which 
apparently reflects the experiences of 
several seminars conducted by a group of 
linguists and mathematicians %-- outlines 
an overall linguistic model where hypergraph 
structures are featured in grammatic description 
and Conceptual Spaces are recognized as a 
foundation for semantics.  The proposal, 
which I will examine in more detail below, 
is sufficiently schematic that it may be 
best treated as a metatheoretical template 
%-- open to elaboration both in terms 
of how hypergraph grammars are specified and 
in terms of how Conceptual Space theory 
is understood to anchor semantics 
(here I will consider both dimensions in the 
context of Langacker's Cognitive Grammar, 
e.g. comparing Langacker's notion of 
`i.domains` to that of `Gardenfors;). 
`p`  

`p.
Assuming, in any case, that we have a specific 
`q.Conceptual Hypergraph` model (unifying 
an elaborated Hypegraph Grammar theory with a 
Conceptual Space semantics), this model can be 
considered a `i.computational` model insofar 
as the resulting hypergraph-based data structures 
are amenable to computational treatments: 
for example, being implemented as data structures 
in a programming language, and subject to manipulation 
via these computational representations.  
Indeed, I will argue that a variation of 
the Conceptual Hypergraph model can be adopted as a 
basis for `i.formal` languages, such as 
computer programming languages.  Accompanying this 
essay is demonstrative implementation of a 
programming language which illustrates this explicitly, 
using a `q.Hypergraph Virtual Machine` and 
hypergraph-based Intermediate Representation to 
concretize the compiler and runtime algorithms needed 
to translate source code (conformant to a hypergraph 
grammar) into machine-readable instructions.  
In this sense, I claim that a Conceptual Hypergraph model 
of language in general is interesting in computational 
contexts in part because it has applications to 
both natural and artificial languages. 
`p`

`p.
Nevertheless, I do not claim here that the Conceptual Hypergraph 
model is well-suited to computational `i.automation`/.  
Although I will describe a formal representation for linguistic 
data within this model, I am not concerned with whether 
computers could be programmed to derive these representations 
automatically, in contrast to the process of 
humans manually assembling the hypergraph structures as 
explanatory models for given sentences.  While I think 
Conceptual Hypergraph models are subject to many 
interesting computational treatments (including 
via compiler/runtime pipelines), I do not endorse 
any philosophical speculation that natural language 
is sufficiently formalizable to be emulated 
by machines (even given practically infinite computing 
power and `q.training data`/).
`p`

`p.
Let me, in particular, make a contrast between 
`i.explanatory` formal models as opposed to 
formalisms aspiring to `i.simulate` human linguistic 
performance.  In the former sense, models are used 
by humans to better understand language as a 
structural and/or cognitive phenomenon.  
The compositional requirements and transformative 
options available to formal models can then 
serve as proxies or intuitions for the rules 
and transformations internal to language.  
In this explanatory role, formal models do not need 
to be precise reconstructions of linguistic behavior, 
because we do not need them to serve as our sole 
source of linguistic explanation: formal models are 
simply one vehicle among others for 
investigating linguistic phenomena and communicating 
linguistic theories.  By contrast, when we 
reify formal models to the point of `i.subsuming` 
all linguistic phenomena %-- in the sense that 
models should engender `AI; engines that replicate 
human linguistic competence %-- we impose an 
unreasonably high burden.  Formal (and computational) 
models can be theoretically useful even if they 
are not totalizing enough to reduce all language 
to computationally tractable algorithms.
`p`

`p.
In this spirit I will argue, then, that 
a Conceptual Hypegraph model can be used to 
bridge Cognitive Grammar to formal linguistic 
methodologies %-- not in the sense that 
Hypergraph Grammar and Conceptual Space theory 
jointly embody a complete formal specification 
for language, nor that the model allows us to 
equip `AI; with something like `q.cognition`/, 
but rather that a certain class of 
Hypergraph Grammar and Conceptual Space constructions 
can be simultaneously illustrative specifications 
of Cognitive Grammar constructions and 
also elements of a system with formal properties, 
subject to formal presentations and analysis.  
`p`

`p.
I believe that language is neither completely 
formal nor completely informal; as a result, 
formal models are neither entirely irrelevant 
nor holistically adequate for linguistic explanation.  
It is true that language is a human (communal) 
activity, and surely acquires some of its structure 
from this interpersonal dimension, just as 
social norms or cultural value systems reflect 
certain regularities that can be structurally 
analyzed.  However, structural explanation has a 
deeper warrant in the context of linguistics than 
in, say, sociology or anthropology.  
There are constructive patterns that are directly 
manifest in well-formed sentences, and which 
are in that guise amenable to structural analysis; 
this differs from Structuralism in mythology, for 
instance, where interpretive sophistication is needed 
to reveal patterns that imply compositional `q.laws` 
somehow operative in myth-making.  Even language 
with no formal rule-books, no instructional pedagogy, 
or no written form, evince precise grammatic 
and morphological systems %-- equally or more complex 
than cosmopolitan languages regulated by institutions 
like the `AcademieFrancaise;.      
`p`

`p.
In short, it is possible to find within language precisely 
specifiable patterns that are not imposed by 
any external authority, nor vague enough to be 
biproducts of a certain manifest structurality that 
we might find in many regions of human communal activity.  
This implies that there is something within meaning or 
meaningfulness %-- or our cognition thereof %-- which 
trends toward structural regularity.  It would certainly 
be part of the linguistic purview to explain how this 
trend arises (organically from the mental and intersubjective 
processes which yield language) and to document 
structural regularities at work in specific languages.  
On the other hand, however, such an analysis has no bearing on 
whether the analysis of structural patterns supplies a 
comprehensive method for analyzing language as a whole, 
or how extensively signification relies on structurally 
enumerable patterns rather than gestures, contextual 
cues, communicative conventions among narrowly defined 
dialect communities, and so forth.  To analyze the 
speech of several friends discussing a baseball game, 
it may be that only a relatively small percentage of 
the communicative principles manifest in their activity 
can be explained by structural semantic or syntactic 
models; such models should then be deemed 
necessary but not sufficient for comprehensive 
treatments of language.
`p`

`p.
Structural patterns may emerge from how we cognize 
and then share impressions of empirical situations; 
or in the internal logic of states of affairs that 
are worthy of or conducive to linguistic expression; 
or some combination.  It is reasonable to assume 
that most (or all) linguistic statements have some 
basis in fact %-- that they are associated with 
some `i.propositional content` which the speaker either 
asserts or somehow comments on.  The point is not 
that every sentence has a meaning which can be directly 
reproduced propositionally, but that most or all sentences' 
meanings take their departure from a propositional 
content that the speaker profiles in some orientation 
%-- as asserted, desired, interpreted, explained, 
doubted, and so forth.  Often the communicative burden 
lies not in merely designating the concomitant 
proposition but in expressing a meta-level attitude 
to that content, so that the speech-act signifies and 
then elaborates upon it:

`exs,
`ex; You know that Warren leads Biden in the polls, don't you?
`ex; I hope that Warren can appeal to moderates.
`ex; I'm sure that Warren will pivot to the center and 
will poll well with moderates.
`exs`

The proposition that `i.Warren will poll well with moderates` 
certainly denotes a testable premise %-- it will prove true or 
false as the polls are in fact taken over time %-- but 
the point of (3) is not only to assert that claim, but to 
add interpretive and causative detail: (3) implies 
that Warren will poll well `i.because` she 
`q.pivots to the center`/.  So we cannot `q.reduce` the 
meaning of (3) to the propositional content glossed 
as `i.Warren will poll well with moderates`/; but 
denoting that content certainly seems to be 
a prerequisite to defining (3)'s actual meaning. 
`p`

`p.
Of course, (2) and (3) can be seen as packaging 
one sort of propositional content inside a second, where 
the `q.outer` content reflects states of affairs pertaining 
to propositional attitudes.  Notice that (2) and (3) are 
falsifiable.  Perhaps (2) is spoken by a critic of 
Warren, who is rooting `i.against` her; but (2) is an 
indirect or diplomatic way of calling attention to her problems 
appealing to moderates (to hope for something implies some 
doubt whether that will in fact transpire).  Conversely, 
(3) might be said by a Warren supporter trying to alleviate 
the concerns of (2).  People can consciously 
falsifiable reports of their propositional attitudes, 
for various rhetorical or manneristic reasons.  
But this implies that propositional attitudes are 
themselves falsifiable contents, so it can be 
true or false that someone hopes for or believes 
something.  As a result, we can argue that the 
actual propositional content invoked by some sentences 
can be factored into an `q.extramental` objective part 
and a speaker-relative attitudinal report.  
`p`

`p.
Speech-acts, of course, also signal speakers' desires 
to `i.make` something the case, including via commands 
and requests.  In the above examples, (1) is 
apparently performative in a similar way, since 
(1) implies that the speaker `q.wants` the addressee 
to accept the designated claim as true.  The 
insinuation is that `i.Warren outpolls Biden` 
(as an asserted fact) `i.and moreover` that 
this fact should by collectively agreed upon, 
among the inventory of shared posits that 
undergird any conversation.  So (1), via some 
indirection, expresses a kind of second-order 
`q.attitudinal` content analogous to (2) and 
(3) (the speaker's belief that `i.Warren outpolls Biden` 
is sufficiently extablished as fact to be 
collectively `q.enregistered`/), while (1) also 
implicates a request (that the other 
conversants consent to this epistemic entrenchment).    
`p`

`p.
In effect, language would be impossible if we could not 
express both propositional contents and attitudes 
to those contents (wherein propositional attitudes 
are in turn a form of propositional content).  
In this sense language will reveal some 
structural patterns merely insofar as language's 
signifying resources include, as a proper part, 
exposition of factual beliefs and assertions.  
Here I am not implying that patterns in 
propositional structure are directly translated 
to patterns in language %-- by way of illustration, 
the usages in (3) are, on reflection, highly metaphorical 
and stylized.  The conventionalized trope of 
a politician `q.pivoting to the center` employs a 
spatial construal to reference an empirical state 
of affairs which, logically reconstructed, 
would be very complex and contextual.  
While we can provide a workable predicate 
gloss %-- someone `q.pivots to the center` if 
their political comments or speeches reveal a 
particular pattern `visavis; the projection of 
distinct political topics onto a common centrist/extremist 
scale, such that someone's posturing over time figures 
summarily as `q.movement` in this abstract space 
%-- the semantics of the idiom `i.pivot to the center` 
is not a facile logical construction like 
`i.bachelor` and `i.unmarried man`/, or `i.ring` and 
`i.jewelry worn on one's finger`/.   
`p`

`p.
Merely noting the predicate structure of signified 
propositional contents, that is, may be at best 
tangential to actual linguistic explanation, because 
it cannot account for how metaphorical cases 
like `q.pivot to the center` are cognized and 
conventionalized.  However, the requirement that 
language must signify states of affairs 
%-- via metaphor or conceptual schema or something 
more transparently compositional %-- is a reasonable 
starting point for exploring where language's structural 
sophistication comes from, because it certainly 
seems that propositional contents have structural 
patterns, so that these must eventually fall out 
of linguistic processing.  Of course, we may also 
argue that linguistic structure derives from how 
we conceptualize states of affairs %-- and encode 
these conceptualizations in language %-- 
as much as from the structural logic of states of 
affairs themselves.    
`p`

`p.
As explanatory intermediaries, both cognitive and 
propositional structure can coexist as 
originations for formalisms manifest in language.  
We need not regard analysis of cognitive frames 
exerting a morphosyntactic influence on the shape 
of aggregate linguistic units as denying a parallel 
influence from the situational context with which 
discource must, to some measure, propositionally 
align; or vice-versa.  And yet there do seem 
to be paradigm-grounded pressures to situate 
language morphology (in the informal sense of 
higher-level linguistic `q.shape`/) `i.either` in 
expressed propositions `i.or` in cognitive construals.  
To some degree this may reflect metatheoretic 
divergence in the basic terms of discussion: 
is the `i.meaning` of (4) here to be the 
proposition that Warren will win, or the speaker's 
belief that Warren will win?

`exs.
`ex; Warren will probably win the nomination.
`ex; Biden's support among the base is eroding.
`exs`

Likewise, should we understand the more metaphorical 
phraseology in (5) as a conventionalized idiom that 
has become a kind of entrenched signifier, no longer 
really operating metaphorically; or rather as  
projections of metaphorical devices which the speaker 
uses conceptually to think through the situation, 
anterior to her opinions being verbalized?     
`p`

`p.
Taking a broad view, language involves a (typically iterative) 
process where a speaker has some thought, encodes it via 
language, yielding a spoken or written aggregate which 
an addressee encounters, processes, and then (hopefully) 
understands.  Most of this larger process occurs within 
the minds of the conversants participating; but 
it could reasonably argued that the specifically 
`i.linguistic` (and not psychological or sociocultural) 
concern here is focused on the observable properties of 
the spoken or written content produced.  The mental 
provenance and reception surrounding that content may be 
very real, but (or so one might say) cognitive 
analysis only has bearing on the specific 
disciplinary focus of `i.linguistics` insofar as 
the objective language artifact bears the 
imprint of certain cognitive processes, which are 
irreducible in a comprehensive account of why 
the artifact exists.  To make an analogy, 
suppose a footballer executes a pass in accorded 
with a specific tactic which his team rehearses 
and discusses in practice.  There are surely many 
cerebral and physiological factors contributing to 
the player making that pass, but a football expert 
would be expected to focus on the pass itself 
%-- its tactical rationale and execution technique.  
In this analogy, actual linguistic content 
%-- sentences, say %-- are like the football in a football 
match; they are tangibly observable.  
The ball is played over the course of a match, and its 
spatial position can be described %-- as can player-specific 
factors affecting the ball's location, such as how they 
execute on-ball maneuvers, and their decision-making 
insofar as it fits within the overall scheme of 
football's rules and tactics.  But the analytic 
attention should rest with the ball itself, and 
only expand to include players' thought processes 
insofar as these bring explanatory value to 
observations of the game's objective features.
`p`

`p.
Analogously, language is, objectively, a realm of spoken and 
written productions or perhaps a system for creating new 
ones.  Consequently, someone can reasonably suggest that 
cognitive analyses explaining how a speaker 
came to enunciate `i.this particular` sentence may be 
correct, but also are not in and of themselves 
descriptions of speakers' meanings.  Reprising earlier 
examples, someone might say that political discourse 
(being fairly important and repetitive in a modern 
democracy) has evolved certain entrenched idioms, so 
we speak of `i.pivoting to the center` or `i.eroding support` 
as a shorthand for characteristic, objectively definable 
situations in the realm of politics.  The entrenched 
expressions and their objective content %-- however 
metaphoric the latter may seem, and abstract/contextual 
the former %-- stand in a signifier/signified relation not 
that different from a more mundane/concrete semiosis 
like `i.cat` and one class of animals, or `i.water` 
and `HTwoO;.  We are, in other words, prepared to 
accept that `q.cat` is a word which in some sense 
`i.means` the clade Felidae, and `q.water` means 
`HTwoO;.  We do not take these `q.meanings` to be 
cognitive phenomena, even if we ackowledge that 
cognition is a kind of metaphysical prerequisite 
%-- no word would mean anything if not for 
each language-user having their own mental inventory 
of correct words for different contexts.  
Yet what makes these inventory items `i.words` is 
their stable co-existence in the minds of 
many (or all) speakers of a language.
`p`

`p.
The whole point of agreeing that `i.cat`/, say, 
is a word in English is to recognize a 
substratum in `i.cat` which is at a theoretic 
level non-cognitive even if it `i.is` cognitive 
as a matter of ontological foundation.  
As a `i.word`/, `i.cat` has a theoretical 
status which abstracts from its cognitive manifestation 
in any one English speaker's mind, such that it 
can be defined `q.extramentally` in terms of the 
pairing between the word and the set of mammals which 
it conventionally designates.  To be properly 
linguistic, it might seem, our understanding of 
lexical and syntactic phenomena must perhaps 
acknowledge the cognitive nature of linguistic 
conventions as a matter of physical empiricism 
%-- words don't `q.exist` in some ethereal 
netherworld %-- but then transcend this cognitive 
layer by analyzing language enough that the synergy 
among different speakers' linguistic predilections, 
rather than any intramental immanence, becomes 
the theoretical center-stage.  Linguistics 
proper therefore arises insofar as the 
cognitive dimension %-- siting linguistic 
rules and judgments in people's minds simply 
as a matter of ontological parsimony %-- 
becomes in a sense canceled out by multi-person 
alignments (which are preconditions for 
truly linguistic phenomena).  Linguistic extra-mentality is 
then akin to how political scientists take 
demographic and electoral trends as their scientific 
givens, even though elections only `q.exist` through the 
voting decisions of concrete individuals. 
`p` 

`p.
I will argue in the next section that Cognitive Linguists 
perhaps discount the pervasiveness or rationale behind 
these extra-mental intuitions, and therefore have not 
fully responded to (or potentially bridged to) 
formal methodology which, in turn, are inclined 
to underestimate the cognitive contributions to meaning.  
My own opinion, already intimated, is that language 
actually unifies formal and contextual dimensions, so 
that methodologies which foreground cognitive construal 
and those which prioritize formal substrata are 
both responding to real `q.signals` in linguistic data, 
and therefore both have merit.  However, I also 
believe that Cognitive and (say) Computational linguists 
have not-entirely-aligned intuitions of the basic demarcation 
of the linguistic discipline itself, which renders a 
certain paradigmatic disconnect almost inevitable.  
`p`

`p.
To see this, consider again the minimal example 
wherein, say, English speakers use the phoneme 
`i.cat` to express an idea which (to some approximation) 
matches the biologists' `i.Felidae`/.  I think everyone 
would agree that a certain cognitive construal is thereby 
conventionalized and internalized to the point where, 
from each individual person's point of view, it becomes 
a `i.de facto` fact of the world: everyone knows that 
everybody else expects us to say `i.cat` when we intend 
to talk about Felids, so %-- however much the association 
may lie in people's minds %-- we all accept the useful 
fiction that `i.cat` means `i.Felid` as a matter of 
objective fact; just as Obama's or Trump's victories were  
objective facts notwithstanding `q.victory` meaning 
many individual persons' decisions to vote for them 
(and even more people's decision to recognize the election 
as legitimate, notwithstanding their own vote).  
Against this background, we can say both that 
linguistics concerns cognitive inclinations that 
are synchronized between people to the point 
of conventional entrenchment; `i.and` that 
linguistics concerns regularities conventionalized 
to the point where cognitive processes can be 
excluded from the fields disciplinary scope 
(and when they can't %-- e.g. in the analysis 
of rhetorical persuasion or of literary artistry 
%-- they tap into aspects of language which linguistics 
is not itself about).  But this leaves us with 
two different conceptions of the linguistic enterprise, 
differences which can be seen most clearly not on 
the methodological level but in the `q.philosophical` 
process of identifying the specific analyzands 
which are in fact the substance of linguistic science. 
`p`

`p.
Moreover, I think this divergence is clearest in the 
context of propositional content.  As I argued earlier, 
most or all sentences are specifically aligned 
with (and project propositional attitudes toward) 
specific propositions; such that the meaning of 
a sentence is dependent on (even when it does not 
coincide with) a proposition which the sentence 
signifies.  This means that language is a system 
which can designate propositions in often 
unambiguous ways %-- where the connection between 
the concrete utterance and the relevant predicate 
complex has essentially the status of 
objective (albeit social) fact (`q.objective` in 
the emergent sense akin to the objective fact of 
an electoral victory, say).  Moreover, this 
connection is largely a matter of agreement and consent, 
without any special interpretation or ad-hoc 
protocols enacted between speakers.  Suppose 
someone overseas desires a baguette from a bakery and, 
not speaking the local language, points to her bread 
of choice; the shopkeeper responds by raising two fingers; 
she responds by giving him two Euros, and he gives her 
the baguette.  Hence their activities have been coordinated, 
but according to relatively unstructured gestures conceived 
on the spot (except insofar as some gestures, like pointing 
or the use of fingers to represent number, have an 
almost-linguistic determinacy).  Conversely, 
if the two participants both speak English, we might 
instead have 

`exs,
`ex. May I have a baguette?
`ex. Two Euros, please.
`exs`

We can reasonably assume that the shopper in (1) expresses her 
desire to `i.purchase` bread (she doesn't expect the baker to 
just hand her the bread as charity, or for her to examine).  
Likewise we can assume that the baker indicates in (2) that the 
bread costs two Euros, so that in the proper discharge of 
his duty he will give her the bread once she gives him the Euros.  
We can clearly identify the relevant propositional contents: 

`exs,
`ex. I would like to purchace a baguette.  
`ex. If you give you two Euros, I will give you a baguette 
and recognize it as yours.
`exs` 

But fully explicating the logical details can seem awkward, 
even impolite.  In reality, we almost always use language 
to designate propositional content which is not precisely 
modeled by the language itself, and therefore 
arises by virtue of conventions and implicatures.  
Language possesses a system of transformations such 
that linguistic structures map to propositional 
contents, even if the former structure is morphologically 
divegent from the structure of the relevant propositions.
`p`

`p.
In effect, language designates propositional content, but 
does so in accord with its own rules and conventions, 
which are not the same as transparent logical articulations 
of predicate structure.  While the `i.processing` which puts 
these rules in effect is mental, their being linguistic 
expressly means that the rules have a commonality which 
transcends any person's (or even any conversation's) 
cognitive dispositions.  We would probably agree  
(barring some extraordinary contextual detail) that
(1) `i.necessarily` signifies the shopper's desire 
to buy a baguette, even if she or the baker (or both) 
are inclined to impose some idiosyncratic interpretation.  
We can of course imagine competing scenarios %-- perhaps the 
baker intends (with her prior knowledge) to give her the baguette 
for free, but she has to pretend an intention to buy the 
bread so as hide their collusion from other shoppers.  
In this case (1) might indeed be a special signal the colluders 
adopt, with an idiosyncratic meaning; but surely they 
are still aware of their departure from correct usage, and 
this departure is part of the metalinguistic rule of 
their convention: they agree to use the sentence 
`i.which on ordinary terms` describes the speaker's 
intention to buy bread as, between them, a coded message.  
Likewise, as some inside joke, two friends might use 
the word `i.cat` to reference `i.dogs`/; but here they 
are self-consciously investing `i.the word that means 
`q.cat`/` with some deviant meaning layered on top of 
its normal one.      
`p`

`p.
So `i.how` linguistic structure translates to propositional 
structure is something outside the control of individual 
people, and so it manifests itself, as a kind of scientific 
fiction, as objective fact.  A linguist (or logician 
or philosopher) is then on credible grounds in believing 
that the locus of scientific inquiry into language lies with 
how linguistic structures communicate propositional 
content even though the structures generated by 
syntax and semantics are not facile duplications of 
the structures of propositions, or predicate-complexes.  
Language appears to be an encoding of logic via 
structures without trivial logical rationales.  
Accordingly, scientists might well be interested in the 
`q.hidden logic` whereby the surface structure of 
language `q.compiles` to the deep structure of 
propositions.  The central focus of that analysis 
would then be propositional content as an extramental 
signification of sentences (as much as `i.cat` is 
an extramental signifier for `i.Felidae`/) 
and the set of rules which govern the reduction 
of linguistic structure to predicate structure.  
Language is fully explicated, on this account, 
when a list of rules is provided such that 
every alignment between a sentence 
(with its specific surface structure) 
and its propositional content (with a 
specific predicate structure) is accounted 
for, so we can have a theory for 
why `i.that` surface (linguistic) structure 
maps to `i.this` deep (predicate) structure.  
`p`

`p.
From this perspective, cognitive processing is not so 
much unimportant as tangential; the surface-to-deep, 
language-to-predicate transformation is certain 
a cognitive phenomenon, but `i.as linguistic` 
it only exists as a cerebral faculty of one person 
if it exists as a shared competence among all 
speakers of the language/dialect.  For `i.theoretical` 
elaboration, then, this `q.predicate reduction` is 
`i.not` cognitive, in the sense that its cognitive 
givenness should not factor in to its theoretical 
treatment.  Instead, language should be seen as a 
`q.predicate reduction` system %-- mapping 
surface linguistis structure to deep predicate 
structure, in the course of signifying propositional 
contents via linguistic media %-- which can be 
described in structural and logical terms, 
witholding appeals to the cognitive nature of 
the mental operations wherein the isolation of 
predicate formations occurs.  
`p`

`p.
I believe this framing of the linguistic enterprise is 
too simplistic, so I will rebut it somewhat in the 
next section, but I also believe that it 
should be assessed on its own terms.  The paradigm of 
`q.truth theoretic` semantics %-- which Langacker designates 
as ... %-- is most directly contrastible with 
Langacker's own Cognitive-Grammatic project when the 
differences are expressed as matters of scientific ontology 
and theoretical posits.  A ... semantics (or philosophy 
of language) can say that there exists objective 
fixations in how language (surface) structure maps to 
predicate (deep) structure %-- regulations which are 
extramental in the same way that propositions themselves 
are, and likewise linguistic artifacts (like spoken words).  
Linguistics per se is (so one might argue) the investigation 
of how, via a catalogue of structural transforms, 
languages encode propositions, via mechanisms which 
do not rely on cognitive faculties (like observations of 
similarity or interpretation of gestures) apart from 
those explicitly regulated by syntactic and semantic 
norms.  There may be alot of further analysis we can 
perform on the conceptual motivation behind 
`q.predicate reduction` rules, on what occurs mentally 
when people formulate and then interpret 
linguistic artifacts under the aegis of predicative 
communication, and on the role of cognitive construals 
in novel or inventive uses of language %-- but these 
are analyses of conceptual processing of linguistic 
structures, not analyses of these structures themselves.  
We cannot assume that the presence of linguistic 
structure in the mind, as something we think about and 
acquire competence for, renders those structures 
intrinsically mental.  By analogy, we can think about 
and become competent in abstract algebra or complex 
analysis; and symmetry groups or complex numbers can 
indeed be objects of thought, indeed objects 
toward which we apply mental exercises to the point that 
manipulating their structural domains becomes a kind 
of cerebral faculty and skill; but none of this makes 
the structures of group theory or complex numbers 
internally `i.cognitive`/.  They are, instead, 
abstract givens which become mental only insofar as 
they become cognitive foci whose thinking-about we 
rehearse to the threshold of a certain cerebral 
competence.  Arguably, syntax and semantics 
are in the same boat %-- they are objective 
and extramental systems, but because it is important 
for most people to master at least one language, 
we expend effort (albeit potentially unconsciously, when 
we learn languages as childen) to internalize these structures 
enough that we can form and understand sentences with little 
or no conscious effort.  That is, a lot of our human 
engagement with language is as something that stretches 
outside our mental reach but which we want to internalize 
as much as possible %-- we want to `i.learn` and 
`i.master` languages, so we are engaged with linguistic 
structures as objects of thought and competence, with 
our cognitive facility in manipulating language.  
However %-- or at least this is an intuition we 
have to respond to %-- study of our cognitive facility 
in manipulating language is a different disciplinary 
obligation than studying language itself.   
`p`

`p.

`p`

